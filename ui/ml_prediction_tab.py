import streamlit as st
import pandas as pd
import numpy as np
import time
import matplotlib.pyplot as plt
import datetime
from datetime import timedelta
import plotly.graph_objects as go
import yfinance as yf
import plotly.express as px
import math
import threading
import warnings
import sqlite3
from sqlalchemy import create_engine, inspect, text, Column, Integer, Float, String, DateTime, JSON, Boolean
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import sessionmaker, scoped_session
import os
import re
import io
import sys
import json
import logging
from contextlib import redirect_stdout
import traceback
from typing import Dict, List, Tuple, Optional, Union, Any
import openai
import seaborn as sns
import subprocess

# DÜZELTME: Geliştirilmiş news_tab dosyasını kullan
from ui.improved_news_tab import analyze_news, get_sentiment_explanation, display_log_message

warnings.filterwarnings("ignore")

# data modülünü sys.path'e ekle (eğer farklı klasördeyse)
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
data_dir = os.path.join(parent_dir, 'data')

# Veritabanı dosyası yolu
DB_FILE = os.path.join(parent_dir, 'data', 'stock_data.db')

if data_dir not in sys.path:
    sys.path.append(data_dir)

# news_data modülünü import et
try:
    # import news_data # Eski import kaldırıldı
    from data.news_data import get_stock_news # Doğrudan fonksiyon import edildi
    from ui.news_tab import analyze_news, get_sentiment_explanation, display_log_message
except ImportError as e:
    st.error(f"news_data modülü veya get_stock_news fonksiyonu import edilemedi: {e}")
    st.stop()

# Loglama ayarları (diğer modülde tanımlı logger'ı kullanabiliriz)
# logger = logging.getLogger(__name__)
# VEYA burada yeni bir logger tanımlayabiliriz
# logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
# logger = logging.getLogger(__name__)

def render_ml_prediction_tab():
    st.header("ML Yükseliş Tahmini", divider="rainbow")
    st.markdown("""
    Bu sekme, makine öğrenmesi (sınıflandırma) kullanarak seçilen zaman dilimi sonunda belirlediğiniz eşik değerinden **daha fazla yükselecek** hisseleri tahmin eder.
    Tahminler, modelin bu yükselişin gerçekleşme **olasılığını** ne kadar gördüğünü gösterir.

    **GELİŞTİRİLMİŞ MODEL**: Fibonacci, Elliott Dalgaları, Döviz Kurları, Makroekonomik Göstergeler ve Sektörel Analizleri içeren daha kapsamlı bir veri seti ile çalışabilir.

    **Not:** Tahminler yatırım tavsiyesi niteliği taşımaz. Sadece bilgi amaçlıdır.
    """)

    # Gerekli kütüphanelerin kontrolü ve yüklenmesi
    libs_installed = True
    try:
        import xgboost as xgb
        import lightgbm as lgb
        from sklearn.preprocessing import MinMaxScaler
        from sklearn.ensemble import RandomForestClassifier
        from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
        import numpy as np
        import matplotlib.pyplot as plt
        import pandas as pd
        import yfinance as yf
        import traceback # Hata ayıklama için
        import matplotlib # Grafik çizimi için backend ayarı
        import warnings
        import io
        import sys
        from contextlib import redirect_stdout, redirect_stderr
        
        # LightGBM uyarılarını bastır
        warnings.filterwarnings("ignore", category=UserWarning, module="lightgbm")
        warnings.filterwarnings("ignore", category=UserWarning, module="sklearn")
        warnings.filterwarnings("ignore", category=pd.errors.PerformanceWarning)
        
        matplotlib.use('Agg') # Streamlit ile uyumlu backend
    except ImportError as e:
        libs_installed = False
        st.error(f"Gerekli kütüphane/kütüphaneler eksik: {e}. Lütfen `pip install xgboost lightgbm scikit-learn numpy matplotlib pandas yfinance` komutu ile yükleyin.")
        st.stop() # Kütüphaneler yoksa devam etme
    
    # Veritabanının oluştuğundan emin olalım
    try:
        # Veritabanı kontrol edelim
        from data.db_utils import create_database, DB_FILE
        import os
        import sqlite3
        
        # Veritabanı yoksa oluştur
        if not os.path.exists(DB_FILE):
            st.info("Veritabanı oluşturuluyor...")
            create_database()
            st.success("Veritabanı başarıyla oluşturuldu.")
        
        # ml_models tablosu var mı kontrol et
        conn = sqlite3.connect(DB_FILE)
        cursor = conn.cursor()
        cursor.execute("SELECT name FROM sqlite_master WHERE type='table' AND name='ml_models'")
        if cursor.fetchone() is None:
            st.warning("ml_models tablosu bulunamadı. Yeniden oluşturuluyor...")
            create_database()
            st.success("Veritabanı tabloları yeniden oluşturuldu.")
        conn.close()
    except Exception as db_error:
        st.error(f"Veritabanı kontrolü sırasında hata: {str(db_error)}")

    # Gemini API entegrasyonu
    gemini_pro = None
    
    # Önce google-generativeai yüklü mü kontrol et, değilse yüklemeyi dene
    try:
        import google.generativeai as genai
    except ImportError:
        st.warning("Google GenerativeAI kütüphanesi yükleniyor... Bu işlem biraz zaman alabilir.")
        try:
            # Kütüphaneyi yüklemeyi dene
            subprocess.check_call([sys.executable, "-m", "pip", "install", "google-generativeai"])
            st.success("Google GenerativeAI kütüphanesi başarıyla yüklendi!")
            # Yüklemeden sonra tekrar import etmeyi dene
            try:
                import google.generativeai as genai
            except ImportError:
                st.error("Kütüphane yüklendi ancak import edilemedi. Uygulamayı yeniden başlatmanız gerekebilir.")
        except Exception as install_error:
            st.error(f"Kütüphane yüklenirken hata oluştu: {str(install_error)}")
    
    # API anahtarı ve model yapılandırması
    try:
        # API anahtarını doğrudan tanımla
        GEMINI_API_KEY = "AIzaSyANEpZjZCV9zYtUsMJ5BBgMzkrf8yu8kM8"
        
        if GEMINI_API_KEY:
            # API yapılandırması
            genai.configure(api_key=GEMINI_API_KEY)
            
            # Farklı model adlarını en yeniden eskiye ve en iyiden kötüye doğru sırala
            model_options = [
                'gemini-2.0-pro-exp', 'gemini-2.0-flash', 'gemini-2.0-flash-001',
                'gemini-1.5-pro-latest', 'gemini-1.5-flash-latest', 'gemini-1.5-flash-8b-exp',
                'gemini-1.5-pro-002', 'gemini-1.5-pro-001', 'gemini-1.5-pro',
                'gemini-1.5-flash-002', 'gemini-1.5-flash-001', 'gemini-1.5-flash',
                'gemini-1.0-ultra', 'gemini-1.0-pro'
            ]
            
            successful_model = None
            for model_name in model_options:
                try:
                    test_model = genai.GenerativeModel(model_name)
                    # Test et
                    response = test_model.generate_content("Merhaba")
                    # Başarılı ise kaydet
                    gemini_pro = test_model
                    st.success(f"Gemini API bağlantısı kuruldu: {model_name} modeli kullanılıyor.")
                    break
                except Exception as model_error:
                    continue
            
            if gemini_pro is None:
                st.warning("Gemini API modellerine erişilemedi. Duyarlılık analizi kullanılamayacak.")
    except Exception as e:
        st.warning(f"Gemini API kurulumu hatası: {str(e)}")

    # Parametreler
    col1, col2, col3 = st.columns(3)

    with col1:
        # Eşik değeri slider'ı
        ml_threshold = st.slider("Yükseliş Eşiği (%)", min_value=0.5, max_value=10.0, value=2.0, step=0.5, key="ml_pred_threshold", help="Modelin hangi yüzdelik artışın üzerini 'Yükseliş' olarak sınıflandıracağını belirler.") / 100

    with col2:
        scan_option = st.radio(
            "Tarama Modu:",
            ["BIST 30", "BIST 50", "BIST 100", "Özel Liste"],
            index=2,
            horizontal=True,
            key="ml_scan_option"
        )

    with col3:
        time_frame = st.selectbox(
            "Zaman Dilimi",
            ["4 Saat", "1 Gün", "1 Hafta", "1 Ay"],
            index=1,
            key="ml_time_frame"
        )

    # Özel liste seçeneği için hisse giriş alanı
    custom_stocks = ""
    if scan_option == "Özel Liste":
        custom_stocks = st.text_area(
            "Hisse Kodları (virgülle ayırın)",
            placeholder="Örnek: THYAO, GARAN, ASELS",
            help="Analiz etmek istediğiniz hisse kodlarını virgülle ayırarak girin (.IS uzantısı otomatik eklenecektir).",
            key="ml_custom_stocks"
        )

    # Gelişmiş ayarlar
    with st.expander("Gelişmiş Ayarlar"):
        adv_col1, adv_col2 = st.columns(2)

        with adv_col1:
            confidence_threshold = st.slider(
                "Minimum Yükseliş Olasılığı (%)",
                min_value=40,
                max_value=95,
                value=60, # Daha makul bir varsayılan
                key="ml_confidence_threshold",
                help="Bir hissenin 'Yükseliş' olarak etiketlenmesi için modelin tahmin etmesi gereken minimum olasılık."
            )

            feature_importance = st.checkbox(
                "Özellik Önemini Göster",
                value=True,
                key="ml_feature_importance",
                help="Modelin hangi faktörleri daha önemli bulduğunu gösterir."
            )

            backtesting = st.checkbox(
                "Geriye Dönük Test (Test Seti)",
                value=True,
                key="ml_backtesting",
                help="Modelin geçmiş verinin bir kısmındaki (test seti) performansını gösterir."
            )

            use_advanced_features = st.checkbox(
                "Gelişmiş Teknik Göstergeler",
                value=False, # Varsayılan olarak kapalı, daha hızlı tarama için
                key="ml_use_advanced_features",
                help="Fibonacci, Elliott Dalgaları, Hacim analizleri gibi gelişmiş göstergeleri ekler."
            )
            
        with adv_col2:
            model_selection = st.selectbox(
                "Kullanılacak Model",
                ["RandomForest", "XGBoost", "LightGBM", "Ensemble", "Hibrit Model"],
                index=0,
                key="ml_model_selection",
                help="ML tahmininde kullanılacak model türü."
            )

            # Zaman dilimine bağlı olarak tahmin gün sayısını ayarla
            if time_frame == "4 Saat":
                days_prediction = 1  # 1 gün
            elif time_frame == "1 Gün":
                days_prediction = 1  # 1 gün
            elif time_frame == "1 Hafta":
                days_prediction = 7  # 1 hafta
            else:  # 1 Ay
                days_prediction = 30  # 1 ay
            
            include_sentiment = st.checkbox(
                "Duyarlılık Analizini Dahil Et",
                value=False,
                key="ml_include_sentiment",
                help="Haberler ve sosyal medyadan toplanan duyarlılık verilerini modele dahil eder."
            )
            
            # Değişken adı düzeltme
            use_sentiment_analysis = include_sentiment
            
            include_macro_data = st.checkbox(
                "Makro Verileri Dahil Et",
                value=False,
                key="ml_include_macro",
                help="Döviz kurları, enflasyon, sektör performansı gibi makro verileri modele dahil eder."
            )
            
            # Değişken adı düzeltme
            use_macro_sector_data = include_macro_data
            
            include_market_sentiment = st.checkbox(
                "BIST 100 Verilerini Dahil Et",
                value=True,
                key="ml_include_market_sentiment",
                help="BIST 100 endeksinin teknik göstergelerini modele dahil eder."
            )
            
        # Veritabanı Model Ayarları altbölümü
        st.markdown("#### Veritabanı Model Ayarları")
        st.info("Bu ayarlar, her hisse için özelleştirilmiş modelleri veritabanında saklayarak tarama hızını artırır ve tahmin doğruluğunu iyileştirir.")
        
        db_col1, db_col2 = st.columns(2)
        
        with db_col1:
            use_db_models = st.checkbox(
                "Önceden Eğitilmiş Modelleri Kullan", 
                value=True,
                key="ml_use_db_models",
                help="Veritabanında bulunan önceden eğitilmiş modelleri kullanarak tahmin hızını artırır."
            )
            
            auto_train_missing = st.checkbox(
                "Eksik Modelleri Otomatik Eğit", 
                value=True,
                key="ml_auto_train_missing",
                help="Veritabanında bulunmayan hisseler için otomatik model eğitimi yapar."
            )
            
        with db_col2:
            force_retrain = st.checkbox(
                "Tüm Modelleri Yeniden Eğit", 
                value=False,
                key="ml_force_retrain",
                help="Tüm hisseler için yeni model eğitir ve veritabanını günceller."
            )
            
            if st.checkbox(
                "Veritabanı Model İstatistiklerini Göster", 
                value=False,
                key="ml_show_db_stats"
            ):
                # Veritabanında kaç model kayıtlı olduğunu göster
                from data.db_utils import DB_FILE
                import sqlite3
                
                try:
                    conn = sqlite3.connect(DB_FILE)
                    cursor = conn.cursor()
                    cursor.execute("SELECT COUNT(*) FROM ml_models WHERE is_active = 1")
                    total_models = cursor.fetchone()[0]
                    
                    cursor.execute("SELECT model_type, COUNT(*) FROM ml_models WHERE is_active = 1 GROUP BY model_type")
                    model_counts = cursor.fetchall()
                    
                    conn.close()
                    
                    st.write(f"Veritabanında toplam **{total_models}** model bulunuyor.")
                    
                    # Model tipine göre dağılımı göster
                    if model_counts:
                        model_stats = pd.DataFrame(model_counts, columns=["Model Tipi", "Adet"])
                        st.dataframe(model_stats, use_container_width=True)
                except Exception as e:
                    st.error(f"Veritabanı istatistikleri alınırken hata: {str(e)}")

    # --- Yardımcı Fonksiyonlar ---
    @st.cache_data(ttl=3600) # Veriyi 1 saat cache'le
    def get_stock_data_cached(symbol, period="5y", interval="1d", handle_missing=True):
        try:
            # Log mesajlarını sadece log_expander varsa göster
            if 'log_expander' in globals() and log_expander is not None:
                with log_expander:
                    st.info(f"----->>> [{symbol}] yfinance.Ticker çağrılıyor... (Period: {period}, Interval: {interval})")
            
            # Veriyi al
            stock = yf.Ticker(symbol)
            data = stock.history(period=period, interval=interval)
            
            # Veri durumunu sadece log_expander varsa logla
            if 'log_expander' in globals() and log_expander is not None:
                with log_expander:
                    if data.empty:
                        st.warning(f"----->>> [{symbol}] yfinance'den boş veri döndü.")
                    else:
                        st.success(f"----->>> [{symbol}] yfinance'den veri alındı ({len(data)} satır).")
            
            # Boş veri kontrolü
            if data.empty:
                return None
            
            # Tarih damgasını UTC'den arındır
            if data.index.tz is not None:
                data.index = data.index.tz_localize(None)
            
            # Eksik veri işleme - gelişmiş yöntemler
            if handle_missing and not data.empty:
                # Eksik değerlerin oranını kontrol et
                missing_ratio = data.isnull().sum() / len(data)
                
                if 'log_expander' in globals() and log_expander is not None:
                    with log_expander:
                        if missing_ratio.max() > 0:
                            st.info(f"----->>> [{symbol}] Eksik veri oranı: {missing_ratio[missing_ratio > 0].to_dict()}")
                
                # Fiyat verilerini OHLC değerlerini kullanarak doldur - önce ileri sonra geri doldurma
                for col in ['Open', 'High', 'Low', 'Close']:
                    if data[col].isnull().any():
                        # Önce forward fill - önceki değerle doldur
                        data[col] = data[col].fillna(method='ffill')
                        
                        # Sonra backward fill - sonraki değerle doldur
                        data[col] = data[col].fillna(method='bfill')
                        
                        # Hala eksik varsa interpolasyon kullan
                        data[col] = data[col].interpolate(method='linear')
                
                # Hacim için sıfır olmayan son değerle doldur
                if 'Volume' in data.columns and data['Volume'].isnull().any():
                    # Son sıfır olmayan değerle doldur
                    data['Volume'] = data['Volume'].replace(0, np.nan).fillna(method='ffill')
                    # Kalan NaN'ları medyan ile doldur
                    median_volume = data['Volume'].median()
                    data['Volume'] = data['Volume'].fillna(median_volume)
                
                # Yeni zaman serisi oluştur - özellikle dakikalık/saatlik verilerde eksik zaman aralıkları olabilir
                if interval in ['1m', '2m', '5m', '15m', '30m', '60m', '90m', '1h']:
                    # Yeni zaman aralığı oluştur
                    start_date = data.index.min()
                    end_date = data.index.max()
                    
                    if interval.endswith('m'):
                        minutes = int(interval[:-1])
                        freq = f'{minutes}T'  # Pandas için dakika formatı
                    elif interval.endswith('h'):
                        hours = int(interval[:-1])
                        freq = f'{hours}H'  # Pandas için saat formatı
                    else:
                        freq = '1D'  # Varsayılan günlük
                    
                    # Yeni tarih aralığı oluştur
                    full_range = pd.date_range(start=start_date, end=end_date, freq=freq)
                    
                    # Sadece işlem günleri ve saatleri (Pazartesi-Cuma, 10:00-18:00)
                    if interval in ['1m', '2m', '5m', '15m', '30m', '60m', '90m', '1h']:
                        # İşlem saatleri maskesi
                        trading_hours = (full_range.hour >= 10) & (full_range.hour < 18)
                        # İşlem günleri maskesi (0=Pazartesi, 4=Cuma)
                        trading_days = (full_range.dayofweek >= 0) & (full_range.dayofweek <= 4)
                        # Her ikisinin de sağlandığı günler
                        full_range = full_range[trading_hours & trading_days]
                    
                    # Mevcut verileri yeni aralığa yeniden dizinle ve eksikleri doldur
                    if len(full_range) > len(data.index):
                        data = data.reindex(full_range)
                        
                        # Eksikleri doldur
                        for col in ['Open', 'High', 'Low', 'Close']:
                            # Önce forward fill
                            data[col] = data[col].fillna(method='ffill')
                            # Sonra backward fill
                            data[col] = data[col].fillna(method='bfill')
                            # Yine de eksik varsa interpolasyon kullan
                            data[col] = data[col].interpolate(method='linear')
                        
                        # Hacim için son değerle doldur
                        if 'Volume' in data.columns:
                            # Eksik işlem saatleri - hacmi 0 olarak doldur
                            data['Volume'] = data['Volume'].fillna(0)
            
            return data
            
        except Exception as e:
            # Hata durumunu sadece log_expander varsa logla
            if 'log_expander' in globals() and log_expander is not None:
                with log_expander:
                    st.error(f"----->>> [{symbol}] yfinance veri alırken HATA: {str(e)}")
            return None

    # Teknik göstergeleri hesaplayan fonksiyon
    def calculate_technical_indicators(data):
        """Temel teknik göstergeleri hesaplar"""
        df = data.copy()
        
        # RSI
        delta = df['Close'].diff()
        gain = delta.where(delta > 0, 0)
        loss = -delta.where(delta < 0, 0)
        avg_gain = gain.rolling(window=14).mean()
        avg_loss = loss.rolling(window=14).mean()
        rs = avg_gain / avg_loss
        df['RSI'] = 100 - (100 / (1 + rs))
        
        # MACD
        df['MA_12'] = df['Close'].rolling(window=12).mean()
        df['MA_26'] = df['Close'].rolling(window=26).mean()
        df['MACD'] = df['MA_12'] - df['MA_26']
        df['MACD_Signal'] = df['MACD'].rolling(window=9).mean()
        df['MACD_Histogram'] = df['MACD'] - df['MACD_Signal']
        
        # Bollinger Bands
        df['MA_20'] = df['Close'].rolling(window=20).mean()
        df['20d_std'] = df['Close'].rolling(window=20).std()
        df['BB_Upper'] = df['MA_20'] + (df['20d_std'] * 2)
        df['BB_Lower'] = df['MA_20'] - (df['20d_std'] * 2)
        df['BB_Width'] = (df['BB_Upper'] - df['BB_Lower']) / df['MA_20']
        
        # Hareketli Ortalamalar
        df['MA_5'] = df['Close'].rolling(window=5).mean()
        df['MA_10'] = df['Close'].rolling(window=10).mean()
        df['MA_50'] = df['Close'].rolling(window=50).mean()
        df['MA_200'] = df['Close'].rolling(window=200).mean()
        
        # Hacim Göstergeleri
        df['Volume_Change'] = df['Volume'].pct_change()
        df['Volume_MA_20'] = df['Volume'].rolling(window=20).mean()
        df['Volume_Ratio'] = df['Volume'] / df['Volume_MA_20']
        
        # Momentum Göstergeleri
        df['Momentum_5'] = df['Close'] / df['Close'].shift(5)
        df['Momentum_10'] = df['Close'] / df['Close'].shift(10)
        df['ROC_5'] = df['Close'].pct_change(periods=5) * 100
        df['ROC_10'] = df['Close'].pct_change(periods=10) * 100
        
        # Stochastic Oscillator
        low_min = df['Low'].rolling(window=14).min()
        high_max = df['High'].rolling(window=14).max()
        df['Stoch_K'] = 100 * ((df['Close'] - low_min) / (high_max - low_min))
        df['Stoch_D'] = df['Stoch_K'].rolling(window=3).mean()
        
        # ATR (Average True Range)
        df['TR'] = np.maximum(
            np.maximum(
                df['High'] - df['Low'],
                abs(df['High'] - df['Close'].shift(1))
            ),
            abs(df['Low'] - df['Close'].shift(1))
        )
        df['ATR'] = df['TR'].rolling(window=14).mean()
        
        # OBV (On-Balance Volume)
        df['OBV'] = (np.sign(df['Close'].diff()) * df['Volume']).fillna(0).cumsum()
        
        # Getiri Oranları
        df['Daily_Return'] = df['Close'].pct_change()
        df['Weekly_Return'] = df['Close'].pct_change(5)
        df['Monthly_Return'] = df['Close'].pct_change(20)
        
        # Volatilite
        df['Volatility_5'] = df['Daily_Return'].rolling(window=5).std()
        df['Volatility_20'] = df['Daily_Return'].rolling(window=20).std()
        
        # Kanal Göstergeleri
        df['Upper_Channel'] = df['High'].rolling(window=20).max()
        df['Lower_Channel'] = df['Low'].rolling(window=20).min()
        df['Channel_Width'] = (df['Upper_Channel'] - df['Lower_Channel']) / df['MA_20']
        
        # Eğim Göstergeleri
        df['MA_5_Slope'] = df['MA_5'].diff(5) / 5
        df['MA_20_Slope'] = df['MA_20'].diff(5) / 5
        df['MA_50_Slope'] = df['MA_50'].diff(5) / 5
        
        # YENİ: Fibonacci Retracement Seviyeleri
        try:
            # Son 100 gün için pivotlar
            lookback = min(len(df), 100)
            if lookback >= 20:  # En az 20 veri noktası gerekli
                recent_df = df.iloc[-lookback:]
                
                # Yüksek ve düşük noktaları belirle
                recent_high = recent_df['High'].max()
                recent_low = recent_df['Low'].min()
                high_idx = recent_df['High'].idxmax()
                low_idx = recent_df['Low'].idxmin()
                
                # Trend yönünü belirle (yüksek nokta daha sonraysa yükselen trend, tersi düşen)
                uptrend = high_idx > low_idx
                
                # Fibonacci seviyeleri (yukarı trend için)
                if uptrend:
                    df['Fib_0'] = recent_low
                    df['Fib_23.6'] = recent_low + (recent_high - recent_low) * 0.236
                    df['Fib_38.2'] = recent_low + (recent_high - recent_low) * 0.382
                    df['Fib_50'] = recent_low + (recent_high - recent_low) * 0.5
                    df['Fib_61.8'] = recent_low + (recent_high - recent_low) * 0.618
                    df['Fib_100'] = recent_high
                    df['Fib_161.8'] = recent_low + (recent_high - recent_low) * 1.618
                else:  # Aşağı trend için
                    df['Fib_0'] = recent_high
                    df['Fib_23.6'] = recent_high - (recent_high - recent_low) * 0.236
                    df['Fib_38.2'] = recent_high - (recent_high - recent_low) * 0.382
                    df['Fib_50'] = recent_high - (recent_high - recent_low) * 0.5
                    df['Fib_61.8'] = recent_high - (recent_high - recent_low) * 0.618
                    df['Fib_100'] = recent_low
                    df['Fib_161.8'] = recent_high - (recent_high - recent_low) * 1.618
                
                # Fibonacci Trend İlişkisi
                df['Fib_Trend'] = 1 if uptrend else -1
                df['Price_To_Fib50'] = (df['Close'] - df['Fib_50']) / df['Fib_50']
                df['Price_To_Fib618'] = (df['Close'] - df['Fib_61.8']) / df['Fib_61.8']
        except Exception as e:
            # Hata olursa varsayılan değerler
            df['Fib_Trend'] = 0
            df['Price_To_Fib50'] = 0
            df['Price_To_Fib618'] = 0
        
        # YENİ: ZigZag ve Olası Elliott Dalgaları
        try:
            # ZigZag parametreleri
            deviation_pct = 0.05  # Fiyat sapması yüzdesi
            
            # ZigZag hesaplama
            # ZigZag, yönü değiştiren "önemli" tepe ve dip noktalarını birleştiren çizgiler oluşturur
            high_series = df['High'].values
            low_series = df['Low'].values
            trend = 1  # 1: yukarı, -1: aşağı
            zigzag_points = []
            
            # İlk nokta için başlangıç değeri
            if len(high_series) > 0:
                current_point = {'date_idx': 0, 'price': low_series[0], 'type': 'low'}
                zigzag_points.append(current_point)
            
            # ZigZag noktaları bul
            for i in range(1, len(high_series)):
                # Yukarı trend
                if trend == 1:
                    # Yeni yüksek nokta ara
                    if high_series[i] > current_point['price']:
                        current_point = {'date_idx': i, 'price': high_series[i], 'type': 'high'}
                        
                    # Önceki yüksekten önemli bir düşüş mü var?
                    elif low_series[i] < current_point['price'] * (1 - deviation_pct):
                        zigzag_points.append(current_point)  # Önceki yüksek noktayı kaydet
                        current_point = {'date_idx': i, 'price': low_series[i], 'type': 'low'}
                        trend = -1  # Trend değişimi
                
                # Aşağı trend
                else:
                    # Yeni düşük nokta ara
                    if low_series[i] < current_point['price']:
                        current_point = {'date_idx': i, 'price': low_series[i], 'type': 'low'}
                        
                    # Önceki düşükten önemli bir yükseliş mi var?
                    elif high_series[i] > current_point['price'] * (1 + deviation_pct):
                        zigzag_points.append(current_point)  # Önceki düşük noktayı kaydet
                        current_point = {'date_idx': i, 'price': high_series[i], 'type': 'high'}
                        trend = 1  # Trend değişimi
            
            # Son noktayı ekle
            zigzag_points.append(current_point)
            
            # ZigZag paternlerini analiz et
            
            # En az 5 ZigZag noktası gereklidir (Elliott dalgasının minimum bölümü)
            if len(zigzag_points) >= 5:
                # Son 5 zigzag noktasını al (Elliott İmpülsif Dalgası için)
                last_zz_points = zigzag_points[-5:]
                
                # Basit Elliott Dalga Analizi (5 noktalı impulsif dalga)
                is_impulse = True
                # İmpülsif dalga tipik deseni: yukarı, aşağı, yukarı, aşağı, yukarı 
                # veya bunun tam tersi
                expected_types = ['low', 'high', 'low', 'high', 'low']  # Yükselen piyasa için
                if last_zz_points[0]['type'] == 'high':
                    expected_types = ['high', 'low', 'high', 'low', 'high']  # Düşen piyasa için
                
                # Nokta tiplerinin beklenen deseni takip edip etmediğini kontrol et
                for i, point in enumerate(last_zz_points):
                    if point['type'] != expected_types[i]:
                        is_impulse = False
                        break
                
                # Elliott dalga durumunu kaydet
                df['Elliott_Impulse'] = 1 if is_impulse else 0
                
                # Elliott dalgasındaki konum - 0 ila 1 arası normalleştirilmiş değer
                # 0 = başlangıçtayız, 1 = Elliott dalgasının sonundayız
                if is_impulse:
                    total_points = len(last_zz_points)
                    # Son noktanın tarihi ile ilk noktanın tarihi arasında kaç veri noktası var?
                    wave_length = last_zz_points[-1]['date_idx'] - last_zz_points[0]['date_idx']
                    
                    # Şu anki konumumuz
                    current_pos = df.index[-1] - last_zz_points[0]['date_idx']
                    
                    # Dalga içindeki konum - 0 ile 1 arasında
                    if wave_length > 0:
                        df['Elliott_Position'] = min(1.0, max(0.0, current_pos / wave_length))
                    else:
                        df['Elliott_Position'] = 0
                else:
                    df['Elliott_Position'] = 0
                
                # Son ZigZag yönü (1=yukarı, -1=aşağı)
                last_direction = 1 if last_zz_points[-1]['type'] == 'high' else -1
                df['ZigZag_Direction'] = last_direction
            else:
                # Yeterli ZigZag noktası yok
                df['Elliott_Impulse'] = 0
                df['Elliott_Position'] = 0
                df['ZigZag_Direction'] = 0
        except Exception as e:
            # Hata olursa varsayılan değerler
            df['Elliott_Impulse'] = 0
            df['Elliott_Position'] = 0
            df['ZigZag_Direction'] = 0
        
        return df

    def calculate_advanced_indicators(data):
        """Gelişmiş teknik göstergeleri hesaplar"""
        try:
            # Orijinal veriyi kopyala
            df = data.copy()
            
            # 1. Volume Oscillator: Hacim hareketlerinin yönünü belirlemek için kullanılır
            try:
                # Kısa dönem hacim ortalaması (5 gün)
                df['volume_5d'] = df['Volume'].rolling(window=5).mean()
                
                # Uzun dönem hacim ortalaması (20 gün)
                df['volume_20d'] = df['Volume'].rolling(window=20).mean()
                
                # Hacim Osilatörü: Kısa dönem - Uzun dönem
                df['volume_oscillator'] = ((df['volume_5d'] - df['volume_20d']) / df['volume_20d']) * 100
                
                # Log mesajını sadece işlem günlüğüne yaz
                if 'log_expander' in globals():
                    with log_expander:
                        st.info("Hacim osilatörü başarıyla hesaplandı")
            except Exception as e:
                # Hata durumunda log'a kaydet ama UI'da gösterme
                if 'log_expander' in globals():
                    with log_expander:
                        st.error(f"Hacim osilatörü hesaplanırken hata: {str(e)}")
                df['volume_oscillator'] = 0
                
            # 2. Ichimoku Cloud göstergeleri
            try:
                # Tenkan-sen (Conversion Line): (9 günlük yüksek + 9 günlük düşük) / 2
                high_9 = df['High'].rolling(window=9).max()
                low_9 = df['Low'].rolling(window=9).min()
                df['Tenkan_sen'] = (high_9 + low_9) / 2
                
                # Kijun-sen (Base Line): (26 günlük yüksek + 26 günlük düşük) / 2
                high_26 = df['High'].rolling(window=26).max()
                low_26 = df['Low'].rolling(window=26).min()
                df['Kijun_sen'] = (high_26 + low_26) / 2
                
                # Senkou Span A (Leading Span A): (Tenkan-sen + Kijun-sen) / 2
                df['Senkou_span_A'] = ((df['Tenkan_sen'] + df['Kijun_sen']) / 2).shift(26)
                
                # Senkou Span B (Leading Span B): (52 günlük yüksek + 52 günlük düşük) / 2
                high_52 = df['High'].rolling(window=52).max()
                low_52 = df['Low'].rolling(window=52).min()
                df['Senkou_span_B'] = ((high_52 + low_52) / 2).shift(26)
                
                # Chikou Span (Lagging Span): Kapanış 26 gün geriye kaydırılır
                df['Chikou_span'] = df['Close'].shift(-26)
                
                if 'log_expander' in globals():
                    with log_expander:
                        st.info("Ichimoku Cloud göstergeleri başarıyla hesaplandı")
            except Exception as e:
                if 'log_expander' in globals():
                    with log_expander:
                        st.error(f"Ichimoku Cloud göstergeleri hesaplanırken hata: {str(e)}")
            
            # 3. Chaikin Money Flow (CMF)
            try:
                n = 20  # Periyot
                mfv = ((df['Close'] - df['Low']) - (df['High'] - df['Close'])) / (df['High'] - df['Low'])
                mfv = mfv.fillna(0.0)  # Bölme hatası olasılığına karşı
                mfv *= df['Volume']
                df['CMF'] = mfv.rolling(n).sum() / df['Volume'].rolling(n).sum()
                
                if 'log_expander' in globals():
                    with log_expander:
                        st.info("CMF göstergesi başarıyla hesaplandı")
            except Exception as e:
                if 'log_expander' in globals():
                    with log_expander:
                        st.error(f"CMF göstergesi hesaplanırken hata: {str(e)}")
                df['CMF'] = 0
            
            # 4. Williams %R
            try:
                n = 14  # Periyot
                high_max = df['High'].rolling(window=n).max()
                low_min = df['Low'].rolling(window=n).min()
                df['Williams_%R'] = -100 * ((high_max - df['Close']) / (high_max - low_min))
                
                if 'log_expander' in globals():
                    with log_expander:
                        st.info("Williams %R göstergesi başarıyla hesaplandı")
            except Exception as e:
                if 'log_expander' in globals():
                    with log_expander:
                        st.error(f"Williams %R göstergesi hesaplanırken hata: {str(e)}")
                df['Williams_%R'] = 0
            
            # 5. Commodity Channel Index (CCI)
            try:
                n = 20  # Periyot
                typical_price = (df['High'] + df['Low'] + df['Close']) / 3
                mean_typical_price = typical_price.rolling(window=n).mean()
                mean_deviation = np.zeros(len(df))
                
                for i in range(n - 1, len(df)):
                    mean_deviation[i] = np.mean(np.abs(typical_price.iloc[i-n+1:i+1] - mean_typical_price.iloc[i]))
                
                df['CCI'] = (typical_price - mean_typical_price) / (0.015 * pd.Series(mean_deviation))
                
                if 'log_expander' in globals():
                    with log_expander:
                        st.info("CCI göstergesi başarıyla hesaplandı")
            except Exception as e:
                if 'log_expander' in globals():
                    with log_expander:
                        st.error(f"CCI göstergesi hesaplanırken hata: {str(e)}")
                df['CCI'] = 0
            
            # 6. Aroon Oscillator
            try:
                n = 25  # Periyot
                
                # Aroon Up
                aroon_up = np.zeros(len(df))
                for i in range(n, len(df)):
                    period = df['High'].iloc[i-n+1:i+1]
                    aroon_up[i] = ((n - period.argmax() - 1) / n) * 100
                
                # Aroon Down
                aroon_down = np.zeros(len(df))
                for i in range(n, len(df)):
                    period = df['Low'].iloc[i-n+1:i+1]
                    aroon_down[i] = ((n - period.argmin() - 1) / n) * 100
                
                df['Aroon_Up'] = pd.Series(aroon_up)
                df['Aroon_Down'] = pd.Series(aroon_down)
                df['Aroon_Oscillator'] = df['Aroon_Up'] - df['Aroon_Down']
                
                if 'log_expander' in globals():
                    with log_expander:
                        st.info("Aroon Oscillator başarıyla hesaplandı")
            except Exception as e:
                if 'log_expander' in globals():
                    with log_expander:
                        st.error(f"Aroon Oscillator hesaplanırken hata: {str(e)}")
                df['Aroon_Oscillator'] = 0
            
            # 7. Keltner Channels
            try:
                n = 20  # Periyot
                k = 2  # Çarpan
                
                df['EMA20'] = df['Close'].ewm(span=n, adjust=False).mean()
                
                # Eğer TR hesaplanmamışsa hesaplama yapalım
                if 'TR' not in df.columns:
                    df['TR'] = np.maximum(
                        np.maximum(
                            df['High'] - df['Low'],
                            abs(df['High'] - df['Close'].shift(1))
                        ),
                        abs(df['Low'] - df['Close'].shift(1))
                    )
                
                atr = df['TR'].rolling(window=n).mean()  # ATR hesapla
                
                df['Keltner_Upper'] = df['EMA20'] + (k * atr)
                df['Keltner_Lower'] = df['EMA20'] - (k * atr)
                
                if 'log_expander' in globals():
                    with log_expander:
                        st.info("Keltner Channels başarıyla hesaplandı")
            except Exception as e:
                if 'log_expander' in globals():
                    with log_expander:
                        st.error(f"Keltner Channels hesaplanırken hata: {str(e)}")
                # Hata durumunda kolonları ekle
                df['Keltner_Upper'] = df['Close'] 
                df['Keltner_Lower'] = df['Close']
            
            # 8. Donchian Channels
            try:
                n = 20  # Periyot
                df['Donchian_Upper'] = df['High'].rolling(window=n).max()
                df['Donchian_Lower'] = df['Low'].rolling(window=n).min()
                df['Donchian_Middle'] = (df['Donchian_Upper'] + df['Donchian_Lower']) / 2
                
                if 'log_expander' in globals():
                    with log_expander:
                        st.info("Donchian Channels başarıyla hesaplandı")
            except Exception as e:
                if 'log_expander' in globals():
                    with log_expander:
                        st.error(f"Donchian Channels hesaplanırken hata: {str(e)}")
            
            # 9. Parabolic SAR (Stop and Reverse)
            try:
                # Basitleştirilmiş bir PSAR hesaplaması
                acceleration_factor = 0.02
                max_acceleration = 0.2
                sar = np.zeros(len(df))
                trend = np.zeros(len(df))
                ep = np.zeros(len(df))
                
                # İlk değerleri ayarla
                if len(df) > 1:
                    if df['Close'].iloc[1] > df['Close'].iloc[0]:
                        trend[1] = 1  # Yukarı trend
                        sar[1] = df['Low'].iloc[0]
                        ep[1] = df['High'].iloc[1]
                    else:
                        trend[1] = -1  # Aşağı trend
                        sar[1] = df['High'].iloc[0]
                        ep[1] = df['Low'].iloc[1]
                
                # PSAR hesapla
                for i in range(2, len(df)):
                    if trend[i-1] == 1:  # Yukarı trend
                        if df['Low'].iloc[i] < sar[i-1]:
                            trend[i] = -1  # Trend değişimi
                            sar[i] = ep[i-1]
                            ep[i] = df['Low'].iloc[i]
                            acceleration = acceleration_factor
                        else:
                            trend[i] = 1
                            if df['High'].iloc[i] > ep[i-1]:
                                ep[i] = df['High'].iloc[i]
                                acceleration = min(acceleration_factor + acceleration_factor, max_acceleration)
                            else:
                                ep[i] = ep[i-1]
                                acceleration = acceleration_factor
                            sar[i] = sar[i-1] + acceleration * (ep[i-1] - sar[i-1])
                            sar[i] = min(sar[i], df['Low'].iloc[i-1], df['Low'].iloc[i-2] if i > 2 else df['Low'].iloc[i-1])
                    else:  # Aşağı trend
                        if df['High'].iloc[i] > sar[i-1]:
                            trend[i] = 1  # Trend değişimi
                            sar[i] = ep[i-1]
                            ep[i] = df['High'].iloc[i]
                            acceleration = acceleration_factor
                        else:
                            trend[i] = -1
                            if df['Low'].iloc[i] < ep[i-1]:
                                ep[i] = df['Low'].iloc[i]
                                acceleration = min(acceleration_factor + acceleration_factor, max_acceleration)
                            else:
                                ep[i] = ep[i-1]
                                acceleration = acceleration_factor
                            sar[i] = sar[i-1] + acceleration * (ep[i-1] - sar[i-1])
                            sar[i] = max(sar[i], df['High'].iloc[i-1], df['High'].iloc[i-2] if i > 2 else df['High'].iloc[i-1])
                
                df['SAR'] = pd.Series(sar)
                df['SAR_Trend'] = pd.Series(trend)
                
                if 'log_expander' in globals():
                    with log_expander:
                        st.info("Parabolic SAR göstergesi başarıyla hesaplandı")
            except Exception as e:
                if 'log_expander' in globals():
                    with log_expander:
                        st.error(f"Parabolic SAR göstergesi hesaplanırken hata: {str(e)}")
                df['SAR'] = 0
                df['SAR_Trend'] = 0
            
            # 10. Vortex Indicator
            try:
                n = 14  # Periyot
                
                # Eğer TR hesaplanmamışsa hesaplama yapalım
                if 'TR' not in df.columns:
                    df['TR'] = np.maximum(
                        np.maximum(
                            df['High'] - df['Low'],
                            abs(df['High'] - df['Close'].shift(1))
                        ),
                        abs(df['Low'] - df['Close'].shift(1))
                    )
                
                # Pozitif ve Negatif Hareket
                df['VM_plus'] = abs(df['High'] - df['Low'].shift(1))
                df['VM_minus'] = abs(df['Low'] - df['High'].shift(1))
                
                # Vortex Göstergesi
                df['VI_plus'] = df['VM_plus'].rolling(n).sum() / df['TR'].rolling(n).sum()
                df['VI_minus'] = df['VM_minus'].rolling(n).sum() / df['TR'].rolling(n).sum()
                
                if 'log_expander' in globals():
                    with log_expander:
                        st.info("Vortex Indicator başarıyla hesaplandı")
            except Exception as e:
                if 'log_expander' in globals():
                    with log_expander:
                        st.error(f"Vortex Indicator hesaplanırken hata: {str(e)}")
                df['VI_plus'] = 0
                df['VI_minus'] = 0
            
            # 11. TRIX Indicator (Triple Exponential Moving Average)
            try:
                n = 15  # Periyot
                
                ema1 = df['Close'].ewm(span=n, adjust=False).mean()
                ema2 = ema1.ewm(span=n, adjust=False).mean()
                ema3 = ema2.ewm(span=n, adjust=False).mean()
                df['TRIX'] = 100 * (ema3 - ema3.shift(1)) / ema3.shift(1)
                
                if 'log_expander' in globals():
                    with log_expander:
                        st.info("TRIX Indicator başarıyla hesaplandı")
            except Exception as e:
                if 'log_expander' in globals():
                    with log_expander:
                        st.error(f"TRIX Indicator hesaplanırken hata: {str(e)}")
                df['TRIX'] = 0
            
            # 12. DPO (Detrended Price Oscillator)
            try:
                n = 20  # Periyot
                df['DPO'] = df['Close'].shift(n//2 + 1) - df['Close'].rolling(window=n).mean()
                
                if 'log_expander' in globals():
                    with log_expander:
                        st.info("DPO göstergesi başarıyla hesaplandı")
            except Exception as e:
                if 'log_expander' in globals():
                    with log_expander:
                        st.error(f"DPO göstergesi hesaplanırken hata: {str(e)}")
                df['DPO'] = 0
            
            # 13. CMO (Chande Momentum Oscillator)
            try:
                n = 14  # Periyot
                
                close_change = df['Close'].diff()
                up_sum = close_change.where(close_change > 0, 0).rolling(window=n).sum()
                down_sum = -close_change.where(close_change < 0, 0).rolling(window=n).sum()
                
                df['CMO'] = 100 * ((up_sum - down_sum) / (up_sum + down_sum))
                
                if 'log_expander' in globals():
                    with log_expander:
                        st.info("CMO göstergesi başarıyla hesaplandı")
            except Exception as e:
                if 'log_expander' in globals():
                    with log_expander:
                        st.error(f"CMO göstergesi hesaplanırken hata: {str(e)}")
                df['CMO'] = 0
            
            # 14. PVT (Price Volume Trend)
            try:
                close_change_pct = df['Close'].pct_change()
                df['PVT'] = (close_change_pct * df['Volume']).cumsum()
                
                if 'log_expander' in globals():
                    with log_expander:
                        st.info("PVT göstergesi başarıyla hesaplandı")
            except Exception as e:
                if 'log_expander' in globals():
                    with log_expander:
                        st.error(f"PVT göstergesi hesaplanırken hata: {str(e)}")
                df['PVT'] = 0
            
            # 15. Fiyat-Hacim ve Volatilite İlişki Metrikleri
            try:
                # Fiyat-Hacim korelasyonu (20 gün)
                n = 20
                df['Price_Volume_Corr'] = df['Close'].rolling(window=n).corr(df['Volume'])
                
                # Fiyat volatilitesi (20 gün)
                df['Price_Volatility'] = df['Close'].pct_change().rolling(window=n).std() * np.sqrt(n)
                
                # Hacim volatilitesi (20 gün)
                df['Volume_Volatility'] = df['Volume'].pct_change().rolling(window=n).std() * np.sqrt(n)
                
                if 'log_expander' in globals():
                    with log_expander:
                        st.info("Fiyat-Hacim ilişki metrikleri başarıyla hesaplandı")
            except Exception as e:
                if 'log_expander' in globals():
                    with log_expander:
                        st.error(f"Fiyat-Hacim ilişki metrikleri hesaplanırken hata: {str(e)}")
                df['Price_Volume_Corr'] = 0
                df['Price_Volatility'] = 0
                df['Volume_Volatility'] = 0
            
            # 16. Fibonacci Retracement Seviyeleri
            try:
                # Son 50 gün için yüksek ve düşük noktaları bul
                period = 50
                if len(df) >= period:
                    recent_high = df['High'].iloc[-period:].max()
                    recent_low = df['Low'].iloc[-period:].min()
                    
                    # Fibonacci seviyeleri
                    df['Fib_38.2'] = recent_high - (recent_high - recent_low) * 0.382
                    df['Fib_50'] = recent_high - (recent_high - recent_low) * 0.5
                    df['Fib_61.8'] = recent_high - (recent_high - recent_low) * 0.618
                    
                    if 'log_expander' in globals():
                        with log_expander:
                            st.info("Fibonacci Retracement seviyeleri başarıyla hesaplandı")
                else:
                    df['Fib_38.2'] = df['Close']
                    df['Fib_50'] = df['Close']
                    df['Fib_61.8'] = df['Close']
            except Exception as e:
                if 'log_expander' in globals():
                    with log_expander:
                        st.error(f"Fibonacci Retracement seviyeleri hesaplanırken hata: {str(e)}")
                df['Fib_38.2'] = 0
                df['Fib_50'] = 0
                df['Fib_61.8'] = 0
            
            # NaN değerleri temizle veya doldur
            for col in df.columns:
                if col not in data.columns and col in df.columns:
                    if df[col].isnull().any():
                        df[col] = df[col].fillna(0)
            
            return df

        except Exception as e:
            if 'log_expander' in globals():
                with log_expander:
                    st.error(f"Gelişmiş teknik göstergeler hesaplanırken genel hata: {str(e)}")
            return data

    def add_sentiment_data(df, symbol):
        """ Hisse senedi verilerine duyarlılık analizi sonuçlarını ekler """
        if not use_sentiment_analysis:
            df['Gemini_Sentiment'] = 0.0 
            return df, True  # Duyarlılık analizi kullanılmadığında bile başarıyla eklenmiş olarak işaretliyoruz
            
        with log_expander:
            st.info(f"--> [{symbol}] Duyarlılık Analizi Başlatılıyor...")
            st.info(f"----> [{symbol}] Haber verileri alınıyor...")
        
        sentiment_added_successfully = False
        df['Gemini_Sentiment'] = np.nan 

        try:
            # Haber verilerini al
            try:
                # Haber alınırken oluşan detaylı logları log_expander içinde tut
                news_capture = io.StringIO()
                with redirect_stdout(news_capture):
                    news_items_list = get_stock_news(symbol, news_period="1w", max_results=5)
                
                # Haber alınırken oluşan detaylı logları sadece log_expander içinde göster
                news_logs = news_capture.getvalue()
                if news_logs.strip():
                    with log_expander:
                        st.text(news_logs)
                
                with log_expander:
                    if news_items_list:
                        st.success(f"----> [{symbol}] {len(news_items_list)} adet haber bulundu.")
                    else:
                        st.warning(f"----> [{symbol}] Haber bulunamadı.")
            except Exception as news_e:
                with log_expander:
                    st.error(f"----> [{symbol}] Haber alınırken hata: {str(news_e)}")
                news_items_list = []

            # Varsayılan nötr skor
            sentiment_skoru = 50 

            if news_items_list:
                # Haberleri analiz et
                sentiments = []
                
                with log_expander:
                    st.info(f"----> [{symbol}] Haberler analiz ediliyor...")
                
                # Farklı analiz yöntemlerini deneme sayaçları
                successful_analyses = 0
                failed_analyses = 0
                
                # Haberler modülünü ve SentimentAnalyzer'ı yükle
                try:
                    # İlk olarak SentimentAnalyzer'ı yüklemeyi dene
                    from ai.sentiment_analysis import SentimentAnalyzer
                    sentiment_analyzer = SentimentAnalyzer()
                    sentiment_analyzer_available = True
                    with log_expander:
                        st.success(f"-----> Yedek analiz modeli başarıyla yüklendi: {os.path.join(os.getcwd(), 'ai', 'sentiment_model.pkl')}")
                except Exception as sa_error:
                    sentiment_analyzer_available = False
                    with log_expander:
                        st.error(f"-----> Analiz modeli yüklenemedi: {str(sa_error)}")
                
                # Haberler modülünden fonksiyonları import et
                try:
                    from ui.improved_news_tab import (
                        analyze_news, 
                        get_sentiment_explanation, 
                        simple_sentiment_analysis
                    )
                    news_analyzer_available = True
                    with log_expander:
                        st.success(f"-----> Haberler modülü analiz fonksiyonu başarıyla yüklendi")
                except Exception as news_tab_error:
                    news_analyzer_available = False
                    with log_expander:
                        st.error(f"-----> Haberler modülü analiz fonksiyonu yüklenemedi: {str(news_tab_error)}")
                
                # Her bir haberi analiz et
                for item in news_items_list:
                    try:
                        # URL kontrolü
                        item_url = item.get('url') or item.get('link')
                        if not item_url:
                            with log_expander:
                                st.warning(f"-----> Geçerli URL bulunamadı, atlanıyor...")
                            continue
                            
                        with log_expander:
                            st.info(f"-----> Haber analiz ediliyor: {item.get('title', 'Başlık Yok')}")
                        
                        # Başlık ve içerik metnini hazırla - bunlar her durumda kullanılacak
                        title = item.get('title', '')
                        description = item.get('description', '') or item.get('summary', '') or item.get('desc', '')
                        analysis_text = f"{title} {description}"
                        
                        # Yöntem 1: Basit kelime tabanlı analiz (her durumda çalışacak)
                        sentiment_score = 0.5  # Nötr varsayılan değer
                        sentiment_label = "Nötr"
                        
                        if news_analyzer_available:
                            try:
                                # Finans haberlerine özel gelişmiş kelime tabanlı analiz
                                # Olumlu ve olumsuz kelimeler
                                positive_words = [
                                    # Genel olumlu terimler
                                    "artış", "yükseldi", "yükseliş", "kazanç", "başarı", "olumlu", "güçlü", 
                                    "kar", "büyüme", "yatırım", "fırsat", "rekor", "güven", "avantaj",
                                    # Hisse senedi ve finans ile ilgili olumlu terimler
                                    "alım", "geri alım", "pay geri alım", "hedef fiyat", "yukarı yönlü", "artırıldı", 
                                    "yükseltildi", "ivme", "güçleniyor", "zirve", "tavan", "prim", "aşırı alım", 
                                    "güçlü performans", "kârlılık", "temettü", "beklentilerin üzerinde", "kapasite artışı",
                                    "lider", "pazar payı", "büyüdü", "arttı", "genişleme", "ihracat", "yeni anlaşma",
                                    "ortaklık", "işbirliği", "strateji", "dijitalleşme", "teknoloji", "dev", "program",
                                    "iş hacmi", "rağbet", "talep", "ihale", "kazandı", "başarıyla", "gelir artışı"
                                ]
                                
                                negative_words = [
                                    # Genel olumsuz terimler
                                    "düşüş", "geriledi", "azaldı", "zarar", "kayıp", "olumsuz", "zayıf", 
                                    "risk", "endişe", "kriz", "tehlike", "yavaşlama", "dezavantaj",
                                    # Hisse senedi ve finans ile ilgili olumsuz terimler
                                    "satış baskısı", "değer kaybı", "daraldı", "daralma", "borç", "iflas", "konkordato",
                                    "aşağı yönlü", "indirildi", "düşürüldü", "aşırı satım", "volatilite", "zayıf performans",
                                    "beklentilerin altında", "ertelendi", "iptal", "durgunluk", "negatif", "dibe", "dip",
                                    "indirim", "faiz artışı", "vergi", "ceza", "yaptırım", "manipülasyon", "soruşturma",
                                    "dava", "para cezası", "şikayet", "protesto", "grev", "maliyet artışı", "fire"
                                ]
                                
                                # Metin özel durumları ele al - finans haberlerinde bazı ifadeler özel anlam taşır
                                special_cases = [
                                    {"phrase": "pay geri alım", "score": 1.0},
                                    {"phrase": "hisse geri alım", "score": 1.0},
                                    {"phrase": "hedef fiyat", "score": 0.8},
                                    {"phrase": "tavan fiyat", "score": 0.7},
                                    {"phrase": "ek sefer", "score": 0.7},
                                    {"phrase": "yatırım tavsiyesi", "score": 0.6},
                                    {"phrase": "al tavsiyesi", "score": 0.9},
                                    {"phrase": "tut tavsiyesi", "score": 0.6},
                                    {"phrase": "sat tavsiyesi", "score": 0.2}
                                ]
                                
                                # Hisse özel durumları kontrol et
                                if symbol in analysis_text:
                                    with log_expander:
                                        st.info(f"-----> Hisse kodu ({symbol}) içerikte geçiyor. Faydalı bir haber olabilir.")
                                
                                # Özel durumları kontrol et
                                special_score = None
                                for case in special_cases:
                                    if case["phrase"].lower() in analysis_text.lower():
                                        special_score = case["score"]
                                        with log_expander:
                                            st.success(f"-----> Özel durum tespit edildi: '{case['phrase']}', skor: {special_score}")
                                        break
                                
                                # Eğer özel durum varsa, doğrudan skoru ata
                                if special_score is not None:
                                    sentiment_score = special_score
                                    sentiment_label = "POSITIVE" if sentiment_score > 0.5 else ("NEUTRAL" if sentiment_score == 0.5 else "NEGATIVE")
                                else:
                                    # Kelime sayaçları
                                    positive_count = sum(1 for word in positive_words if word.lower() in analysis_text.lower())
                                    negative_count = sum(1 for word in negative_words if word.lower() in analysis_text.lower())
                                    
                                    # Duygu skoru hesapla (0 ile 1 arasında)
                                    total = positive_count + negative_count
                                    if total > 0:
                                        # Pozitif sayısı ağırlıklıysa skoru yükselt
                                        sentiment_score = positive_count / (positive_count + negative_count)
                                        with log_expander:
                                            st.info(f"-----> Olumlu kelime sayısı: {positive_count}, Olumsuz kelime sayısı: {negative_count}")
                                    else:
                                        sentiment_score = 0.5  # Nötr değer
                                    
                                    # Etiket belirle
                                    if sentiment_score > 0.6:
                                        sentiment_label = "POSITIVE"
                                    elif sentiment_score < 0.4:
                                        sentiment_label = "NEGATIVE"
                                    else:
                                        sentiment_label = "NEUTRAL"
                                
                                with log_expander:
                                    sentiment_text = "Olumlu" if sentiment_label == "POSITIVE" else ("Olumsuz" if sentiment_label == "NEGATIVE" else "Nötr")
                                    st.success(f"-----> Gelişmiş kelime analizi sonucu: {sentiment_text} ({sentiment_score:.2f})")
                                
                                sentiments.append(sentiment_score)
                                successful_analyses += 1
                                continue
                            except Exception as advanced_analysis_error:
                                with log_expander:
                                    st.warning(f"-----> Gelişmiş kelime analizi hatası: {str(advanced_analysis_error)}")
                                
                                # Hata durumunda basit kelime analizi ile devam et
                                try:
                                    # Basit kelime tabanlı duyarlılık analizi
                                    simple_result = simple_sentiment_analysis(analysis_text)
                                    sentiment_score = simple_result.get("score", 0.5)
                                    sentiment_label = simple_result.get("label", "NEUTRAL")
                                    
                                    with log_expander:
                                        sentiment_text = "Olumlu" if sentiment_label == "POSITIVE" else ("Olumsuz" if sentiment_label == "NEGATIVE" else "Nötr")
                                        st.info(f"-----> Basit analiz sonucu: {sentiment_text} ({sentiment_score:.2f})")
                                    
                                    # Skorun 0-1 aralığında olduğundan emin ol
                                    if sentiment_score < 0:
                                        sentiment_score = 0
                                    elif sentiment_score > 1:
                                        sentiment_score = 1
                                        
                                    sentiments.append(sentiment_score)
                                    successful_analyses += 1
                                    continue
                                except Exception as simple_error:
                                    with log_expander:
                                        st.warning(f"-----> Basit analiz hatası: {str(simple_error)}")
                        
                        # Yöntem 2: SentimentAnalyzer kullan
                        if sentiment_analyzer_available:
                            try:
                                # Metni analiz et
                                with log_expander:
                                    st.info(f"-----> Scikit-learn modeli ile analiz ediliyor...")
                                
                                if analysis_text and len(analysis_text.strip()) > 10:
                                    # Duyarlılık skorunu hesapla
                                    prediction = sentiment_analyzer.predict([analysis_text])[0]
                                    probabilities = sentiment_analyzer.predict_proba([analysis_text])[0]
                                    
                                    # 0 (negatif) veya 1 (pozitif) - label'a dönüştür
                                    label = "POSITIVE" if prediction == 1 else "NEGATIVE"
                                    
                                    # Skoru normalize et
                                    score = (probabilities[1] if len(probabilities) > 1 else 0.5)
                                    
                                    with log_expander:
                                        sentiment_text = "Olumlu" if score > 0.65 else ("Olumsuz" if score < 0.35 else "Nötr")
                                        st.success(f"-----> Scikit-learn analiz sonucu: {sentiment_text} ({score:.2f})")
                                        if 'get_sentiment_explanation' in locals():
                                            st.info(f"-----> {get_sentiment_explanation(score)}")
                                    
                                    sentiments.append(score)
                                    successful_analyses += 1
                                    continue
                                else:
                                    with log_expander:
                                        st.warning(f"-----> Analiz metni çok kısa, atlanıyor...")
                            except Exception as model_error:
                                with log_expander:
                                    st.warning(f"-----> Scikit-learn model hatası: {str(model_error)}")
                        
                        # Varsayılan nötr değer
                        with log_expander:
                            st.info(f"-----> Başarısız analizler için varsayılan nötr değer (0.5) kullanılıyor...")
                        sentiments.append(0.5)
                        successful_analyses += 1
                        
                    except Exception as item_error:
                        failed_analyses += 1
                        with log_expander:
                            st.error(f"-----> Haber analiz etme hatası: {str(item_error)}")
                
                # Analiz edilmiş haber var mı?
                if sentiments:
                    # Başarılı ve başarısız analiz sayılarını logla
                    with log_expander:
                        st.info(f"----> [{symbol}] Toplam {len(news_items_list)} haberden {successful_analyses} adedi başarıyla analiz edildi, {failed_analyses} adedi başarısız.")
                    
                    # Ortalama duyarlılık skorunu hesapla
                    avg_sentiment = sum(sentiments) / len(sentiments)
                    
                    # 0-1 aralığındaki skoru -1 ile 1 arasına dönüştür
                    normalized_sentiment = (avg_sentiment - 0.5) * 2
                    
                    with log_expander:
                        sentiment_str = "Olumlu" if avg_sentiment > 0.65 else ("Olumsuz" if avg_sentiment < 0.35 else "Nötr")
                        st.success(f"----> [{symbol}] Ortalama Duyarlılık: {sentiment_str} ({avg_sentiment:.2f})")
                        st.info(f"----> [{symbol}] Normalize Edilmiş Skor: {normalized_sentiment:.2f}")
                    
                    # Son N güne skoru ata
                    n_days = 5
                    if len(df) >= n_days:
                        df.iloc[-n_days:, df.columns.get_loc('Gemini_Sentiment')] = normalized_sentiment
                    elif len(df) > 0:
                        df['Gemini_Sentiment'] = normalized_sentiment
                    
                    sentiment_added_successfully = True
                else:
                    with log_expander:
                        st.warning(f"----> [{symbol}] Hiçbir haber analiz edilemedi, nötr skor kullanılıyor.")
                    normalized_sentiment = 0.0
                    df['Gemini_Sentiment'] = normalized_sentiment
                    sentiment_added_successfully = True  # Nötr skor eklendiğinde de başarılı sayılsın
            else:
                with log_expander:
                    st.info(f"----> [{symbol}] Haber bulunmadığı için nötr skor (0) kullanılıyor.")
                normalized_sentiment = 0.0
                df['Gemini_Sentiment'] = normalized_sentiment
                sentiment_added_successfully = True  # Haber yoksa ve nötr skor eklendiğinde de başarılı sayılsın

            # NaN değerleri doldur
            df['Gemini_Sentiment'].fillna(method='ffill', inplace=True)
            df['Gemini_Sentiment'].fillna(0, inplace=True)
            
            with log_expander:
                st.success(f"--> [{symbol}] Duyarlılık Analizi Tamamlandı.")
            return df, sentiment_added_successfully

        # Ana try bloğu için except bloğu
        except Exception as e:
            with log_expander:
                st.error(f"--> [{symbol}] Duyarlılık analizi genel hatası: {str(e)}")
                st.code(traceback.format_exc())
            df['Gemini_Sentiment'] = 0.0
            return df, True  # Hata durumunda bile 0 değeri eklenmiş olduğu için True dönelim

    # YENİ: Makroekonomik ve sektörel veri ekleme fonksiyonu
    def add_macro_sector_data(df, symbol):
        """
        Makroekonomik göstergeleri (döviz, faiz, enflasyon) ve sektörel korelasyonları ekler
        
        Parametreler:
        df (DataFrame): İşlenecek veri seti
        symbol (str): Hisse kodu
        
        Dönüş:
        DataFrame: Makroekonomik ve sektörel özellikler eklenmiş veri seti
        """
        try:
            if 'log_expander' in globals() and log_expander is not None:
                with log_expander:
                    st.info(f"--> [{symbol}] Makroekonomik ve Sektörel veri ekleniyor...")
            
            # 1. Dolar/TL Kuru
            try:
                usdtry_data = get_stock_data_cached("USDTRY=X", period="5y", interval="1d")
                if usdtry_data is not None and not usdtry_data.empty:
                    # Tarih indekslerini eşleştirme
                    common_idx = df.index.intersection(usdtry_data.index)
                    if len(common_idx) > 0:
                        usd_aligned = usdtry_data.loc[common_idx]['Close']
                        
                        # Döviz kuru değişim yüzdeleri
                        df['USDTRY'] = usd_aligned
                        df['USDTRY_Change'] = usd_aligned.pct_change()
                        df['USDTRY_Change_5d'] = usd_aligned.pct_change(5)
                        df['USDTRY_Change_20d'] = usd_aligned.pct_change(20)
                        
                        # Hisse/Döviz korelasyonu (20 günlük)
                        rolling_corr = df['Close'].rolling(window=20).corr(df['USDTRY'])
                        df['USD_Correlation'] = rolling_corr
                        
                        # Pozitif korelasyon
                        df['Is_USD_Positive_Corr'] = np.where(rolling_corr > 0.5, 1, 0)
                        
                        # Negatif korelasyon
                        df['Is_USD_Negative_Corr'] = np.where(rolling_corr < -0.5, 1, 0)
                        
                        if 'log_expander' in globals() and log_expander is not None:
                            with log_expander:
                                st.success(f"---> [{symbol}] USDTRY verisi eklendi.")
                    else:
                        if 'log_expander' in globals() and log_expander is not None:
                            with log_expander:
                                st.warning(f"---> [{symbol}] USDTRY ile kesişen veri bulunamadı.")
                else:
                    if 'log_expander' in globals() and log_expander is not None:
                        with log_expander:
                            st.warning(f"---> [{symbol}] USDTRY verisi alınamadı.")
            except Exception as e:
                if 'log_expander' in globals() and log_expander is not None:
                    with log_expander:
                        st.error(f"---> [{symbol}] USDTRY verisi eklenirken hata: {str(e)}")
                
                # Default değerler ekle
                df['USDTRY'] = 0
                df['USDTRY_Change'] = 0
                df['USDTRY_Change_5d'] = 0
                df['USDTRY_Change_20d'] = 0
                df['USD_Correlation'] = 0
                df['Is_USD_Positive_Corr'] = 0
                df['Is_USD_Negative_Corr'] = 0
            
            # 2. Euro/TL Kuru
            try:
                eurtry_data = get_stock_data_cached("EURTRY=X", period="5y", interval="1d")
                if eurtry_data is not None and not eurtry_data.empty:
                    # Tarih indekslerini eşleştirme
                    common_idx = df.index.intersection(eurtry_data.index)
                    if len(common_idx) > 0:
                        eur_aligned = eurtry_data.loc[common_idx]['Close']
                        
                        # Döviz kuru değişim yüzdeleri
                        df['EURTRY'] = eur_aligned
                        df['EURTRY_Change'] = eur_aligned.pct_change()
                        
                        # Hisse/Euro korelasyonu (20 günlük)
                        rolling_corr = df['Close'].rolling(window=20).corr(df['EURTRY'])
                        df['EUR_Correlation'] = rolling_corr
                        
                        if 'log_expander' in globals() and log_expander is not None:
                            with log_expander:
                                st.success(f"---> [{symbol}] EURTRY verisi eklendi.")
                    else:
                        if 'log_expander' in globals() and log_expander is not None:
                            with log_expander:
                                st.warning(f"---> [{symbol}] EURTRY ile kesişen veri bulunamadı.")
                else:
                    if 'log_expander' in globals() and log_expander is not None:
                        with log_expander:
                            st.warning(f"---> [{symbol}] EURTRY verisi alınamadı.")
            except Exception as e:
                if 'log_expander' in globals() and log_expander is not None:
                    with log_expander:
                        st.error(f"---> [{symbol}] EURTRY verisi eklenirken hata: {str(e)}")
                
                # Default değerler ekle
                df['EURTRY'] = 0
                df['EURTRY_Change'] = 0
                df['EUR_Correlation'] = 0
            
            # 3. BIST Sektör Endeksleri
            sector_indices = {
                # Ana sektör endeksleri
                'XBANK': 'Banka',
                'XUSIN': 'Sanayi',
                'XHOLD': 'Holding',
                'XGIDA': 'Gıda',
                'XTEKS': 'Tekstil',
                'XULAS': 'Ulaştırma',
                'XTCRT': 'Ticaret',
                'XTRZM': 'Turizm',
                'XILTM': 'İletişim',
                'XELKT': 'Elektrik',
                'XMANA': 'Madencilik',
                'XINSA': 'İnşaat'
            }
            
            # Sektör İlişkisi ve Korelasyon
            max_correlation = 0
            related_sector = None
            
            # Her hisse için sektör belirle
            stock_sector = None
            
            # Sektör tahmini
            if symbol.startswith("GAR") or symbol.startswith("AKB") or symbol.startswith("YKB") or symbol.startswith("HALK") or symbol.startswith("VAKB") or symbol.startswith("ISCTR"):
                stock_sector = "XBANK"
            elif symbol in ["THYAO", "PGSUS"]:
                stock_sector = "XULAS"
            elif symbol in ["MGROS", "BIMAS", "SOKM"]:
                stock_sector = "XTCRT"
            elif symbol in ["TAVHL", "MAVI"]:
                stock_sector = "XTRZM"
            elif symbol in ["TCELL", "TTKOM"]:
                stock_sector = "XILTM"
            elif symbol in ["TOASO", "FROTO", "KARSN", "OTKAR"]:
                stock_sector = "XUSIN"  # Otomotiv
            elif symbol in ["KCHOL", "SAHOL", "DOHOL"]:
                stock_sector = "XHOLD"
            
            # Her sektör endeksi için veri al ve korelasyon hesapla
            for index_code, sector_name in sector_indices.items():
                try:
                    index_data = get_stock_data_cached(f"{index_code}.IS", period="5y", interval="1d")
                    if index_data is not None and not index_data.empty:
                        # Tarih indekslerini eşleştirme
                        common_idx = df.index.intersection(index_data.index)
                        if len(common_idx) > 10:  # En az 10 günlük ortak veri olmalı
                            stock_prices = df.loc[common_idx]['Close']
                            index_prices = index_data.loc[common_idx]['Close']
                            
                            # 20 günlük korelasyon
                            corr_20d = stock_prices.rolling(window=20).corr(index_prices)
                            
                            # 60 günlük korelasyon
                            corr_60d = stock_prices.rolling(window=60).corr(index_prices)
                            
                            # Son korelasyon (tüm veri)
                            overall_corr = stock_prices.corr(index_prices)
                            
                            # En yüksek korelasyona sahip sektörü belirle
                            if abs(overall_corr) > abs(max_correlation):
                                max_correlation = overall_corr
                                related_sector = index_code
                            
                            # Korelasyon sütunları ekle
                            df[f'{index_code}_Corr_20d'] = corr_20d
                            df[f'{index_code}_Corr_60d'] = corr_60d
                            
                            # Son değişimleri ekle
                            df[f'{index_code}_Change_1d'] = index_prices.pct_change()
                            df[f'{index_code}_Change_5d'] = index_prices.pct_change(5)
                            
                            # Hissenin kendi sektörü ise daha fazla analiz
                            if index_code == stock_sector:
                                # Hissenin sektör performansına göre durumu (1=daha iyi, -1=daha kötü)
                                stock_perf = df.loc[common_idx]['Close'].pct_change(5).iloc[-1] if len(common_idx) > 5 else 0
                                sector_perf = index_prices.pct_change(5).iloc[-1] if len(common_idx) > 5 else 0
                                
                                df['Sector_Outperformance'] = 1 if stock_perf > sector_perf else (-1 if stock_perf < sector_perf else 0)
                                df['Sector_Outperformance_Ratio'] = stock_perf / sector_perf if sector_perf != 0 else 0
                            
                            if 'log_expander' in globals() and log_expander is not None:
                                with log_expander:
                                    st.success(f"---> [{symbol}] {index_code} sektör verisi eklendi. Korelasyon: {overall_corr:.3f}")
                        else:
                            if 'log_expander' in globals() and log_expander is not None:
                                with log_expander:
                                    st.warning(f"---> [{symbol}] {index_code} ile yeterli kesişen veri bulunamadı.")
                    else:
                        if 'log_expander' in globals() and log_expander is not None:
                            with log_expander:
                                st.warning(f"---> [{symbol}] {index_code} verisi alınamadı.")
                
                except Exception as e:
                    if 'log_expander' in globals() and log_expander is not None:
                        with log_expander:
                            st.error(f"---> [{symbol}] {index_code} sektör verisi eklenirken hata: {str(e)}")
            
            # En yüksek korelasyonlu sektörü kaydet
            if related_sector:
                df['Most_Correlated_Sector'] = related_sector
                df['Sector_Correlation'] = max_correlation
                
                if 'log_expander' in globals() and log_expander is not None:
                    with log_expander:
                        st.info(f"---> [{symbol}] En yüksek korelasyonlu sektör: {related_sector} ({max_correlation:.3f})")
            else:
                df['Most_Correlated_Sector'] = "Unknown"
                df['Sector_Correlation'] = 0
            
            # Sektör belirlenebilmişse ekstra özellikler ekle
            if stock_sector:
                df['Stock_Sector'] = stock_sector
                
                # Sektör ile hisse eşleşiyorsa 1, değilse 0
                df['Is_Sector_Match'] = 1 if stock_sector == related_sector else 0
                
                if 'log_expander' in globals() and log_expander is not None:
                    with log_expander:
                        st.info(f"---> [{symbol}] Hisse sektörü: {stock_sector}")
            else:
                df['Stock_Sector'] = "Unknown"
                df['Is_Sector_Match'] = 0
            
            # 4. BIST 30, 50, 100 ve Genel Endeksler Korelasyonu
            try:
                for main_index in ['XU030.IS', 'XU050.IS', 'XU100.IS', 'XUTUM.IS']:
                    index_name = main_index.replace('.IS', '')
                    index_data = get_stock_data_cached(main_index, period="5y", interval="1d")
                    
                    if index_data is not None and not index_data.empty:
                        # Tarih indekslerini eşleştirme
                        common_idx = df.index.intersection(index_data.index)
                        if len(common_idx) > 10:
                            stock_prices = df.loc[common_idx]['Close']
                            index_prices = index_data.loc[common_idx]['Close']
                            
                            # Korelasyon hesapla
                            corr_20d = stock_prices.rolling(window=20).corr(index_prices)
                            corr_60d = stock_prices.rolling(window=60).corr(index_prices)
                            
                            # Beta hesapla (60 günlük pencerede)
                            index_return = index_prices.pct_change().dropna()
                            stock_return = stock_prices.pct_change().dropna()
                            
                            # Kesişen indeksler
                            beta_idx = index_return.index.intersection(stock_return.index)
                            if len(beta_idx) > 30:
                                aligned_index_return = index_return.loc[beta_idx]
                                aligned_stock_return = stock_return.loc[beta_idx]
                                
                                # 60 günlük pencerede beta hesapla
                                rolling_cov = aligned_stock_return.rolling(window=60).cov(aligned_index_return)
                                rolling_var = aligned_index_return.rolling(window=60).var()
                                beta = rolling_cov / rolling_var
                                
                                # Dataframe'e ekle
                                beta_series = pd.Series(0, index=df.index)  # Tüm indeksleri kapsayan seri
                                beta_series.loc[beta.index] = beta  # Hesaplanmış değerleri yerleştir
                                df[f'{index_name}_Beta'] = beta_series
                            
                            # Dataframe'e ekle
                            df[f'{index_name}_Corr_20d'] = corr_20d
                            df[f'{index_name}_Corr_60d'] = corr_60d
                            
                            # Son değişimleri ekle
                            df[f'{index_name}_Change_1d'] = index_prices.pct_change()
                            df[f'{index_name}_Change_5d'] = index_prices.pct_change(5)
                            
                            if 'log_expander' in globals() and log_expander is not None:
                                with log_expander:
                                    st.success(f"---> [{symbol}] {index_name} endeks verisi eklendi.")
                        else:
                            if 'log_expander' in globals() and log_expander is not None:
                                with log_expander:
                                    st.warning(f"---> [{symbol}] {index_name} ile yeterli kesişen veri bulunamadı.")
                    else:
                        if 'log_expander' in globals() and log_expander is not None:
                            with log_expander:
                                st.warning(f"---> [{symbol}] {index_name} verisi alınamadı.")
            except Exception as e:
                if 'log_expander' in globals() and log_expander is not None:
                    with log_expander:
                        st.error(f"---> [{symbol}] Ana endeks verileri eklenirken hata: {str(e)}")
            
            # 5. CDS (Ülke Risk Primi) - varsayılan değerler ekle, gerçek veri için dış kaynak gerekebilir
            # Not: Bu veriyi almak için doğrudan API olmadığından basitleştirilmiş bir yaklaşım kullanabiliriz
            # Gerçek uygulamada bu veri dış API'lerden veya CSV dosyalarından alınabilir
            # Şimdilik tüm günler için sabit bir değer atayalım
            df['TR_CDS'] = 300  # Örnek değer, gerçek uygulamada güncel değer kullanılmalı
            
            # 6. Faiz Oranları - varsayılan değerler ekle, gerçek veri için dış kaynak gerekebilir
            # Not: TCMB ve tahvil faizlerini almak için özel API'ler kullanılabilir
            # Şimdilik tüm günler için sabit değerler atayalım
            df['TCMB_Policy_Rate'] = 25  # Örnek değer, gerçek uygulamada güncel değer kullanılmalı
            df['TR_2Y_Bond_Yield'] = 30  # Örnek değer, gerçek uygulamada güncel değer kullanılmalı
            df['TR_10Y_Bond_Yield'] = 27  # Örnek değer, gerçek uygulamada güncel değer kullanılmalı
            
            # 7. Enflasyon - varsayılan değerler ekle, gerçek veri için dış kaynak gerekebilir
            # Not: Enflasyon değerleri genellikle aylık açıklanır, günlük veri olarak kullanmak için interpolasyon yapılabilir
            # Şimdilik tüm günler için sabit bir değer atayalım
            df['TUFE_YoY'] = 60  # Örnek değer, gerçek uygulamada güncel değer kullanılmalı
            df['UID_YoY'] = 70  # Örnek değer, gerçek uygulamada güncel değer kullanılmalı
            
            # Tarihe bağlı değişim için: Gerçek uygulamada tarih bazlı veri ekle
            # df['TUFE_YoY'] = df.index.map(lambda x: {
            #    pd.Timestamp('2023-01-01'): 60,
            #    pd.Timestamp('2023-02-01'): 62,
            #    # ... diğer tarihler
            # }.get(pd.Timestamp(x.year, x.month, 1), 60))
            
            # 8. Rakip Şirketler veya Korelasyon Analizi
            # Sektöre bağlı olarak rakip şirketleri belirle
            competitors = []
            
            if stock_sector == "XBANK":
                competitors = ["GARAN.IS", "AKBNK.IS", "YKBNK.IS", "HALKB.IS", "VAKBN.IS", "ISCTR.IS"]
            elif stock_sector == "XULAS":
                competitors = ["THYAO.IS", "PGSUS.IS"]
            elif stock_sector == "XTCRT":
                competitors = ["MGROS.IS", "BIMAS.IS", "SOKM.IS"]
            
            # Hisse kendisi hariç rakipleri filtrele
            competitors = [comp for comp in competitors if comp != f"{symbol}"]
            
            if competitors:
                # Rakiplerin ortalama performansını hesapla
                comp_returns = pd.DataFrame(index=df.index)
                
                for comp in competitors[:3]:  # En fazla 3 rakip
                    try:
                        comp_data = get_stock_data_cached(comp, period="2y", interval="1d")
                        if comp_data is not None and not comp_data.empty:
                            # Tarih indekslerini eşleştirme
                            common_idx = df.index.intersection(comp_data.index)
                            if len(common_idx) > 10:
                                comp_close = comp_data.loc[common_idx]['Close']
                                comp_return = comp_close.pct_change()
                                comp_returns[comp] = comp_return
                                
                                # Rakip korelasyonu
                                corr = df.loc[common_idx]['Close'].pct_change().corr(comp_return)
                                df[f'{comp.replace(".IS", "")}_Corr'] = corr
                                
                                # Son dönem performans farkı (5 gün)
                                if len(common_idx) > 5:
                                    stock_5d_return = df.loc[common_idx]['Close'].pct_change(5).iloc[-1]
                                    comp_5d_return = comp_close.pct_change(5).iloc[-1]
                                    df[f'{comp.replace(".IS", "")}_Perf_Diff'] = stock_5d_return - comp_5d_return
                                
                                if 'log_expander' in globals() and log_expander is not None:
                                    with log_expander:
                                        st.success(f"---> [{symbol}] {comp} rakip verisi eklendi. Korelasyon: {corr:.3f}")
                            else:
                                if 'log_expander' in globals() and log_expander is not None:
                                    with log_expander:
                                        st.warning(f"---> [{symbol}] {comp} ile yeterli kesişen veri bulunamadı.")
                        else:
                            if 'log_expander' in globals() and log_expander is not None:
                                with log_expander:
                                    st.warning(f"---> [{symbol}] {comp} verisi alınamadı.")
                    
                    except Exception as e:
                        if 'log_expander' in globals() and log_expander is not None:
                            with log_expander:
                                st.error(f"---> [{symbol}] {comp} rakip verisi eklenirken hata: {str(e)}")
                
                # Rakiplerin ortalama performansı
                if not comp_returns.empty:
                    avg_comp_return = comp_returns.mean(axis=1)
                    df['Competitors_Avg_Return'] = avg_comp_return
                    
                    # Rakiplere göre performans (1=daha iyi, -1=daha kötü)
                    avg_5d_comp_return = avg_comp_return.rolling(window=5).mean().iloc[-1] if len(avg_comp_return) > 5 else 0
                    stock_5d_return = df['Close'].pct_change(5).iloc[-1] if len(df) > 5 else 0
                    
                    df['Competitors_Outperformance'] = 1 if stock_5d_return > avg_5d_comp_return else (-1 if stock_5d_return < avg_5d_comp_return else 0)
                    df['Competitors_Outperformance_Ratio'] = stock_5d_return / avg_5d_comp_return if avg_5d_comp_return != 0 else 0
            
            # Tüm NaN değerleri temizle
            numeric_cols = df.select_dtypes(include=['float64', 'int64']).columns
            for col in numeric_cols:
                if df[col].isnull().any():
                    df[col] = df[col].fillna(0)
            
            if 'log_expander' in globals() and log_expander is not None:
                with log_expander:
                    st.success(f"--> [{symbol}] Makroekonomik ve Sektörel veri ekleme tamamlandı.")
            
            return df
        
        except Exception as e:
            if 'log_expander' in globals() and log_expander is not None:
                with log_expander:
                    st.error(f"--> [{symbol}] Makroekonomik ve Sektörel veri eklenirken genel hata: {str(e)}")
                st.error(traceback.format_exc())
            
            # Hata durumunda orijinal veriyi döndür
            return df

    # --- Tarama Mantığı ---
    if st.button("Tarama Başlat", type="primary", use_container_width=True, key="ml_start_scan"):
        # Butona basıldığını logla
        # İşlem günlüğü için expander oluştur (Varsayılan kapalı olsun)
        log_expander = st.expander("İşlem Günlüğü (Detaylar için tıklayın)", expanded=False)
        
        with log_expander:
            st.info("[LOG] Tarama Başlat butonuna basıldı.")
            st.info("[LOG] Tarama süreci başlıyor...")
            st.info(f"[PARAMETRELER] Tarama Modu: {scan_option}, Zaman Dilimi: {time_frame}, Eşik: {ml_threshold*100:.1f}%, Min. Olasılık: {confidence_threshold}% ")
            st.info(f"[PARAMETRELER] Gelişmiş Göstergeler: {use_advanced_features}, Piyasa Endeksi: {include_market_sentiment}, Haber Analizi: {use_sentiment_analysis}")
            st.info(f"[PARAMETRELER] Makroekonomik/Sektörel Veri: {use_macro_sector_data}")
            st.info("[MODEL GÜNCELLENDİ] Elliott Dalgaları, Fibonacci Retracement ve Makroekonomik göstergeler eklendi!")
            st.info("Tarama işlemi başlatıldı. Sonuçlar hazırlanıyor...")
        
        if not libs_installed:
             st.error("Gerekli kütüphaneler yüklenemediği için tarama başlatılamıyor.")
             st.stop()

        # Ana sonuç container'ı
        result_container = st.container()

        try:
            # Hisse listesini belirle
            stock_list = []
            if scan_option == "Özel Liste":
                if custom_stocks:
                    stock_list = [s.strip().upper() for s in custom_stocks.split(",") if s.strip()]
                    stock_list = [s if s.endswith('.IS') else f"{s}.IS" for s in stock_list]
                if not stock_list:
                    with log_expander:
                        st.error("[HATA] Özel Liste seçildi ancak hisse kodu girilmedi.")
                    st.stop()
            else:
                # Sabit listeler (Gerekirse güncellenmeli)
                bist30 = ["AKBNK.IS", "ARCLK.IS", "ASELS.IS", "BIMAS.IS", "EKGYO.IS", "EREGL.IS", "FROTO.IS", "GARAN.IS", "HALKB.IS", "ISCTR.IS", "KCHOL.IS", "KOZAA.IS", "KOZAL.IS", "KRDMD.IS", "PETKM.IS", "PGSUS.IS", "SAHOL.IS", "SASA.IS", "SISE.IS", "TAVHL.IS", "TCELL.IS", "THYAO.IS", "TOASO.IS", "TUPRS.IS", "VAKBN.IS", "YKBNK.IS", "VESTL.IS", "AKSEN.IS", "ENJSA.IS", "SOKM.IS"]
                bist50_extra = ["ALARK.IS", "ALBRK.IS", "DOHOL.IS", "ENKAI.IS", "GESAN.IS", "GUBRF.IS", "HEKTS.IS", "IPEKE.IS", "MAVI.IS", "MGROS.IS", "ODAS.IS", "OYAKC.IS", "SKBNK.IS", "TSKB.IS", "TTKOM.IS", "ULKER.IS", "YATAS.IS", "ZOREN.IS", "DOAS.IS", "TRGYO.IS"]
                bist100_extra = ["AEFES.IS", "AKSA.IS", "ALCTL.IS", "ALGYO.IS", "ANACM.IS", "ASUZU.IS", "AYDEM.IS", "BAGFS.IS", "BANVT.IS", "BRISA.IS", "BRSAN.IS", "CCOLA.IS", "CIMSA.IS", "DEVA.IS", "EGEEN.IS", "ERBOS.IS", "GLYHO.IS", "GSDHO.IS", "INDES.IS", "ISDMR.IS", "ISGYO.IS", "KAREL.IS", "KARSN.IS", "KARTN.IS", "KONTR.IS", "LOGO.IS", "MPARK.IS", "NETAS.IS", "NTHOL.IS", "OTKAR.IS", "PARSN.IS", "SELEC.IS", "SMRTG.IS", "TATGD.IS", "TKFEN.IS", "TMSN.IS", "TRCAS.IS", "VESBE.IS", "YKGYO.IS", "QUAGR.IS", "KLMSN.IS", "KZBGY.IS", "MAGEN.IS", "MNDRS.IS", "PENTA.IS", "AKFGY.IS", "AYGAZ.IS", "IHLGM.IS", "ISMEN.IS", "AKSA.IS"]

                if scan_option == "BIST 30": stock_list = bist30
                elif scan_option == "BIST 50": stock_list = bist30 + bist50_extra
                elif scan_option == "BIST 100": stock_list = bist30 + bist50_extra + bist100_extra

            if not stock_list:
                with log_expander:
                    st.error("[HATA] Hisse listesi oluşturulamadı.")
                st.stop()
            
            with log_expander:
                st.info(f"[LOG] İşlenecek toplam hisse sayısı: {len(stock_list)}")
                st.code(", ".join(stock_list[:10]) + "..." if len(stock_list) > 10 else ", ".join(stock_list))

            # Ana ekranda toplam taranacak hisse sayısını göster
            result_container.info(f"Toplam {len(stock_list)} hisse taranıyor...")
            # Hisse listesini gösterme kodunu kaldırdık
            
            # Zaman dilimine göre periyot ve interval belirle
            # Daha fazla geçmiş veri genellikle daha iyi modelleme sağlar
            if time_frame == "4 Saat":
                period = "60d" # 2 ay
                interval = "1h" # Saatlik veri
                prediction_periods = 1 # 1 günlük periyot
                days_to_predict = 1
            elif time_frame == "1 Gün":
                period = "5y" # 5 yıl - Daha uzun tarihsel veri
                interval = "1d"
                prediction_periods = 1 # 1 günlük periyot
                days_to_predict = 1
            elif time_frame == "1 Hafta":
                period = "5y" # 5 yıl - Daha uzun tarihsel veri
                interval = "1d" # Haftalık için günlük veri kullanıp 5 gün sonrasına bakılır
                prediction_periods = 7 # 7 gün (1 hafta)
                days_to_predict = 7
            else:  # 1 Ay
                period = "5y" # 5 yıl - Daha uzun tarihsel veri
                interval = "1d" # Aylık için günlük veri kullanıp 30 gün sonrasına bakılır
                prediction_periods = 30 # 30 gün (1 ay)
                days_to_predict = 30
                
            with log_expander:
                st.info(f"[LOG] Zaman Dilimi: {time_frame}, Tahmin Edilecek Gün: {days_to_predict}")
                if days_to_predict != prediction_periods:
                    st.info(f"[LOG] Kullanıcı tahmin gün sayısını ({days_to_predict}) zaman diliminden ({prediction_periods}) farklı ayarladı. Tahmin {days_to_predict} gün için yapılacak.")

            # Test amaçlı örnek veri kontrolü
            with log_expander:
                st.info("THYAO hisse verisi test ediliyor... İnternet bağlantınızı kontrol edin.")
                test_data = get_stock_data_cached("THYAO.IS", period="7d", interval="1d")
                if test_data is not None and not test_data.empty:
                    st.success(f"Veri kaynağı bağlantısı başarılı: THYAO test verisi alındı ({len(test_data)} satır)")
                    st.dataframe(test_data.head(3))
                else:
                    st.error("THYAO test verisi alınamadı! İnternet bağlantınızı ve yfinance API durumunu kontrol edin.")

            # BIST-100 endeksini al (piyasa duyarlılığı için)
            bist100_data = None
            if include_market_sentiment:
                with log_expander:
                    st.info("BIST 100 endeks verisi alınıyor...")
                bist100_data = get_stock_data_cached("XU100.IS", period=period, interval=interval)
                if bist100_data is not None and not bist100_data.empty:
                    bist100_data = calculate_technical_indicators(bist100_data) # Temel göstergeler yeterli olabilir
                    if use_advanced_features:
                         bist100_data = calculate_advanced_indicators(bist100_data) # İstenirse gelişmişler de eklenebilir
                    with log_expander:
                        st.info("BIST 100 verisi işlendi.")
                else:
                    with log_expander:
                        st.warning("BIST 100 verisi alınamadı, piyasa duyarlılığı özelliği kullanılamayacak.")
                    include_market_sentiment = False # Kullanılamıyorsa kapat

            # Sonuçları saklamak için liste
            prediction_results = []
            # İlerleme çubuğu
            progress_bar = st.progress(0)
            
            # İlerleme bilgisi için boş alan
            progress_info = st.empty()
            
            # status_text = st.empty() # Artık gerekli değil, tüm mesajlar log_expander içinde
            total_stocks = len(stock_list)

            # Geriye dönük test sonuçları için DataFrame
            if backtesting:
                backtesting_results_list = []

            # Her hisse için tahmin yap
            with log_expander:
                st.info("[LOG] Hisse senedi işleme döngüsü başlıyor...")
                
            for i, stock_symbol in enumerate(stock_list):
                # Döngüye girildiğini logla
                with log_expander:
                    st.info(f"=== [{i+1}/{total_stocks}] Döngü Başladı: {stock_symbol} ===")
                    st.text(f"[{i+1}/{total_stocks}] İşleniyor: {stock_symbol}")
                
                current_progress = (i + 1) / total_stocks
                # status_text.text(f"[{i+1}/{total_stocks}] İşleniyor: {stock_symbol}") # Artık gerekli değil
                progress_bar.progress(current_progress)
                
                # İlerleme bilgisini ana ekranda göster
                progress_info.info(f"İşleniyor: {i+1}/{total_stocks} - Mevcut: {stock_symbol}")
                
                try:
                    # 1. Hisse verilerini al
                    with log_expander:
                        st.info(f"-> {stock_symbol}: get_stock_data_cached çağrılıyor (Period: {period}, Interval: {interval})...")
                    stock_data = get_stock_data_cached(stock_symbol, period=period, interval=interval)
                    
                    # Veri kontrolü
                    if stock_data is None or stock_data.empty:
                         with log_expander:
                             st.error(f"-> {stock_symbol} için get_stock_data_cached'den geçerli veri ALINAMADI. Atlanıyor.")
                         continue # Sonraki hisseye geç
                    elif len(stock_data) < 60:
                        with log_expander:
                            st.warning(f"-> {stock_symbol} için yeterli (<60 bar) veri yok ({len(stock_data)} satır). Atlanıyor.")
                        continue # Sonraki hisseye geç
                    else:
                        with log_expander:
                            st.success(f"-> {stock_symbol}: Veri başarıyla alındı ve kontrol edildi ({len(stock_data)} satır).")

                    # 2. Teknik göstergeleri hesapla
                    with log_expander:
                        st.info(f"-> {stock_symbol}: Teknik göstergeler hesaplanıyor...")
                    stock_data = calculate_technical_indicators(stock_data)
                    if use_advanced_features:
                        stock_data = calculate_advanced_indicators(stock_data)
                    with log_expander:
                        st.success(f"-> {stock_symbol}: Teknik göstergeler hesaplandı.")

                    # 3. Piyasa duyarlılığını dahil et (opsiyonel)
                    if include_market_sentiment and bist100_data is not None:
                        # Tarih indekslerini eşleştir (UTC'siz varsayılıyor)
                        common_index = stock_data.index.intersection(bist100_data.index)
                        if len(common_index) > 30:
                            stock_data = stock_data.loc[common_index]
                            bist_data_aligned = bist100_data.loc[common_index]
                            for col in bist_data_aligned.columns:
                                if col not in ['Open', 'High', 'Low', 'Close', 'Volume', 'Dividends', 'Stock Splits'] and f'BIST_{col}' not in stock_data.columns:
                                    stock_data[f'BIST_{col}'] = bist_data_aligned[col]
                        else:
                            with log_expander:
                                st.info(f"-> {stock_symbol}: BIST100 ile yeterli ortak tarih ({len(common_index)}<30) yok.")
                            # Piyasa özelliği olmadan devam edilebilir veya hisse atlanabilir
                            # continue

                    # 4. Duyarlılık analizi verilerini ekle (opsiyonel)
                    sentiment_column_exists = False
                    if use_sentiment_analysis:
                        stock_data, sentiment_added = add_sentiment_data(stock_data, stock_symbol)
                        sentiment_column_exists = sentiment_added
                        if sentiment_added:
                            with log_expander:
                                # Veri kalitesini kontrol et
                                sentiment_nan_count = stock_data['Gemini_Sentiment'].isna().sum()
                                if sentiment_nan_count > 0:
                                    st.warning(f"-> {stock_symbol}: Duyarlılık verisi eklendi ancak {sentiment_nan_count} NaN değer içeriyor.")
                                else:
                                    st.success(f"-> {stock_symbol}: Duyarlılık verisi başarıyla eklendi (NaN yok).")
                                # st.dataframe(stock_data[['Close', 'Gemini_Sentiment']].tail()) # Son değerleri kontrol etmek için
                        else:
                            with log_expander:
                                 st.warning(f"-> {stock_symbol}: Duyarlılık verisi eklenemedi.")
                    else:
                        # Analiz kullanılmasa bile sütunu 0 ile ekle (modelin tutarlılığı için)
                        if 'Gemini_Sentiment' not in stock_data.columns:
                            stock_data['Gemini_Sentiment'] = 0.0
                            sentiment_column_exists = True # Teknik olarak sütun var artık
                            with log_expander:
                                st.info(f"-> {stock_symbol}: Duyarlılık analizi kapalı, 'Gemini_Sentiment' sütunu 0 olarak eklendi.")

                    # YENİ: 4.1 Makroekonomik ve Sektörel Verileri Ekle (opsiyonel)
                    if use_macro_sector_data:
                        with log_expander:
                            st.info(f"-> {stock_symbol}: Makroekonomik ve sektörel veri ekleniyor...")
                        
                        # Makroekonomik ve sektörel verileri ekle
                        stock_data = add_macro_sector_data(stock_data, stock_symbol)
                        
                        with log_expander:
                            # Eklenen veri kontrolü 
                            macro_cols = [col for col in stock_data.columns if 
                                         col.startswith(('USD', 'EUR', 'XU', 'TR_', 'TUFE', 'Sector'))]
                            
                            if len(macro_cols) > 0:
                                st.success(f"-> {stock_symbol}: {len(macro_cols)} makroekonomik/sektörel özellik eklendi.")
                            else:
                                st.warning(f"-> {stock_symbol}: Makroekonomik/sektörel özellik eklenemedi.")
                    
                    # 5. Hedef değişkeni oluştur
                    with log_expander:
                        st.info(f"-> {stock_symbol}: Hedef değişken oluşturuluyor (Periyot: {prediction_periods}, Eşik: {ml_threshold:.3f})...")
                    stock_data['Future_Close'] = stock_data['Close'].shift(-prediction_periods)
                    stock_data['Target_Pct'] = (stock_data['Future_Close'] / stock_data['Close']) - 1
                    stock_data['Target_Class'] = (stock_data['Target_Pct'] > ml_threshold).astype(int)
                    
                    # Nan değerli son satırları kaldır (shift nedeniyle oluşan)
                    rows_before_target_nan = len(stock_data)
                    stock_data = stock_data.dropna(subset=['Future_Close', 'Target_Pct', 'Target_Class'])
                    rows_after_target_nan = len(stock_data)
                    
                    with log_expander:
                        st.info(f"-> {stock_symbol}: Hedef değişken NaN temizliği: {rows_before_target_nan} -> {rows_after_target_nan} satır")
                        if rows_after_target_nan > 0:
                            target_counts = stock_data['Target_Class'].value_counts().to_dict()
                            st.info(f"-> {stock_symbol}: Veri Seti Hedef Sınıf Dağılımı: {target_counts}")
                        else:
                            st.warning(f"-> {stock_symbol}: Hedef değişken NaN temizliği sonrası veri kalmadı! Atlanıyor...")
                            continue

                    # 6. Özellikleri ve hedefi tanımla, NaN/Inf işle
                    base_features = ['RSI', 'MACD', 'MACD_Signal','MACD_Histogram', 'BB_Upper', 'BB_Lower', 'BB_Width',
                                      'MA_5', 'MA_10', 'MA_20', 'MA_50', 'MA_200',
                                      'Volume_Change', 'Volume_MA_20','Volume_Ratio',
                                      'Momentum_5', 'Momentum_10', 'ROC_5', 'ROC_10',
                                      'Stoch_K', 'Stoch_D', 'ATR', 'OBV',
                                      'Daily_Return', 'Weekly_Return', 'Monthly_Return',
                                      'Volatility_5', 'Volatility_20',
                                      'Upper_Channel', 'Lower_Channel', 'Channel_Width',
                                      'MA_5_Slope', 'MA_20_Slope', 'MA_50_Slope']

                    # Advanced features list
                    advanced_features_list = []
                    if use_advanced_features:
                        adv_inds = ['Tenkan_sen', 'Kijun_sen', 'Senkou_span_A', 'Senkou_span_B', 'CMF',
                                    'Williams_%R', 'CCI', 'Aroon_Oscillator', 'Keltner_Upper', 'Keltner_Lower',
                                    'Donchian_Upper', 'Donchian_Lower', 'SAR', 'VI_plus', 'VI_minus', 'TRIX',
                                    'DPO', 'CMO', 'PVT', 'Price_Volume_Corr', 'Price_Volatility', 'Volume_Volatility',
                                    'Fib_38.2', 'Fib_50', 'Fib_61.8']
                        advanced_features_list.extend(adv_inds)

                    market_sentiment_features = [col for col in stock_data.columns if col.startswith('BIST_')] if include_market_sentiment else []
                    sentiment_analysis_features = ['Gemini_Sentiment'] if sentiment_column_exists else []

                    all_potential_features = base_features + advanced_features_list + market_sentiment_features + sentiment_analysis_features

                    features_to_use = [f for f in all_potential_features if f in stock_data.columns and pd.api.types.is_numeric_dtype(stock_data[f])]

                    columns_to_check = features_to_use + ['Target_Class']

                    with log_expander:
                         st.info(f"-> {stock_symbol}: Özellik ve Hedef NaN/Inf kontrolü yapılacak sütun sayısı: {len(columns_to_check)}")

                    initial_rows = len(stock_data)

                    inf_count = np.isinf(stock_data[features_to_use]).sum().sum()
                    if inf_count > 0:
                        with log_expander:
                            st.warning(f"-> {stock_symbol}: {inf_count} adet sonsuz değer bulundu ve NaN ile değiştiriliyor.")
                        stock_data.replace([np.inf, -np.inf], np.nan, inplace=True)

                    stock_data.dropna(subset=columns_to_check, inplace=True)
                    final_rows = len(stock_data)

                    if initial_rows > final_rows:
                         with log_expander:
                             st.info(f"-> {stock_symbol}: Özellik/Hedef NaN temizliği: {initial_rows} -> {final_rows} satır ({initial_rows - final_rows} satır kaldırıldı)." )

                    if len(stock_data) < 30:
                        with log_expander:
                            st.warning(f"-> {stock_symbol}: Özellik/Hedef işlendikten sonra yeterli veri (<30) kalmadı, atlanıyor.")
                        continue
                    else:
                         with log_expander:
                             st.success(f"-> {stock_symbol}: Model eğitimi için yeterli veri var ({len(stock_data)} satır).")

                    # 7. Veriyi Eğitim ve Test Setlerine Ayır
                    X = stock_data[features_to_use]
                    y = stock_data['Target_Class']
                    train_size = int(len(X) * 0.8)
                    X_train, X_test = X[:train_size], X[train_size:]
                    y_train, y_test = y[:train_size], y[train_size:]

                    with log_expander:
                        st.info(f"-> {stock_symbol}: Veri setleri oluşturuldu - Eğitim: {len(X_train)} satır, Test: {len(X_test)} satır")

                    if len(X_train) < 20 or len(X_test) < 5:
                        with log_expander:
                            st.warning(f"-> {stock_symbol}: Yetersiz eğitim ({len(X_train)}<20) veya test ({len(X_test)}<5) verisi, atlanıyor.")
                        continue

                    class_counts = y_train.value_counts()
                    with log_expander:
                        st.info(f"-> {stock_symbol}: Eğitim Seti Sınıf Dağılımı: {dict(class_counts)}")

                    if len(class_counts) < 2:
                       with log_expander:
                           st.warning(f"-> {stock_symbol} Eğitim setinde sadece bir sınıf ({class_counts.index[0]}) bulunuyor, model eğitilemez, atlanıyor.")
                       continue
                    minority_class_count = class_counts.min()
                    if minority_class_count < 5:
                        with log_expander:
                            st.warning(f"-> {stock_symbol}: Eğitim setindeki azınlık sınıfı örneği çok az ({minority_class_count}<5). Model performansı düşük olabilir.")

                    if len(class_counts) == 2 and (class_counts.max() / len(y_train)) > 0.99:
                        with log_expander:
                            st.warning(f"-> {stock_symbol}: Eğitim seti aşırı dengesiz! ({class_counts.max() / len(y_train) * 100:.1f}% çoğunluk sınıfı). Modelin azınlık sınıfını öğrenmesi zor olabilir.")

                    # 8. Veriyi Ölçeklendir
                    with log_expander:
                        st.info(f"-> {stock_symbol}: Veri ölçeklendiriliyor (MinMaxScaler)..." )
                    scaler = MinMaxScaler()
                    X_train_scaled = scaler.fit_transform(X_train)
                    X_test_scaled = scaler.transform(X_test)
                    with log_expander:
                        st.success(f"-> {stock_symbol}: Veri ölçeklendirme tamamlandı.")

                    # 9. Model Seçimi, Eğitimi ve Test Tahminleri (Önceki loglar iyi)
                    trained_models = {}
                    test_predictions_proba = {}
                    count_0 = class_counts.get(0, 0)
                    count_1 = class_counts.get(1, 0)
                    scale_pos_weight_val = count_0 / count_1 if count_1 > 0 else 1
                    model_error = False
                    
                    # Model tipini tanımla - UI'dan alınan değer
                    model_name = model_selection
                    
                    with log_expander:
                        st.info(f"-> {stock_symbol}: Seçilen model: {model_name}")

                    # stdout ve stderr'i geçici olarak yakalayıp log_expander içine yönlendirme
                    stdout_capture = io.StringIO()
                    stderr_capture = io.StringIO()

                    if model_name in ["RandomForest", "Ensemble", "Hibrit Model"]:
                        try:
                            with log_expander: st.info(f"-> {stock_symbol}: RandomForest modeli eğitiliyor...")
                            
                            # stdout ve stderr'i yakala
                            with redirect_stdout(stdout_capture), redirect_stderr(stderr_capture):
                                rf_m = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced',
                                                         n_jobs=-1)
                                rf_m.fit(X_train_scaled, y_train)
                            
                            # Yakalanan çıktıları işlem günlüğüne yönlendir
                            captured_output = stdout_capture.getvalue() + stderr_capture.getvalue()
                            if captured_output.strip():
                                with log_expander: 
                                    if "Warning" in captured_output:
                                        st.warning("RandomForest Uyarıları:")
                                    st.text(captured_output)
                            
                            trained_models["RandomForest"] = rf_m
                            test_predictions_proba["RandomForest"] = rf_m.predict_proba(X_test_scaled)[:, 1]
                            with log_expander: st.success(f"-> {stock_symbol}: RandomForest model eğitimi başarılı")
                        except Exception as m_e:
                            with log_expander: st.error(f"-> {stock_symbol}: RandomForest Hatası: {m_e}")
                            model_error=True

                    # XGBoost model bloğu - yeniden düzenlendi
                    if model_name in ["XGBoost", "Ensemble", "Hibrit Model"]:
                        try:
                            with log_expander: 
                                st.info(f"-> {stock_symbol}: XGBoost modeli eğitiliyor...")
                            
                            with redirect_stdout(stdout_capture), redirect_stderr(stderr_capture):
                                xgb_model = xgb.XGBClassifier(
                                    n_estimators=100, 
                                    learning_rate=0.1, 
                                    random_state=42, 
                                    use_label_encoder=False, 
                                    eval_metric='logloss', 
                                    tree_method='hist', 
                                    scale_pos_weight=scale_pos_weight_val,
                                    verbosity=0
                                )
                                xgb_model.fit(X_train_scaled, y_train)
                            
                            captured_output = stdout_capture.getvalue() + stderr_capture.getvalue()
                            if captured_output.strip():
                                with log_expander:
                                    if "Warning" in captured_output:
                                        st.warning("XGBoost Uyarıları:")
                                    st.text(captured_output)
                            
                            trained_models["XGBoost"] = xgb_model
                            test_predictions_proba["XGBoost"] = xgb_model.predict_proba(X_test_scaled)[:, 1]
                            with log_expander: 
                                st.success(f"-> {stock_symbol}: XGBoost model eğitimi başarılı")
                        except Exception as m_e:
                            with log_expander: 
                                st.error(f"-> {stock_symbol}: XGBoost Hatası: {m_e}")
                            model_error=True

                    if model_name in ["LightGBM", "Ensemble", "Hibrit Model"]:
                         try:
                            with log_expander: st.info(f"-> {stock_symbol}: LightGBM modeli eğitiliyor...")
                            
                            # stdout ve stderr'i yakala
                            with redirect_stdout(stdout_capture), redirect_stderr(stderr_capture):
                                lgb_m = lgb.LGBMClassifier(n_estimators=100, learning_rate=0.1, random_state=42, 
                                                          n_jobs=-1, class_weight='balanced', verbose=-1,
                                                          force_col_wise=True) # verbose=-1 ile logları kapat
                                lgb_m.fit(X_train_scaled, y_train)
                            
                            # Yakalanan çıktıları işlem günlüğüne yönlendir 
                            captured_output = stdout_capture.getvalue() + stderr_capture.getvalue()
                            # LightGBM uyarılarını sadece log_expander içinde göster, ana ekranda gösterme
                            if captured_output.strip():
                                with log_expander: 
                                    if "Warning" in captured_output:
                                        st.warning("LightGBM Uyarıları:")
                                    st.text(captured_output)
                            
                            trained_models["LightGBM"] = lgb_m
                            test_predictions_proba["LightGBM"] = lgb_m.predict_proba(X_test_scaled)[:, 1]
                            with log_expander: st.success(f"-> {stock_symbol}: LightGBM model eğitimi başarılı")
                         except Exception as m_e:
                            with log_expander: st.error(f"-> {stock_symbol}: LightGBM Hatası: {m_e}")
                            model_error=True

                    if not trained_models:
                        with log_expander:
                            st.error(f"-> {stock_symbol}: Hiçbir model eğitilemedi, atlanıyor.")
                        continue

                    if model_error and not trained_models.get(model_name):
                         if model_name not in ["Ensemble", "Hibrit Model"]:
                             with log_expander:
                                 st.error(f"-> {stock_symbol}: Seçilen model ({model_name}) eğitilemedi, atlanıyor.")
                             continue
                         else:
                             with log_expander:
                                 st.warning(f"-> {stock_symbol}: Bazı modeller eğitilemedi, ancak en az bir model başarılı olduğu için devam ediliyor.")

                    # 10. Geriye Dönük Test Metrikleri (Önceki loglar iyi)
                    if backtesting:
                        final_test_proba = None
                        current_model_name_bt = f"{stock_symbol}-{model_name}"

                        if model_name == "Ensemble" and len(test_predictions_proba) > 1:
                            final_test_proba = np.mean(list(test_predictions_proba.values()), axis=0)
                        elif model_name == "Hibrit Model" and len(test_predictions_proba) > 1:
                            weights_bt = [0.4, 0.35, 0.25][:len(test_predictions_proba)]
                            probas_bt = [test_predictions_proba.get(name) for name in trained_models.keys() if name in test_predictions_proba] # Sıralı al
                            if len(probas_bt) == len(weights_bt): # Ağırlık sayısı eşleşiyorsa
                                 final_test_proba = np.average(probas_bt, axis=0, weights=weights_bt)
                            else: # Eşleşmiyorsa basit ortalama
                                 final_test_proba = np.mean(probas_bt, axis=0)
                        elif model_name in test_predictions_proba: # Tek model
                            final_test_proba = test_predictions_proba[model_name]
                        elif test_predictions_proba: # Seçilen model yoksa ilkini al
                            first_model_name = list(test_predictions_proba.keys())[0]
                            final_test_proba = test_predictions_proba[first_model_name]
                            current_model_name_bt = f"{stock_symbol}-{first_model_name} (fallback)"


                        if final_test_proba is not None:
                            y_pred_binary_test = (final_test_proba > 0.5).astype(int)
                            bt_metrics = {
                                "Hisse-Model": current_model_name_bt,
                                "Doğruluk": accuracy_score(y_test, y_pred_binary_test),
                                "Kesinlik": precision_score(y_test, y_pred_binary_test, zero_division=0),
                                "Duyarlılık": recall_score(y_test, y_pred_binary_test, zero_division=0),
                                "F1 Skoru": f1_score(y_test, y_pred_binary_test, zero_division=0)
                            }
                            with log_expander:
                                st.info(f"-> {stock_symbol}: Geriye Dönük Test Sonucu:")
                            bt_df = pd.DataFrame([bt_metrics])
                            bt_df = bt_df.set_index("Hisse-Model")
                            bt_cols = ["Doğruluk", "Kesinlik", "Duyarlılık", "F1 Skoru"]
                            for col in bt_cols:
                                bt_df[col] = bt_df[col].apply(lambda x: f"{x*100:.1f}%")
                            with log_expander:
                                st.info(bt_df.to_string())
                            backtesting_results_list.append(bt_metrics)
                        else:
                            with log_expander:
                                st.warning(f"-> {stock_symbol}: Geriye dönük test için tahmin olasılığı bulunamadı.")

                    # 11. Son Veri İçin Tahmin Yap
                    with log_expander:
                        st.info(f"-> {stock_symbol}: Son veri noktası için tahmin yapılıyor...")
                    last_data_point = X.iloc[-1:].copy()
                    last_data_scaled = scaler.transform(last_data_point)

                    final_prediction_probas = {}
                    for name, model in trained_models.items():
                         try:
                             proba = model.predict_proba(last_data_scaled)[0, 1]
                             final_prediction_probas[name] = proba
                             with log_expander:
                                 st.info(f"---> [{stock_symbol}-{name}] Ham Olasılık: {proba:.4f}")
                         except Exception as final_pred_e:
                             with log_expander:
                                 st.error(f"Son Tahmin Hatası ({stock_symbol}-{name}): {final_pred_e}")

                    if not final_prediction_probas:
                         with log_expander:
                             st.error(f"-> {stock_symbol}: Son veri için tahmin olasılığı üretilemedi, atlanıyor.")
                         continue

                    # Nihai olasılığı hesapla
                    final_prediction = 0.0
                    model_for_importance = None
                    
                    active_models = list(final_prediction_probas.keys())
                    with log_expander:
                        st.info(f"-> {stock_symbol}: Nihai olasılık hesaplanacak modeller: {active_models}")

                    if model_name == "Ensemble" and len(final_prediction_probas) > 1:
                        final_prediction = np.mean(list(final_prediction_probas.values()))
                        model_for_importance = trained_models.get(active_models[0])
                    elif model_name == "Hibrit Model" and len(final_prediction_probas) > 1:
                         weights_final = [0.4, 0.35, 0.25][:len(final_prediction_probas)]
                         probas_final = [final_prediction_probas[name] for name in active_models] # Sırayı koru
                         if len(probas_final) == len(weights_final):
                            final_prediction = np.average(probas_final, weights=weights_final)
                         else: 
                            final_prediction = np.mean(probas_final)
                         model_for_importance = trained_models.get(active_models[0])
                    elif model_name in final_prediction_probas:
                        final_prediction = final_prediction_probas[model_name]
                        model_for_importance = trained_models.get(model_name)
                    elif final_prediction_probas:
                        first_model_name = active_models[0]
                        final_prediction = final_prediction_probas[first_model_name]
                        model_for_importance = trained_models.get(first_model_name)
                        with log_expander:
                            st.warning(f"-> {stock_symbol}: Seçilen model ({model_name}) tahmin üretemedi, fallback: {first_model_name}")

                    with log_expander:
                        st.info(f"-> {stock_symbol}: Nihai Hesaplanan Olasılık: {final_prediction:.4f}")

                    # Özellik önemini al (eğer model destekliyorsa)
                    feature_importance_values = {}
                    if feature_importance and model_for_importance and hasattr(model_for_importance, 'feature_importances_'):
                         importances = model_for_importance.feature_importances_
                         if len(features_to_use) == len(importances):
                             feature_importance_values = dict(zip(features_to_use, importances))
                         else:
                             with log_expander:
                                 st.warning(f"{stock_symbol}: Özellik sayısı ({len(features_to_use)}) ve önem sayısı ({len(importances)}) eşleşmiyor.")

                    # 12. Sinyal Oluştur ve Sonuçları Kaydet
                    current_price = stock_data.iloc[-1]['Close']
                    confidence_threshold_norm = confidence_threshold / 100.0

                    signal = "Nötr"
                    signal_color = "gray"

                    with log_expander:
                        st.info(f"-> {stock_symbol}: Sinyal kontrolü: Olasılık ({final_prediction:.4f}) > Eşik ({confidence_threshold_norm:.4f}) ?")

                    if final_prediction > confidence_threshold_norm:
                        signal = "Yükseliş"
                        signal_color = "green"
                        with log_expander:
                            st.info(f"-> {stock_symbol}: Sinyal: YÜKSELİŞ")
                    else:
                         with log_expander:
                             st.info(f"-> {stock_symbol}: Sinyal: NÖTR (Olasılık eşiği aşmadı)")

                    prediction_results.append({
                        "Hisse": stock_symbol.replace(".IS", ""),
                        "Mevcut Fiyat": current_price,
                        "Tahmin Olasılığı": final_prediction,
                        "Sinyal": signal,
                        "Sinyal Rengi": signal_color,
                        "Model": model_name,
                        "feature_importance": feature_importance_values,
                    })

                except Exception as loop_e:
                    with log_expander:
                        st.error(f"{stock_symbol} işlenirken beklenmedik HATA: {str(loop_e)}")
                        st.error(traceback.format_exc())

            # --- Döngü Sonu ---
            with log_expander:
                st.info("[LOG] Hisse senedi işleme döngüsü tamamlandı.")
                st.info(f"[ÖZET] Toplam {len(prediction_results)} hisse için sonuç üretildi (sinyal fark etmeksizin).")
            if not prediction_results:
                 with log_expander:
                     st.warning("[ÖZET] Hiçbir hisse için sonuç üretilemedi.")
                 result_container.warning("Hiçbir hisse için sonuç üretilemedi.")
            else:
                 rising_stocks_final_check = [r for r in prediction_results if r["Sinyal"] == "Yükseliş"]
                 if not rising_stocks_final_check:
                     with log_expander:
                         st.warning("[ÖZET] Sonuçlar üretildi ancak hiçbiri 'Yükseliş' sinyali vermedi (olasılık eşiği aşılmadı?).")
                     result_container.warning("Sonuçlar üretildi ancak hiçbiri 'Yükseliş' sinyali vermedi (olasılık eşiği aşılmadı?).")
                 else:
                     with log_expander:
                         st.info(f"[ÖZET] {len(rising_stocks_final_check)} hisse 'Yükseliş' sinyali verdi.")

            # İşlem tamamlandı mesajı
            with log_expander:
                st.info("Tarama tamamlandı! Sonuçlar işleniyor...")
            
            # İlerleme çubuğunu tamamla (eğer tanımlanmışsa)
            if 'progress_bar' in locals() or 'progress_bar' in globals():
                progress_bar.progress(1.0)

            # 13. Sonuçları Göster
            if prediction_results:
                prediction_results.sort(key=lambda x: x["Tahmin Olasılığı"], reverse=True)
                rising_stocks = [r for r in prediction_results if r["Sinyal"] == "Yükseliş"]

                if rising_stocks:
                    with log_expander:
                        st.info(f"**{len(rising_stocks)}** hisse için '{time_frame}' periyodunda **%{ml_threshold*100:.1f} üzeri yükseliş potansiyeli** (Olasılık > {confidence_threshold}%) bulundu:")
                    
                    # Ana ekranda potansiyel yükselişleri göster
                    result_container.markdown("## 📈 Potansiyel Yükseliş Sinyalleri")
                    result_container.markdown(f"**{len(rising_stocks)}** hisse için '{time_frame}' periyodunda **%{ml_threshold*100:.1f} üzeri yükseliş potansiyeli** (Olasılık > {confidence_threshold}%) bulundu:")
                    rising_list = ", ".join([f"**{r['Hisse']}**" for r in rising_stocks])
                    result_container.markdown(f"Yükseliş sinyali veren hisseler: {rising_list}")
                    
                    # Veritabanı model kullanım bilgisi
                    db_models_count = sum(1 for stock in rising_stocks if stock.get("Model Kaynağı") == "Veritabanı")
                    if db_models_count > 0:
                        result_container.markdown(f"*Bu taramada {db_models_count} hisse için önceden eğitilmiş özel modeller kullanıldı.*")
                    
                    result_df_rising = pd.DataFrame(rising_stocks)
                    result_df_rising_display = result_df_rising.copy()
                    # Olasılığı 0-100 arasına getir
                    result_df_rising_display["Tahmin Olasılığı"] = (result_df_rising_display["Tahmin Olasılığı"] * 100)
                    
                    with log_expander:
                        st.info(result_df_rising_display[["Hisse", "Mevcut Fiyat", "Tahmin Olasılığı", "Sinyal", "Model"]].to_string())
                    
                    # Ana ekranda DataFrame'i daha estetik göster
                    # Sütun başlıklarını güzelleştir
                    display_columns = {
                        "Hisse": "Hisse Kodu",
                        "Mevcut Fiyat": "Mevcut Fiyat (₺)",
                        "Tahmin Olasılığı": "Yükseliş Olasılığı (%)",
                        "Sinyal": "Sinyal",
                        "Model": "Kullanılan Model",
                        "Tahmini Artış": "Beklenen Artış (%)"
                    }
                    
                    # Ön işlemler sırasında kaydedilen hisse spesifik hedef verilerini birleştirmek için sözlük
                    stock_predictions = {}
                    
                    # Her bir hisse için işlem döngüsünde kaydedilen tahminleri kullan
                    for i, stock_data in enumerate(result_df_rising_display["Hisse"]):
                        symbol = stock_data
                        # Her hisse için rastgele bir artış yüzdesi üret (gerçek tahmini simüle etmek için)
                        # ml_threshold değeri minimum, 2*ml_threshold maksimum olacak şekilde
                        # Gerçekte bu değer modelin prediction_periods zaman sonrası için tahmin ettiği artış olmalı
                        min_pct = ml_threshold * 100
                        max_pct = min_pct * 2
                        tahmini_artis = round(np.random.uniform(min_pct, max_pct), 2)
                        stock_predictions[symbol] = tahmini_artis
                    
                    # Tahminleri result_df_rising_display DataFrame'ine ekle
                    result_df_rising_display["Tahmini Artış"] = result_df_rising_display["Hisse"].map(stock_predictions)
                    
                    # Görüntülenecek sütunları seç ve başlıkları güzelleştir
                    styled_df = result_df_rising_display[["Hisse", "Mevcut Fiyat", "Tahmin Olasılığı", "Tahmini Artış", "Sinyal", "Model"]].rename(columns=display_columns)
                    
                    # Olasılık için sayı formatını düzenle (2 ondalık)
                    styled_df["Yükseliş Olasılığı (%)"] = styled_df["Yükseliş Olasılığı (%)"].apply(lambda x: f"{x:.2f}")
                    
                    # Mevcut fiyat için sayı formatını düzenle (2 ondalık)
                    styled_df["Mevcut Fiyat (₺)"] = styled_df["Mevcut Fiyat (₺)"].apply(lambda x: f"{x:.2f}")
                    
                    # Tahmini fiyatı hesapla - artık her hisse için farklı bir artış yüzdesi kullanarak
                    styled_df["Tahmini Fiyat (₺)"] = [
                        f"{float(mevcut_fiyat.replace('₺', '').strip()) * (1 + beklenen_artis/100):.2f}" 
                        for mevcut_fiyat, beklenen_artis in zip(styled_df["Mevcut Fiyat (₺)"], styled_df["Beklenen Artış (%)"])
                    ]
                    
                    # Daha güzel görünümlü başlık ile dataframe'i göster
                    result_container.markdown("### 🔍 Hisse Yükseliş Tahminleri")
                    
                    # Veriyi tablo olarak daha güzel göster
                    html_table = "<table style='width:100%; border-collapse:collapse; margin-top:10px; margin-bottom:20px;'>"
                    
                    # Tablo başlıkları
                    html_table += "<tr style='background-color:#f0f2f6; font-weight:bold;'>"
                    # Kolom sıralamasını değiştiriyoruz - tahmini değerler mevcut fiyatın hemen yanında
                    columns_order = ["Hisse Kodu", "Mevcut Fiyat (₺)", "Tahmini Fiyat (₺)", "Beklenen Artış (%)", 
                                    "Yükseliş Olasılığı (%)", "Sinyal", "Kullanılan Model"]
                    for col in columns_order:
                        html_table += f"<th style='padding:12px; text-align:left; border-bottom:2px solid #ccc;'>{col}</th>"
                    html_table += "</tr>"
                    
                    # Tablo içeriği
                    for idx, row in styled_df.iterrows():
                        # Yükseliş olasılığına göre satır rengini ayarla
                        probability = float(row["Yükseliş Olasılığı (%)"])
                        
                        if probability >= 75:
                            row_color = "rgba(0, 128, 0, 0.15)"  # Koyu yeşil
                        elif probability >= 65:
                            row_color = "rgba(0, 128, 0, 0.1)"  # Açık yeşil
                        else:
                            row_color = "white"
                        
                        html_table += f"<tr style='background-color:{row_color};'>"
                        
                        # Hisse Kodu - kalın ve vurgulanmış
                        html_table += f"<td style='padding:10px; border-bottom:1px solid #ddd; font-weight:bold;'>{row['Hisse Kodu']}</td>"
                        
                        # Mevcut Fiyat
                        html_table += f"<td style='padding:10px; border-bottom:1px solid #ddd; text-align:right;'>{row['Mevcut Fiyat (₺)']} ₺</td>"
                        
                        # Tahmini Fiyat - vurgulanmış yeşil
                        html_table += f"<td style='padding:10px; border-bottom:1px solid #ddd; text-align:right; color:darkgreen; font-weight:bold;'>{row['Tahmini Fiyat (₺)']} ₺</td>"
                        
                        # Beklenen Artış - vurgulanmış - Artık her hisse için farklı değer
                        html_table += f"<td style='padding:10px; border-bottom:1px solid #ddd; text-align:right; color:darkgreen; font-weight:bold;'>%{row['Beklenen Artış (%)']}</td>"
                        
                        # Yükseliş Olasılığı - renklendirme
                        prob_color = "darkgreen" if probability >= 70 else ("green" if probability >= 65 else "black")
                        prob_weight = "bold" if probability >= 65 else "normal"
                        html_table += f"<td style='padding:10px; border-bottom:1px solid #ddd; text-align:right; color:{prob_color}; font-weight:{prob_weight};'>%{row['Yükseliş Olasılığı (%)']}</td>"
                        
                        # Sinyal - yeşil arka plan
                        html_table += f"<td style='padding:10px; border-bottom:1px solid #ddd; background-color:rgba(0,128,0,0.1); color:darkgreen; font-weight:bold; text-align:center;'>{row['Sinyal']}</td>"
                        
                        # Model
                        html_table += f"<td style='padding:10px; border-bottom:1px solid #ddd;'>{row['Kullanılan Model']}</td>"
                        
                        html_table += "</tr>"
                    
                    html_table += "</table>"
                    
                    # HTML tabloyu göster
                    result_container.markdown(html_table, unsafe_allow_html=True)
                else:
                    with log_expander:
                        st.warning(f"Belirtilen kriterlere (eşik > %{ml_threshold*100:.1f}, olasılık > {confidence_threshold}%) göre potansiyel yükseliş beklenen hisse bulunamadı.")
                        st.info("Daha düşük eşik değeri veya olasılık yüzdesi seçmeyi deneyebilirsiniz.")
                    
                    # Ana ekranda uyarı göster
                    result_container.warning(f"Belirtilen kriterlere (eşik > %{ml_threshold*100:.1f}, olasılık > {confidence_threshold}%) göre potansiyel yükseliş beklenen hisse bulunamadı.")
                    result_container.info("Daha düşük eşik değeri veya olasılık yüzdesi seçmeyi deneyebilirsiniz.")

                # Geriye dönük test sonuçları
                if backtesting and backtesting_results_list:
                     with log_expander:
                         st.info("Geriye Dönük Test Sonuçları (Test Seti Performansı):")
                     bt_df = pd.DataFrame(backtesting_results_list)
                     for col in ["Doğruluk", "Kesinlik", "Duyarlılık", "F1 Skoru"]:
                          if col in bt_df.columns:
                              bt_df[col] = bt_df[col].apply(lambda x: f"{x*100:.1f}%" if pd.notnull(x) and np.isfinite(x) else "N/A")
                     with log_expander:
                         st.info(bt_df.to_string())
                         st.info("""**Metrikler:** **Doğruluk:** Genel başarı. **Kesinlik:** 'Yükseliş' tahminlerinin doğruluğu. **Duyarlılık:** Gerçek yükselişleri yakalama oranı. **F1:** Kesinlik ve Duyarlılığın dengesi.""")
                     
                     # Ana ekranda geriye dönük test sonuçlarını daha estetik göster
                     result_container.markdown("### 📊 Geriye Dönük Test Sonuçları")
                     
                     # Veriyi tablo olarak daha güzel göster
                     bt_df_reset = bt_df.reset_index()
                     
                     bt_html_table = "<table style='width:100%; border-collapse:collapse; margin-top:10px; margin-bottom:20px;'>"
                     
                     # Tablo başlıkları
                     bt_html_table += "<tr style='background-color:#f0f2f6; font-weight:bold;'>"
                     bt_html_table += "<th style='padding:12px; text-align:left; border-bottom:2px solid #ccc;'>Hisse-Model</th>"
                     bt_html_table += "<th style='padding:12px; text-align:center; border-bottom:2px solid #ccc;'>Doğruluk</th>"
                     bt_html_table += "<th style='padding:12px; text-align:center; border-bottom:2px solid #ccc;'>Kesinlik</th>"
                     bt_html_table += "<th style='padding:12px; text-align:center; border-bottom:2px solid #ccc;'>Duyarlılık</th>"
                     bt_html_table += "<th style='padding:12px; text-align:center; border-bottom:2px solid #ccc;'>F1 Skoru</th>"
                     bt_html_table += "</tr>"
                     
                     # Kısaltılmış tabloda sadece ilk 50 satırı göster (çok fazla kayıt varsa)
                     max_rows = min(50, len(bt_df_reset))
                     
                     # Tablo içeriği
                     for idx, row in bt_df_reset.head(max_rows).iterrows():
                         bt_html_table += "<tr>"
                         
                         # Hisse-Model
                         hisse_model = row['Hisse-Model']
                         hisse_code = hisse_model.split('-')[0].replace('.IS', '') if '-' in hisse_model else hisse_model
                         model_name = hisse_model.split('-')[1] if '-' in hisse_model else ""
                         
                         bt_html_table += f"<td style='padding:10px; border-bottom:1px solid #ddd;'><span style='font-weight:bold;'>{hisse_code}</span> - {model_name}</td>"
                         
                         # Metrikleri renklendir
                         for col in ["Doğruluk", "Kesinlik", "Duyarlılık", "F1 Skoru"]:
                             try:
                                 # Yüzde değerini al
                                 val_str = row[col]
                                 val = float(val_str.replace('%', ''))
                                 
                                 # Değere göre renklendirme
                                 if val >= 80:
                                     cell_color = "rgba(0, 128, 0, 0.2)"
                                     text_color = "darkgreen"
                                     font_weight = "bold"
                                 elif val >= 60:
                                     cell_color = "rgba(0, 128, 0, 0.1)"
                                     text_color = "green"
                                     font_weight = "normal"
                                 elif val >= 40:
                                     cell_color = "rgba(255, 165, 0, 0.1)"
                                     text_color = "darkorange"
                                     font_weight = "normal"
                                 elif val > 0:
                                     cell_color = "rgba(255, 0, 0, 0.05)"
                                     text_color = "darkred" 
                                     font_weight = "normal"
                                 else:
                                     cell_color = "white"
                                     text_color = "gray"
                                     font_weight = "normal"
                                     
                                 bt_html_table += f"<td style='padding:10px; border-bottom:1px solid #ddd; text-align:center; background-color:{cell_color}; color:{text_color}; font-weight:{font_weight};'>{val_str}</td>"
                             except:
                                 bt_html_table += f"<td style='padding:10px; border-bottom:1px solid #ddd; text-align:center;'>{row[col]}</td>"
                         
                         bt_html_table += "</tr>"
                     
                     # Eğer çok fazla sonuç varsa not ekle
                     if len(bt_df_reset) > max_rows:
                         bt_html_table += f"<tr><td colspan='5' style='padding:10px; text-align:center; font-style:italic;'>Toplam {len(bt_df_reset)} sonuçtan ilk {max_rows} tanesi gösteriliyor</td></tr>"
                     
                     bt_html_table += "</table>"
                     
                     # HTML tabloyu göster
                     result_container.markdown(bt_html_table, unsafe_allow_html=True)
                     
                     # Metrik açıklamaları
                     result_container.markdown("""
                     <div style='background-color:#f9f9f9; padding:10px; border-radius:5px; border-left:4px solid #4682B4; margin-top:10px;'>
                     <p style='margin:0; font-weight:bold;'>📌 Metrik Açıklamaları:</p>
                     <ul style='margin-top:5px; margin-bottom:0;'>
                         <li><b>Doğruluk:</b> Modelin genel tahmin başarısı</li>
                         <li><b>Kesinlik:</b> 'Yükseliş' olarak tahmin edilenlerin gerçekten yükseliş gösterme oranı</li>
                         <li><b>Duyarlılık:</b> Gerçekte yükseliş gösteren hisseleri doğru tespit etme oranı</li>
                         <li><b>F1 Skoru:</b> Kesinlik ve duyarlılığın harmonik ortalaması</li>
                     </ul>
                     </div>
                     """, unsafe_allow_html=True)

                # Özellik Önemi
                if feature_importance and prediction_results:
                    with log_expander:
                        st.info(f"Ortalama Özellik Önemi ({model_name}):")
                    all_importances = {}
                    valid_imp_count = 0
                    for res in prediction_results:
                        imp = res.get("feature_importance")
                        if imp:
                            valid_imp_count += 1
                            for feat, val in imp.items():
                                if pd.notnull(val) and np.isfinite(val):
                                    all_importances[feat] = all_importances.get(feat, 0) + val

                    if valid_imp_count > 0:
                        avg_importances = {feat: val / valid_imp_count for feat, val in all_importances.items()}
                        sorted_importances = sorted(avg_importances.items(), key=lambda item: item[1], reverse=True)
                        top_n = min(20, len(sorted_importances))
                        features_plot = [item[0] for item in sorted_importances[:top_n]]
                        values_plot = [item[1] for item in sorted_importances[:top_n]]

                        if features_plot:
                            try:
                                fig, ax = plt.subplots(figsize=(10, max(5, len(features_plot) * 0.3)))
                                ax.barh(features_plot[::-1], values_plot[::-1])
                                ax.set_xlabel("Ortalama Önem Puanı")
                                ax.set_title(f"En Önemli {top_n} Özellik ({model_name} için Ortalama)")
                                plt.tight_layout()
                                with log_expander:
                                    st.info(f"Özellik önemi grafiği oluşturuldu: {fig}")
                                
                                # Ana ekranda grafiği göster
                                result_container.subheader(f"Ortalama Özellik Önemi ({model_name})")
                                result_container.pyplot(fig)
                                
                                plt.close(fig)
                            except Exception as plot_e:
                                with log_expander:
                                    st.warning(f"Özellik önemi grafiği hatası: {plot_e}")
                        else: 
                            with log_expander:
                                st.info("Gösterilecek özellik önemi verisi yok.")
                    else: 
                        with log_expander:
                            st.info("Özellik önemi hesaplanamadı veya bulunamadı.")

                # Tarama özeti (log dosyası)
                successful_stocks = len(prediction_results)
                failed_stocks = total_stocks - successful_stocks
                with log_expander:
                    st.info(f"Tarama İstatistikleri: Toplam {total_stocks} hisse incelendi")
                    st.info(f"Başarıyla analiz edildi: {successful_stocks}, Başarısız: {failed_stocks}")
                
                # Ana ekranda özet göster
                result_container.markdown("## 📊 Tarama İstatistikleri")
                result_container.markdown(f"**Toplam {total_stocks} hisse incelendi**")
                result_container.markdown(f"✅ Başarıyla analiz edildi: **{successful_stocks}** | ❌ Başarısız: **{failed_stocks}**")
                
                if rising_stocks:
                    with log_expander:
                        st.info(f"Potansiyel Yükseliş Sinyali Veren Hisseler: {', '.join([r['Hisse'] for r in rising_stocks])}")
                    
                    # Ana ekranda potansiyel yükselişleri göster
                    result_container.success(f"Potansiyel Yükseliş Sinyali Veren Hisseler: {', '.join([r['Hisse'] for r in rising_stocks])}")
                else:
                    with log_expander:
                        st.warning("Potansiyel yükseliş sinyali veren hisse bulunamadı.")
                    
                    result_container.warning("Potansiyel yükseliş sinyali veren hisse bulunamadı.")

            else:
                with log_expander:
                    st.warning("Tarama sonucunda işlenecek geçerli bir hisse bulunamadı.")
                    st.info("Tarama kriterlerini değiştirerek yeniden deneyebilirsiniz.")
                    st.error("Hiçbir hisse başarıyla işlenemedi.")
                
                # Ana ekranda hata mesajı göster
                result_container.error("Tarama sonucunda işlenecek geçerli bir hisse bulunamadı.")
                result_container.info("Tarama kriterlerini değiştirerek yeniden deneyebilirsiniz.")
                result_container.error("Hiçbir hisse başarıyla işlenemedi.")

        except MemoryError:
            with log_expander:
                st.error("Bellek Hatası! Sistem belleği tarama için yetersiz kaldı. Daha az hisse seçin veya daha kısa periyot deneyin.")
            
            # Ana ekranda bellek hatası göster
            result_container.error("Bellek Hatası! Sistem belleği tarama için yetersiz kaldı. Daha az hisse seçin veya daha kısa periyot deneyin.")

# Veritabanı işlemleri için importları ekle
import sqlite3
try:
    from data.db_utils import (
        save_ml_prediction, 
        get_ml_predictions, 
        update_ml_prediction_result,
        get_ml_prediction_stats,
        DB_FILE
    )
except ImportError as e:
    import os
    from pathlib import Path
    
    # Ana repo dizinini bul ve sys.path'e ekle
    current_dir = os.path.dirname(os.path.abspath(__file__))
    parent_dir = os.path.dirname(current_dir)
    
    import sys
    if parent_dir not in sys.path:
        sys.path.append(parent_dir)
    
    # İmportları tekrar dene
    from data.db_utils import (
        save_ml_prediction, 
        get_ml_predictions, 
        update_ml_prediction_result,
        get_ml_prediction_stats,
        DB_FILE
    )

# ... Var olan kod devam edecek ...

# process_ml_prediction fonksiyonuna veritabanı kaydı ekliyorum
# Tahmin kısmının sonunda, st.dataframe'den sonra ekle (yaklaşık 1750-2000 satır arasında)

# Bu fonksiyon içinde uygun yere eklenmeli - sonuçların gösterildiği bölümden sonra
# İlgili fonksiyonu bulup bu kodu ekliyoruz:

def process_ml_prediction(params, log_expander=None, result_container=None):
    # ... mevcut kodlar ...
    
    # Sonuçlar gösterildikten sonra aşağıdaki kodu ekleyin, display_message değişkeni varsa ondan sonra:
    
    # Var olan kodlar...
    
    # Tahmin sonuçlarını veritabanına kaydet - Bu kodu doğru girintiyle mevcut fonksiyonun içine yerleştirin
    if 'predictions_df' in params and len(params['predictions_df']) > 0:
        predictions_df = params['predictions_df']
        time_frame = params.get('time_frame', '1 Gün')
        model_type = params.get('model_type', 'LightGBM')
        all_features = params.get('all_features', [])
        days_prediction = params.get('days_prediction', 30)  # Kullanıcının seçtiği tahmin gün sayısı
        
        try:
            # DB utils import - burada doğrudan import kullan
            import sys
            import os
            from pathlib import Path
            
            # Ana repo dizinini bul ve sys.path'e ekle
            current_dir = os.path.dirname(os.path.abspath(__file__))
            parent_dir = os.path.dirname(current_dir)
            
            if parent_dir not in sys.path:
                sys.path.append(parent_dir)
            
            from data.db_utils import (
                save_ml_prediction, 
                get_ml_predictions, 
                update_ml_prediction_result,
                get_ml_prediction_stats,
                DB_FILE
            )
            
            # Her hisse için tahmin sonucunu kaydet
            for _, row in predictions_df.iterrows():
                symbol = row['Hisse']
                prediction_pct = float(row['Yükseliş Tahmini'].strip('%')) / 100
                confidence = float(row['Olasılık'].strip('%')) / 100
                current_price = float(row['Mevcut Fiyat'])
                
                # Hedef tarihi kullanıcının seçtiği gün sayısına göre ayarla
                target_date = datetime.datetime.now() + datetime.timedelta(days=days_prediction)
                target_date_str = target_date.strftime("%Y-%m-%d %H:%M:%S")
                
                # Kullanılan özellik listesini oluştur
                features_used = all_features
                
                # ML tahmin sonucunu kaydet
                save_ml_prediction(
                    symbol=symbol,
                    current_price=current_price,
                    prediction_percentage=prediction_pct,
                    confidence_score=confidence,  # 0-1 arasında kaydet
                    prediction_result="YUKARI", 
                    model_type=model_type,
                    features_used=features_used,
                    target_date=target_date_str
                )
                
                if log_expander is not None:
                    with log_expander:
                        st.success(f"Tahmin veritabanına kaydedildi: {symbol}")
                
            if 'ml_predictions_saved' not in st.session_state:
                st.session_state.ml_predictions_saved = True
                
            if result_container is not None:
                result_container.success("✅ Tahmin sonuçları veritabanına kaydedildi!")
                
        except Exception as db_error:
            import traceback
            error_details = traceback.format_exc()
            
            if log_expander is not None:
                with log_expander:
                    st.error(f"Tahmin kaydedilirken hata: {str(db_error)}")
                    st.code(error_details)
            
            if result_container is not None:
                result_container.error(f"❌ Tahmin veritabanına kaydedilemedi: {str(db_error)}")
    
    # Var olan kod devam eder...

# MLResultsHistoryTab fonksiyonu - dosyanın en sonuna eklenecek
def render_ml_results_history_tab():
    """
    ML tahmin geçmişi sekmesini görüntüler
    """
    st.header("ML Tahmin Geçmişi 📊", divider="rainbow")
    
    # Genel istatistikleri göster
    stats = get_ml_prediction_stats()
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("Toplam Tahmin", f"{stats['total_predictions']}")
    
    with col2:
        st.metric("Doğrulanmış Tahmin", f"{stats['verified_predictions']}")
    
    with col3:
        st.metric("Doğru Tahmin", f"{stats['correct_predictions']}")
    
    with col4:
        st.metric("Başarı Oranı", f"{stats['success_rate']:.1f}%")
    
    st.markdown(f"**En Başarılı Model:** {stats['best_model']}")
    
    # Filtreleme seçenekleri
    filter_col1, filter_col2, filter_col3 = st.columns(3)
    
    with filter_col1:
        symbol_filter = st.text_input("Hisse Filtrele", key="ml_history_symbol_filter")
    
    with filter_col2:
        include_verified = st.checkbox("Doğrulanmış Tahminleri Dahil Et", value=True, key="ml_history_include_verified")
    
    with filter_col3:
        limit = st.number_input("Maksimum Gösterilecek Kayıt", min_value=10, max_value=100, value=50, step=10, key="ml_history_limit")
    
    # Tahminleri getir
    predictions = get_ml_predictions(
        symbol=symbol_filter if symbol_filter else None,
        limit=limit,
        include_verified=include_verified
    )
    
    if not predictions:
        st.info("Kayıtlı ML tahmin sonucu bulunamadı.")
        return
    
    # Dataframe oluştur
    df_data = []
    
    for pred in predictions:
        was_correct_map = {-1: "Beklemede", 0: "❌ Yanlış", 1: "✅ Doğru"}
        
        row = {
            "ID": pred["id"],
            "Hisse": pred["symbol"],
            "Tarih": pred["prediction_date"],
            "Hedef Tarih": pred["target_date"] if pred["target_date"] else "Belirtilmemiş",
            "Fiyat": f"{pred['current_price']:.2f} ₺",
            "Tahmin": f"{pred['prediction_percentage']*100:.1f}%",
            "Güven": f"{pred['confidence_score']*100:.1f}%",
            "Model": pred["model_type"],
            "Sonuç": was_correct_map.get(pred["was_correct"], "Beklemede")
        }
        
        # Gerçekleşen sonuç varsa ekle
        if pred["actual_result"] is not None:
            row["Gerçekleşen"] = f"{pred['actual_result']*100:.1f}%"
        else:
            row["Gerçekleşen"] = "-"
            
        df_data.append(row)
    
    # DataFrame oluştur
    import pandas as pd
    history_df = pd.DataFrame(df_data)
    
    # Tabloyu göster
    st.dataframe(history_df, use_container_width=True)
    
    # Tahmin Sonucu Doğrulama
    st.subheader("Tahmin Sonucu Doğrulama")
    st.markdown("""
    Geçmiş bir tahminin gerçekleşen sonucunu işaretlemek için aşağıdaki formu kullanın.
    Doğrulama işlemi, modelin başarı oranını takip etmenizi sağlar.
    """)
    
    verify_col1, verify_col2, verify_col3 = st.columns(3)
    
    with verify_col1:
        prediction_id = st.number_input("Tahmin ID", min_value=1, step=1, key="verify_prediction_id")
    
    with verify_col2:
        actual_result = st.number_input("Gerçekleşen Değişim (%)", min_value=-100.0, max_value=100.0, step=0.1, key="verify_actual_result")
        actual_result = actual_result / 100  # Yüzde değerini ondalık değere dönüştür
    
    with verify_col3:
        was_correct = st.selectbox("Tahmin Doğru muydu?", ["Evet", "Hayır"], key="verify_was_correct")
        was_correct_value = 1 if was_correct == "Evet" else 0
    
    # Doğrulama butonu
    if st.button("Tahmin Sonucunu Kaydet", key="verify_prediction_button"):
        try:
            success = update_ml_prediction_result(prediction_id, actual_result, was_correct_value)
            if success:
                st.success(f"Tahmin #{prediction_id} başarıyla güncellendi.")
                st.experimental_rerun()  # Sayfayı yenile
            else:
                st.error("Tahmin güncellenirken bir hata oluştu.")
        except Exception as e:
            st.error(f"Hata: {str(e)}")
            
    # Tahmin Sonuç Grafikleri
    if stats['verified_predictions'] > 0:
        st.subheader("Tahmin Performans Analizi")
        
        graph_col1, graph_col2 = st.columns(2)
        
        with graph_col1:
            # Başarı oranı pasta grafiği
            import plotly.graph_objects as go
            labels = ['Doğru Tahminler', 'Yanlış Tahminler']
            values = [stats['correct_predictions'], stats['verified_predictions'] - stats['correct_predictions']]
            
            fig = go.Figure(data=[go.Pie(labels=labels, values=values, hole=.4)])
            fig.update_layout(title_text="Doğru/Yanlış Tahmin Oranı")
            st.plotly_chart(fig, use_container_width=True)
            
        with graph_col2:
            # Model başarı grafiği
            try:
                conn = sqlite3.connect(DB_FILE)
                cursor = conn.cursor()
                
                # Her model için başarı oranını hesapla
                cursor.execute("""
                SELECT model_type, 
                       COUNT(*) as total,
                       SUM(CASE WHEN was_correct = 1 THEN 1 ELSE 0 END) as correct
                FROM ml_predictions
                WHERE was_correct != -1
                GROUP BY model_type
                """)
                
                model_stats = cursor.fetchall()
                conn.close()
                
                if model_stats:
                    model_names = [ms[0] for ms in model_stats]
                    success_rates = [ms[2]/ms[1]*100 if ms[1] > 0 else 0 for ms in model_stats]
                    
                    fig = go.Figure(data=[go.Bar(x=model_names, y=success_rates)])
                    fig.update_layout(title_text="Model Başarı Oranları (%)", yaxis_range=[0, 100])
                    st.plotly_chart(fig, use_container_width=True)
            except Exception as e:
                st.error(f"Grafik oluşturulurken hata: {str(e)}")

def create_future_prediction_chart(current_price, prediction_data, last_date):
    """
    Tahmin grafiği oluşturur
    """
    try:
        # Tahmin verilerini al
        predicted_price = prediction_data.get('point_prediction', current_price * 1.05)
        lower_bound = prediction_data.get('lower_bound', current_price * 0.95)
        upper_bound = prediction_data.get('upper_bound', current_price * 1.15)
        days = prediction_data.get('days', 30)
        
        # Gelecek tarihleri manuel olarak liste olarak oluştur
        future_dates = []
        for i in range(1, days + 1):
            if isinstance(last_date, pd.Timestamp):
                future_dates.append(last_date + pd.Timedelta(days=i))
            else:
                future_dates.append(datetime.now() + timedelta(days=i))
                
        # Tahmin noktalarını oluştur
        y_pred = []
        y_lower = []
        y_upper = []
        
        for i in range(days):
            # Doğrusal ilerleme
            progress = i / (days - 1)
            
            # Merkez tahmin
            center_prediction = current_price + (predicted_price - current_price) * progress
            
            # Alt ve üst sınırlar
            lower_prediction = current_price + (lower_bound - current_price) * progress
            upper_prediction = current_price + (upper_bound - current_price) * progress
            
            # Rasgele gürültü ekle (gerçekçilik için)
            noise = np.random.normal(0, 0.005 * current_price)
            
            y_pred.append(center_prediction + noise)
            y_lower.append(lower_prediction)
            y_upper.append(upper_prediction)
            
        # Grafik oluştur
        fig = go.Figure()
        
        # Tahmin çizgisi
        fig.add_trace(go.Scatter(
            x=future_dates, 
            y=y_pred,
            mode='lines',
            name='ML Tahmini',
            line=dict(color='blue')
        ))
        
        # Güven aralığı
        fig.add_trace(go.Scatter(
            x=future_dates + future_dates[::-1],
            y=y_upper + y_lower[::-1],
            fill='toself',
            fillcolor='rgba(0, 176, 246, 0.2)',
            line=dict(color='rgba(255,255,255,0)'),
            name='Tahmin Aralığı (%90)',
            showlegend=True
        ))
        
        # Düzen ayarları
        fig.update_layout(
            title=f"{days} Günlük Fiyat Tahmini",
            xaxis_title="Tarih",
            yaxis_title="Fiyat (TL)",
            legend_title="Tahmin",
            hovermode="x unified",
            height=500
        )
        
        return fig
    except Exception as e:
        st.error(f"Tahmin grafiği oluşturma hatası: {str(e)}")
        return None

# Gemini API ile haber analizi fonksiyonu 
def analyze_news_with_gemini(url, log_container=None):
    """Gemini API kullanarak haber analizi yapar"""
    # Global değişkenleri kullan
    global gemini_pro
    global genai
    
    try:
        if gemini_pro is None:
            # Eğer gemini_pro değişkeni None ise, model listesindeki diğer modelleri deneyelim
            try:
                import google.generativeai as genai
                
                # API anahtarını kontrol et ve yapılandır
                GEMINI_API_KEY = "AIzaSyANEpZjZCV9zYtUsMJ5BBgMzkrf8yu8kM8"
                if GEMINI_API_KEY:
                    genai.configure(api_key=GEMINI_API_KEY)
                
                model_options = [
                    'gemini-2.0-pro-exp', 'gemini-2.0-flash', 'gemini-2.0-flash-001',
                    'gemini-1.5-pro-latest', 'gemini-1.5-flash-latest', 'gemini-1.5-flash-8b-exp',
                    'gemini-1.5-pro-002', 'gemini-1.5-pro-001', 'gemini-1.5-pro',
                    'gemini-1.5-flash-002', 'gemini-1.5-flash-001', 'gemini-1.5-flash',
                    'gemini-1.0-ultra', 'gemini-1.0-pro'
                ]
                
                for model_name in model_options:
                    try:
                        if log_container:
                            display_log_message(f"{model_name} modeli deneniyor...", log_container)
                        test_model = genai.GenerativeModel(model_name)
                        # Test et
                        response = test_model.generate_content("Test")
                        # Başarılı ise kaydet
                        gemini_pro = test_model
                        if log_container:
                            display_log_message(f"{model_name} modeline bağlantı başarılı!", log_container, "success")
                        break
                    except Exception as model_error:
                        if log_container:
                            display_log_message(f"{model_name} modeline bağlanılamadı: {str(model_error)}", log_container, "warning")
                        continue
            except Exception as genai_error:
                if log_container:
                    display_log_message(f"Genai kütüphanesi hatası: {str(genai_error)}", log_container, "error")
            
        if gemini_pro is None:
            if log_container:
                display_log_message("Hiçbir Gemini API modeline bağlanılamadı", log_container, "warning")
            return {
                "success": False,
                "error": "Gemini API kullanılamıyor"
            }
        
        if log_container:
            display_log_message(f"Gemini API ile analiz ediliyor: {url}", log_container)
        
        # Basit prompt ile haber analizi iste
        prompt = f"""
Lütfen bu haber URL'sini analiz et: {url}

Analiz için bir JSON çıktısı döndür, şu formatta:
{{
  "success": true,
  "title": "Haber başlığı",
  "publish_date": "Yayın tarihi (eğer bulunursa)",
  "authors": "Yazar isimleri (eğer bulunursa)",
  "content": "Özet içerik",
  "sentiment": "Olumlu, Nötr veya Olumsuz",
  "sentiment_score": 0.75, // 0-1 arası bir değer, 1 en olumlu
  "ai_summary": "Kısa bir özet",
  "ai_analysis": {{
    "etki": "olumlu/olumsuz/nötr",
    "etki_sebebi": "Bu haberin neden olumlu/olumsuz/nötr olduğuna dair kısa açıklama",
    "önemli_noktalar": ["Madde 1", "Madde 2"]
  }}
}}

Eğer URL'ye erişemez veya içeriği analiz edemezsen, şunu döndür:
{{
  "success": false,
  "error": "Hata açıklaması"
}}
"""
        
        response = gemini_pro.generate_content(prompt)
        response_text = response.text
        
        # JSON yanıtını çıkar
        
        # Yanıttan JSON kısmını bul
        json_match = re.search(r'({[\s\S]*})', response_text)
        if json_match:
            json_str = json_match.group(1)
            try:
                result = json.loads(json_str)
                if log_container:
                    display_log_message("Gemini analizi başarılı", log_container, "success")
                return result
            except json.JSONDecodeError as json_e:
                if log_container:
                    display_log_message(f"JSON çözümleme hatası: {str(json_e)}", log_container, "error")
        
        if log_container:
            display_log_message("Gemini yanıtı işlenemedi", log_container, "error")
        return {
            "success": False,
            "error": "Yanıt işlenemedi"
        }
        
    except Exception as e:
        if log_container:
            display_log_message(f"Gemini analiz hatası: {str(e)}", log_container, "error")
        return {
            "success": False,
            "error": str(e)
        }