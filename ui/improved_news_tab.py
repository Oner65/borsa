import streamlit as st
import pandas as pd
from datetime import datetime, timedelta
import time
import requests
from bs4 import BeautifulSoup
import os
import json
try:
    from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification
    TRANSFORMERS_AVAILABLE = True
except ImportError:
    TRANSFORMERS_AVAILABLE = False
    st.warning("Transformers kÃ¼tÃ¼phanesi bulunamadÄ±. DuyarlÄ±lÄ±k analizi basit metotlar kullanÄ±larak yapÄ±lacak.")
try:
    import nltk
    from nltk.tokenize import sent_tokenize
    NLTK_AVAILABLE = True
    # Ä°lk Ã§alÄ±ÅŸtÄ±rmada NLTK veri paketini indirme
    try:
        nltk.data.find('tokenizers/punkt')
    except LookupError:
        nltk.download('punkt')
except ImportError:
    NLTK_AVAILABLE = False
import traceback

# Kendi eÄŸittiÄŸimiz duyarlÄ±lÄ±k analizi modelini kullan
try:
    import sys
    import os
    # Proje kÃ¶k dizinine eriÅŸ
    project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    if project_root not in sys.path:
        sys.path.append(project_root)
    from ai.sentiment_analysis import SentimentAnalyzer
    SENTIMENT_ANALYZER_AVAILABLE = True
    # Sentiment analyzer Ã¶rneÄŸi oluÅŸtur
    sentiment_analyzer = SentimentAnalyzer()
except Exception as e:
    SENTIMENT_ANALYZER_AVAILABLE = False
    st.error(f"DuyarlÄ±lÄ±k analizi modeli yÃ¼klenirken hata: {str(e)}")

# API anahtarÄ± kontrolÃ¼
NEWS_API_KEY = os.environ.get("NEWS_API_KEY", "")

# Log mesajlarÄ± iÃ§in yardÄ±mcÄ± fonksiyon
def display_log_message(message, log_container=None, type="info"):
    import logging
    logger = logging.getLogger(__name__)
    
    if type == "error":
        logger.error(message)
        if log_container and getattr(log_container, "_expanded", False):
            log_container.error(message)
    elif type == "warning":
        logger.warning(message)
        if log_container and getattr(log_container, "_expanded", False):
            log_container.warning(message)
    else:
        logger.info(message)
        if log_container and getattr(log_container, "_expanded", False):
            log_container.info(message)

# Sentiment analiz modeli - global tanÄ±mlama ve lazy loading
@st.cache_resource
def load_sentiment_model():
    if not TRANSFORMERS_AVAILABLE:
        return lambda text: [{"label": "POSITIVE", "score": 0.5}]
        
    try:
        tokenizer = AutoTokenizer.from_pretrained("dbmdz/bert-base-turkish-cased")
        model = AutoModelForSequenceClassification.from_pretrained("dbmdz/bert-base-turkish-cased")
        return pipeline("sentiment-analysis", model=model, tokenizer=tokenizer)
    except Exception as e:
        st.error(f"Model yÃ¼klenirken hata oluÅŸtu: {str(e)}")
        # Fallback olarak basit bir fonksiyon dÃ¶ndÃ¼r
        return lambda text: [{"label": "POSITIVE", "score": 0.5}]

# Basit duyarlÄ±lÄ±k analizi - transformers olmadÄ±ÄŸÄ±nda kullanÄ±lÄ±r
def simple_sentiment_analysis(text):
    """Basit kelime tabanlÄ± duyarlÄ±lÄ±k analizi"""
    if not text:
        return {"label": "POSITIVE", "score": 0.5}
        
    # TÃ¼rkÃ§e olumlu ve olumsuz kelimeler
    positive_words = {
        'artÄ±ÅŸ', 'yÃ¼kseliÅŸ', 'kazanÃ§', 'kÃ¢r', 'rekor', 'baÅŸarÄ±', 'pozitif', 'olumlu', 'gÃ¼Ã§lÃ¼', 'bÃ¼yÃ¼me',
        'iyileÅŸme', 'yÃ¼kseldi', 'arttÄ±', 'Ã§Ä±ktÄ±', 'gÃ¼ven', 'istikrar', 'avantaj', 'fÄ±rsat', 'yatÄ±rÄ±m',
        'imzalandÄ±', 'anlaÅŸma', 'destek', 'teÅŸvik', 'ivme', 'fayda', 'geliÅŸti', 'yeni', 'ileri'
    }
    
    negative_words = {
        'dÃ¼ÅŸÃ¼ÅŸ', 'kayÄ±p', 'zarar', 'risk', 'gerileme', 'olumsuz', 'negatif', 'zayÄ±f', 'belirsizlik',
        'endiÅŸe', 'azaldÄ±', 'dÃ¼ÅŸtÃ¼', 'kaybetti', 'gecikme', 'borÃ§', 'iflas', 'kriz', 'tehdit', 'sorun',
        'baÅŸarÄ±sÄ±z', 'yaptÄ±rÄ±m', 'ceza', 'iptal', 'durgunluk'
    }
    
    # Metin iÃ§indeki kelimeleri kontrol et
    text = text.lower()
    words = text.split()
    
    positive_count = sum(1 for word in words if word in positive_words)
    negative_count = sum(1 for word in words if word in negative_words)
    
    total = positive_count + negative_count
    if total == 0:
        return {"label": "POSITIVE", "score": 0.5}
    
    score = positive_count / total if total > 0 else 0.5
    label = "POSITIVE" if score >= 0.5 else "NEGATIVE"
    
    return {"label": label, "score": score if label == "POSITIVE" else 1 - score}

# Haber iÃ§eriÄŸi Ã§ekme - geliÅŸtirilmiÅŸ versiyon
def fetch_news_content(url, log_container=None):
    if not url or url == "#":
        display_log_message("GeÃ§ersiz URL", log_container, "warning")
        return None
        
    try:
        # FarklÄ± User-Agent'lar deneyelim
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
        }
        
        display_log_message(f"Ä°Ã§erik Ã§ekiliyor: {url}", log_container)
        try:
            response = requests.get(url, headers=headers, timeout=15)
            response.raise_for_status()  # HTTP hatalarÄ±nÄ± yakala
        except requests.exceptions.RequestException as e:
            display_log_message(f"Ä°stek hatasÄ±: {str(e)}", log_container, "error")
            # Alternatif User-Agent ile tekrar dene
            headers = {
                "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/15.0 Safari/605.1.15"
            }
            try:
                display_log_message("Alternatif User-Agent ile tekrar deneniyor...", log_container)
                response = requests.get(url, headers=headers, timeout=15)
                response.raise_for_status()
            except requests.exceptions.RequestException as e:
                display_log_message(f"Ä°kinci deneme baÅŸarÄ±sÄ±z: {str(e)}", log_container, "error")
                return None
            
        # Ä°Ã§eriÄŸi parse et
        try:
            soup = BeautifulSoup(response.content, "html.parser")
        except Exception as e:
            display_log_message(f"HTML ayrÄ±ÅŸtÄ±rma hatasÄ±: {str(e)}", log_container, "error")
            return None
        
        # Makale iÃ§eriÄŸini bulmaya Ã§alÄ±ÅŸ - farklÄ± yÃ¶ntemler dene
        content = ""
        
        # BaÅŸlÄ±ÄŸÄ± almaya Ã§alÄ±ÅŸ
        title = ""
        title_tag = soup.find("title")
        if title_tag:
            title = title_tag.get_text().strip()
            display_log_message(f"BaÅŸlÄ±k bulundu: {title[:50]}...", log_container)
        
        # YaygÄ±n makale iÃ§erik alanlarÄ±nÄ± kontrol et (geniÅŸletilmiÅŸ)
        article_selectors = [
            "article", "div.content", "div.article-body", "div.news-detail", "div.news-content",
            "div.post-content", "div.entry-content", "div.story-body", "div.article", 
            ".article__content", ".news-item", ".news-text", "#content-area", "#article-body",
            ".content-detail", ".article-text", ".news__content", ".article-container"
        ]
        
        for selector in article_selectors:
            try:
                article = soup.select_one(selector)
                if article:
                    # Ä°Ã§erik paragraflarÄ±nÄ± bul
                    paragraphs = article.find_all("p")
                    if paragraphs:
                        content = " ".join(p.get_text().strip() for p in paragraphs)
                        display_log_message(f"Ä°Ã§erik bulundu ('{selector}' seÃ§icisiyle): {len(content)} karakter", log_container)
                        break
            except Exception as e:
                display_log_message(f"SeÃ§ici '{selector}' iÅŸlenirken hata: {str(e)}", log_container, "warning")
                continue
        
        # Hala iÃ§erik bulunamadÄ±ysa, tÃ¼m paragraflarÄ± dene
        if not content:
            display_log_message("Standart seÃ§icilerle iÃ§erik bulunamadÄ±, tÃ¼m paragraflar deneniyor...", log_container)
            paragraphs = soup.find_all("p")
            if paragraphs:
                # En az 30 karakterlik paragraflarÄ± al
                valid_paragraphs = [p.get_text().strip() for p in paragraphs if len(p.get_text().strip()) > 30]
                if valid_paragraphs:
                    content = " ".join(valid_paragraphs)
                    display_log_message(f"TÃ¼m paragraflardan iÃ§erik bulundu: {len(content)} karakter", log_container)
            
        # Ä°Ã§erik yoksa ve haber sitesi bilinen bir siteyse Ã¶zel selectorlar dene
        if not content and "bloomberght.com" in url:
            display_log_message("BloombergHT iÃ§in Ã¶zel seÃ§iciler deneniyor...", log_container)
            paragraphs = soup.select(".news-content p, .paywall-content p")
            if paragraphs:
                content = " ".join(p.get_text().strip() for p in paragraphs)
        
        if not content and "bigpara.com" in url:
            display_log_message("BigPara iÃ§in Ã¶zel seÃ§iciler deneniyor...", log_container)
            paragraphs = soup.select(".detailText p")
            if paragraphs:
                content = " ".join(p.get_text().strip() for p in paragraphs)
        
        # Ä°Ã§erik yoksa
        if not content:
            display_log_message("Ä°Ã§erik bulunamadÄ±, meta aÃ§Ä±klamasÄ± deneniyor...", log_container, "warning")
            # Son Ã§are: Meta aÃ§Ä±klamasÄ±nÄ± al
            meta_desc = soup.find("meta", attrs={"name": "description"}) or soup.find("meta", attrs={"property": "og:description"})
            if meta_desc:
                content = meta_desc.get("content", "")
                display_log_message(f"Meta aÃ§Ä±klamasÄ±ndan iÃ§erik bulundu: {len(content)} karakter", log_container)
        
        # Hala iÃ§erik yoksa
        if not content:
            display_log_message("Ä°Ã§erik bulunamadÄ±!", log_container, "error")
            return None
        
        # Tarih elementi
        publish_date = ""
        date_selectors = [
            'meta[property="article:published_time"]',
            'time', 
            'span.date', 
            'div.date',
            '.publish-date',
            '.news-date',
            '.article-date',
            'meta[property="og:published_time"]'
        ]
        
        for selector in date_selectors:
            try:
                date_element = soup.select_one(selector)
                if date_element:
                    if selector.startswith('meta'):
                        publish_date = date_element.get('content', '')
                    else:
                        publish_date = date_element.get_text().strip()
                    if publish_date:
                        display_log_message(f"YayÄ±n tarihi bulundu: {publish_date}", log_container)
                        break
            except Exception:
                continue
        
        return {
            "title": title,
            "content": content,
            "publish_date": publish_date,
            "authors": "BelirtilmemiÅŸ"  # Yazarlar varsayÄ±lan olarak belirtilmedi
        }
                
    except Exception as e:
        display_log_message(f"Ä°Ã§erik Ã§ekerken hata: {str(e)}", log_container, "error")
        import traceback
        display_log_message(f"Hata detayÄ±: {traceback.format_exc()}", log_container, "error")
        return None

# Metni Ã¶zetleme fonksiyonu
def summarize_text(text, max_length=150):
    if not text:
        return "Ä°Ã§erik bulunamadÄ±."
        
    # Metin Ã§ok kÄ±saysa direkt dÃ¶ndÃ¼r
    if len(text) <= max_length:
        return text
    
    if NLTK_AVAILABLE:
        try:
            # Metni cÃ¼mlelere ayÄ±r
            sentences = sent_tokenize(text)
            
            # Metin Ã§ok uzunsa ilk birkaÃ§ cÃ¼mleyi al
            summary = ""
            for sentence in sentences:
                if len(summary) + len(sentence) < max_length:
                    summary += sentence + " "
                else:
                    break
                    
            return summary.strip()
        except Exception:
            # NLTK ile Ã¶zetleme baÅŸarÄ±sÄ±z olursa basit kesme kullan
            return text[:max_length] + "..."
    else:
        # NLTK yoksa basit kesme kullan
        return text[:max_length] + "..."

# DuyarlÄ±lÄ±k deÄŸerini yorumlama fonksiyonu
def get_sentiment_explanation(score):
    if score >= 0.7:
        return "Bu haber piyasa/ÅŸirket iÃ§in oldukÃ§a olumlu iÃ§erik barÄ±ndÄ±rÄ±yor."
    elif score >= 0.55:
        return "Bu haber genel olarak olumlu bir ton taÅŸÄ±yor."
    elif score <= 0.3:
        return "Bu haber piyasa/ÅŸirket iÃ§in olumsuz iÃ§erik barÄ±ndÄ±rÄ±yor."
    elif score <= 0.45:
        return "Bu haber hafif olumsuz bir tona sahip."
    else:
        return "Bu haber nÃ¶tr bir tona sahip."

# DuyarlÄ±lÄ±k analizi fonksiyonu
def analyze_news(url, log_container=None):
    try:
        if not url or url == "#":
            display_log_message(f"GeÃ§ersiz URL: '{url}'", log_container, "warning")
            return {"success": False, "error": "GeÃ§ersiz URL"}
            
        # URL formatÄ±nÄ± kontrol et
        if not url.startswith(('http://', 'https://')):
            display_log_message(f"GeÃ§ersiz URL formatÄ±: '{url}'", log_container, "warning")
            return {"success": False, "error": f"GeÃ§ersiz URL formatÄ±: {url}"}
        
        display_log_message(f"Haber analiz ediliyor: {url}", log_container)
        
        # Haber iÃ§eriÄŸini Ã§ek
        news_data = fetch_news_content(url, log_container)
        if not news_data:
            display_log_message(f"Haber iÃ§eriÄŸi Ã§ekilemedi: {url}", log_container, "warning")
            return {"success": False, "error": "Haber iÃ§eriÄŸi Ã§ekilemedi"}
            
        if not news_data.get("content"):
            display_log_message(f"Haber iÃ§eriÄŸi boÅŸ: {url}", log_container, "warning") 
            return {"success": False, "error": "Haber iÃ§eriÄŸi boÅŸ"}
        
        content = news_data.get("content")
        display_log_message(f"Ä°Ã§erik uzunluÄŸu: {len(content)} karakter", log_container)
        
        # Ä°Ã§erik Ã§ok uzunsa modelin iÅŸleyebileceÄŸi boyuta getir
        if len(content) > 500:
            # Analiz iÃ§in ilk 500 karakter
            analysis_content = content[:500]
            display_log_message(f"Ä°Ã§erik kÄ±saltÄ±ldÄ±: {len(analysis_content)} karakter", log_container)
        else:
            analysis_content = content
            
        # Ã–zet oluÅŸtur
        summary = summarize_text(content)
        
        display_log_message("DuyarlÄ±lÄ±k analizi yapÄ±lÄ±yor...", log_container)
            
        # DuyarlÄ±lÄ±k analizi yap - Ã¶nce kendi modelimizi dene
        if SENTIMENT_ANALYZER_AVAILABLE:
            try:
                display_log_message("Ã–zel eÄŸitilmiÅŸ model kullanÄ±lÄ±yor...", log_container)
                # scikit-learn modeli kullan
                prediction = sentiment_analyzer.predict([analysis_content])[0]
                probabilities = sentiment_analyzer.predict_proba([analysis_content])[0]
                
                # 0 (negatif) veya 1 (pozitif) - bunu "NEGATIVE" veya "POSITIVE" formatÄ±na dÃ¶nÃ¼ÅŸtÃ¼r
                label = "POSITIVE" if prediction == 1 else "NEGATIVE"
                
                # -1 ile 1 arasÄ±nda deÄŸer dÃ¶ndÃ¼rÃ¼r, bunu 0-1 arasÄ±na normalize et
                score = (probabilities + 1) / 2 if label == "POSITIVE" else 1 - ((probabilities + 1) / 2)
                
                result = {"label": label, "score": score}
                display_log_message(f"DuyarlÄ±lÄ±k analiz sonucu: {result}", log_container)
            except Exception as e:
                display_log_message(f"Ã–zel model hatasÄ±: {str(e)}", log_container, "error")
                display_log_message(traceback.format_exc(), log_container, "error")
                # Hata durumunda transformers veya basit analiz yap
                if TRANSFORMERS_AVAILABLE:
                    try:
                        sentiment_model = load_sentiment_model()
                        display_log_message(f"TransformersAPI kullanÄ±lÄ±yor...", log_container)
                        result = sentiment_model(analysis_content)[0]
                        display_log_message(f"TransformersAPI sonucu: {result}", log_container)
                    except Exception as e:
                        display_log_message(f"Transformers hatasÄ±: {str(e)}", log_container, "error")
                        # Hata durumunda basit analiz yap
                        display_log_message("Basit duyarlÄ±lÄ±k analizi kullanÄ±lÄ±yor...", log_container)
                        result = simple_sentiment_analysis(analysis_content)
                        display_log_message(f"Basit analiz sonucu: {result}", log_container)
                else:
                    # Transformers yoksa basit analiz yap
                    display_log_message("Basit duyarlÄ±lÄ±k analizi kullanÄ±lÄ±yor...", log_container)
                    result = simple_sentiment_analysis(analysis_content)
                    display_log_message(f"Basit analiz sonucu: {result}", log_container)
        elif TRANSFORMERS_AVAILABLE:
            try:
                sentiment_model = load_sentiment_model()
                display_log_message(f"TransformersAPI kullanÄ±lÄ±yor...", log_container)
                result = sentiment_model(analysis_content)[0]
                display_log_message(f"TransformersAPI sonucu: {result}", log_container)
            except Exception as e:
                display_log_message(f"Transformers hatasÄ±: {str(e)}", log_container, "error")
                # Hata durumunda basit analiz yap
                display_log_message("Basit duyarlÄ±lÄ±k analizi kullanÄ±lÄ±yor...", log_container)
                result = simple_sentiment_analysis(analysis_content)
                display_log_message(f"Basit analiz sonucu: {result}", log_container)
        else:
            # Transformers yoksa basit analiz yap
            display_log_message("Basit duyarlÄ±lÄ±k analizi kullanÄ±lÄ±yor...", log_container)
            result = simple_sentiment_analysis(analysis_content)
            display_log_message(f"Basit analiz sonucu: {result}", log_container)
        
        # Sonucu formatla
        label = result.get("label", "")
        score = result.get("score", 0.5)
        
        # AÃ§Ä±klama oluÅŸtur
        explanation = get_sentiment_explanation(score)
        
        return {
            "success": True,
            "title": news_data.get("title", ""),
            "content": content,
            "summary": summary,
            "authors": news_data.get("authors", "BelirtilmemiÅŸ"),
            "sentiment": {
                "label": label,
                "score": score,
                "explanation": explanation
            },
            "publish_date": news_data.get("publish_date", "")
        }
        
    except Exception as e:
        display_log_message(f"Haber analiz edilirken hata: {str(e)}", log_container, "error")
        import traceback
        display_log_message(f"Hata detayÄ±: {traceback.format_exc()}", log_container, "error")
        return {"success": False, "error": f"Analiz hatasÄ±: {str(e)}"}

# NewsAPI alternatifi - farklÄ± kaynaklardan haber toplama
def get_stock_news(ticker, num_news=5, max_days=30, debug=False):
    """
    Belirli bir hisse senedi iÃ§in haberleri getiren fonksiyon.
    
    Args:
        ticker (str): Hisse senedi sembolÃ¼ (Ã¶rn. 'THYAO')
        num_news (int): Getirilecek haber sayÄ±sÄ±
        max_days (int): Haberlerin maksimum kaÃ§ gÃ¼n Ã¶ncesine ait olabileceÄŸi
        debug (bool): Hata ayÄ±klama mesajlarÄ±nÄ±n gÃ¶sterilip gÃ¶sterilmeyeceÄŸi
        
    Returns:
        dict: AÅŸaÄŸÄ±daki anahtarlarÄ± iÃ§eren sÃ¶zlÃ¼k:
            - success (bool): Ä°ÅŸlemin baÅŸarÄ±lÄ± olup olmadÄ±ÄŸÄ±
            - message (str): Ä°ÅŸlem sonucu mesajÄ±
            - data (list): Haber verileri
            - logs (list): Ä°ÅŸlem sÄ±rasÄ±nda oluÅŸan loglar
    """
    import time
    from datetime import datetime, timedelta
    import random
    import re
    from bs4 import BeautifulSoup
    
    # YardÄ±mcÄ± iÅŸlevler
    def log_message(message, level="INFO"):
        """Log mesajÄ± oluÅŸturur"""
        logs.append(f"[{level}] {message}")
        if debug:
            print(f"[{level}] {message}")
            
    # Ticker-ÅŸirket ismi eÅŸleÅŸtirmeleri
    ticker_to_company = {
        "THYAO": "TÃ¼rk Hava YollarÄ±",
        "TUPRS": "TÃ¼praÅŸ",
        "ASELS": "Aselsan",
        "GARAN": "Garanti BankasÄ±",
        "EREGL": "EreÄŸli Demir Ã‡elik",
        "AKBNK": "Akbank",
        "KCHOL": "KoÃ§ Holding",
        "SAHOL": "SabancÄ± Holding",
        "YKBNK": "YapÄ± Kredi BankasÄ±",
        "BIMAS": "BÄ°M"
    }
    
    # HTML temizleme iÅŸlevi
    def clean_html(html_text):
        """HTML iÃ§eriÄŸini dÃ¼z metne dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r"""
        if not html_text:
            return ""
        try:
            # HTML etiketlerini kaldÄ±r
            soup = BeautifulSoup(html_text, "html.parser")
            text = soup.get_text(separator=" ", strip=True)
            # Fazla boÅŸluklarÄ± temizle
            text = re.sub(r'\s+', ' ', text).strip()
            return text
        except Exception as e:
            log_message(f"HTML temizleme hatasÄ±: {str(e)}", "ERROR")
            return html_text
    
    # SonuÃ§ ve log deÄŸiÅŸkenleri
    result = {"success": False, "message": "", "data": [], "logs": []}
    logs = []
    news_data = []
    
    try:
        # Google News provider'Ä±nÄ± baÅŸlat
        log_message(f"{ticker} iÃ§in Google News baÅŸlatÄ±lÄ±yor...")
        google_news = GoogleNews()
        
        # Åirket adÄ±nÄ± bul veya ticker'Ä± kullan
        company_name = ticker_to_company.get(ticker, ticker)
        search_term = f"{company_name} hisse"
        
        log_message(f"Arama terimi: {search_term}")
        
        # Google News ile haber ara
        news_items = google_news.search(search_term, max_results=15)
        
        # Yetersiz sonuÃ§ varsa alternatif arama terimleri dene
        if len(news_items) < 3:
            log_message(f"Yetersiz sonuÃ§ ({len(news_items)}), alternatif arama yapÄ±lÄ±yor...")
            alt_terms = [f"{ticker} borsa", "ekonomi borsa", "piyasa analiz"]
            
            for term in alt_terms:
                log_message(f"Alternatif arama terimi: {term}")
                alt_items = google_news.search(term, max_results=10)
                if alt_items:
                    news_items.extend(alt_items)
                    if len(news_items) >= 10:
                        break
        
        log_message(f"Toplam {len(news_items)} haber bulundu, iÅŸleniyor...")
        
        # Haberleri iÅŸle
        for item in news_items:
            try:
                # Gerekli bilgileri Ã§Ä±kar
                title = item.get('title', '')
                link = item.get('link', '')
                desc = item.get('desc', '')
                site = item.get('site', '')
                date_str = item.get('datetime', '')
                
                # BoÅŸ alanlarÄ± kontrol et
                if not title or not link:
                    continue
                
                # AÃ§Ä±klama boÅŸsa baÅŸlÄ±ÄŸÄ± kullan
                if not desc:
                    desc = title
                else:
                    desc = clean_html(desc)
                
                # Haber kaynaÄŸÄ± kontrolÃ¼
                if not site:
                    # URL'den site adÄ±nÄ± Ã§Ä±karmaya Ã§alÄ±ÅŸ
                    match = re.search(r'https?://(?:www\.)?([^/]+)', link)
                    if match:
                        site = match.group(1)
                
                # Haber Ã¶ÄŸesini oluÅŸtur
                news_item = {
                    "title": title,
                    "link": link,
                    "description": desc[:300] + ('...' if len(desc) > 300 else ''),
                    "source": site,
                    "date": date_str,
                    "sentiment_score": 0,
                    "sentiment_label": "NÃ¶tr"
                }
                
                # Duygu analizi yap
                try:
                    from ai.sentiment_analyzer import SentimentAnalyzer
                    
                    analyzer = SentimentAnalyzer()
                    text_to_analyze = f"{title} {desc}"
                    
                    # Model kullanÄ±lamadÄ±ÄŸÄ±nda basit anahtar kelime tabanlÄ± duygu analizi
                    text = f"{title} {desc}"
                    
                    # Olumlu ve olumsuz kelimeler
                    positive_words = [
                        # Genel olumlu terimler
                        "artÄ±ÅŸ", "yÃ¼kseldi", "yÃ¼kseliÅŸ", "kazanÃ§", "baÅŸarÄ±", "olumlu", "gÃ¼Ã§lÃ¼", 
                        "kar", "bÃ¼yÃ¼me", "yatÄ±rÄ±m", "fÄ±rsat", "rekor", "gÃ¼ven", "avantaj",
                        # Hisse senedi ve finans ile ilgili olumlu terimler
                        "alÄ±m", "geri alÄ±m", "pay geri alÄ±m", "hedef fiyat", "yukarÄ± yÃ¶nlÃ¼", "artÄ±rÄ±ldÄ±", 
                        "yÃ¼kseltildi", "ivme", "gÃ¼Ã§leniyor", "zirve", "tavan", "prim", "aÅŸÄ±rÄ± alÄ±m", 
                        "gÃ¼Ã§lÃ¼ performans", "kÃ¢rlÄ±lÄ±k", "temettÃ¼", "beklentilerin Ã¼zerinde", "kapasite artÄ±ÅŸÄ±",
                        "lider", "pazar payÄ±", "bÃ¼yÃ¼dÃ¼", "arttÄ±", "geniÅŸleme", "ihracat", "yeni anlaÅŸma",
                        "ortaklÄ±k", "iÅŸbirliÄŸi", "strateji", "dijitalleÅŸme", "teknoloji", "dev", "program",
                        "iÅŸ hacmi", "raÄŸbet", "talep", "ihale", "kazandÄ±", "baÅŸarÄ±yla", "gelir artÄ±ÅŸÄ±"
                    ]
                    
                    negative_words = [
                        # Genel olumsuz terimler
                        "dÃ¼ÅŸÃ¼ÅŸ", "geriledi", "azaldÄ±", "zarar", "kayÄ±p", "olumsuz", "zayÄ±f", 
                        "risk", "endiÅŸe", "kriz", "tehlike", "yavaÅŸlama", "dezavantaj",
                        # Hisse senedi ve finans ile ilgili olumsuz terimler
                        "satÄ±ÅŸ baskÄ±sÄ±", "deÄŸer kaybÄ±", "daraldÄ±", "daralma", "borÃ§", "iflas", "konkordato",
                        "aÅŸaÄŸÄ± yÃ¶nlÃ¼", "indirildi", "dÃ¼ÅŸÃ¼rÃ¼ldÃ¼", "aÅŸÄ±rÄ± satÄ±m", "volatilite", "zayÄ±f performans",
                        "beklentilerin altÄ±nda", "ertelendi", "iptal", "durgunluk", "negatif", "dibe", "dip",
                        "indirim", "faiz artÄ±ÅŸÄ±", "vergi", "ceza", "yaptÄ±rÄ±m", "manipÃ¼lasyon", "soruÅŸturma",
                        "dava", "para cezasÄ±", "ÅŸikayet", "protesto", "grev", "maliyet artÄ±ÅŸÄ±", "fire"
                    ]
                    
                    # Metin Ã¶zel durumlarÄ± ele al - finans haberlerinde bazÄ± ifadeler Ã¶zel anlam taÅŸÄ±r
                    special_cases = [
                        {"phrase": "pay geri alÄ±m", "score": 1.0},
                        {"phrase": "hisse geri alÄ±m", "score": 1.0},
                        {"phrase": "hedef fiyat", "score": 0.8},
                        {"phrase": "tavan fiyat", "score": 0.7},
                        {"phrase": "ek sefer", "score": 0.7},
                        {"phrase": "yatÄ±rÄ±m tavsiyesi", "score": 0.6},
                        {"phrase": "al tavsiyesi", "score": 0.9},
                        {"phrase": "tut tavsiyesi", "score": 0.6},
                        {"phrase": "sat tavsiyesi", "score": 0.2}
                    ]
                    
                    # Ã–zel durumlarÄ± kontrol et
                    special_score = None
                    for case in special_cases:
                        if case["phrase"].lower() in text.lower():
                            special_score = case["score"]
                            log_message(f"Ã–zel durum tespit edildi: '{case['phrase']}', skor: {special_score}", "INFO")
                            break
                    
                    # EÄŸer Ã¶zel durum varsa, doÄŸrudan skoru ata
                    if special_score is not None:
                        score = special_score
                        label = "Olumlu" if score > 0.5 else ("NÃ¶tr" if score == 0.5 else "Olumsuz")
                    else:
                        # Kelime sayaÃ§larÄ±
                        positive_count = sum(1 for word in positive_words if word.lower() in text.lower())
                        negative_count = sum(1 for word in negative_words if word.lower() in text.lower())
                        
                        # Duygu skoru hesapla (0 ile 1 arasÄ±nda)
                        total = positive_count + negative_count
                        if total > 0:
                            # Pozitif sayÄ±sÄ± aÄŸÄ±rlÄ±klÄ±ysa skoru yÃ¼kselt
                            score = positive_count / (positive_count + negative_count)
                        else:
                            score = 0.5  # NÃ¶tr deÄŸer
                        
                        # Etiket belirle
                        if score > 0.6:
                            label = "Olumlu"
                        elif score < 0.4:
                            label = "Olumsuz"
                        else:
                            label = "NÃ¶tr"
                    
                    news_item["sentiment_score"] = score
                    news_item["sentiment_label"] = label
                
                except Exception as e:
                    log_message(f"Model tabanlÄ± duygu analizi baÅŸarÄ±sÄ±z: {str(e)}", "WARNING")
                    
                    # Model kullanÄ±lamadÄ±ÄŸÄ±nda basit anahtar kelime tabanlÄ± duygu analizi
                    text = f"{title} {desc}"
                    
                    # Olumlu ve olumsuz kelimeler
                    positive_words = [
                        # Genel olumlu terimler
                        "artÄ±ÅŸ", "yÃ¼kseldi", "yÃ¼kseliÅŸ", "kazanÃ§", "baÅŸarÄ±", "olumlu", "gÃ¼Ã§lÃ¼", 
                        "kar", "bÃ¼yÃ¼me", "yatÄ±rÄ±m", "fÄ±rsat", "rekor", "gÃ¼ven", "avantaj",
                        # Hisse senedi ve finans ile ilgili olumlu terimler
                        "alÄ±m", "geri alÄ±m", "pay geri alÄ±m", "hedef fiyat", "yukarÄ± yÃ¶nlÃ¼", "artÄ±rÄ±ldÄ±", 
                        "yÃ¼kseltildi", "ivme", "gÃ¼Ã§leniyor", "zirve", "tavan", "prim", "aÅŸÄ±rÄ± alÄ±m", 
                        "gÃ¼Ã§lÃ¼ performans", "kÃ¢rlÄ±lÄ±k", "temettÃ¼", "beklentilerin Ã¼zerinde", "kapasite artÄ±ÅŸÄ±",
                        "lider", "pazar payÄ±", "bÃ¼yÃ¼dÃ¼", "arttÄ±", "geniÅŸleme", "ihracat", "yeni anlaÅŸma",
                        "ortaklÄ±k", "iÅŸbirliÄŸi", "strateji", "dijitalleÅŸme", "teknoloji", "dev", "program",
                        "iÅŸ hacmi", "raÄŸbet", "talep", "ihale", "kazandÄ±", "baÅŸarÄ±yla", "gelir artÄ±ÅŸÄ±"
                    ]
                    
                    negative_words = [
                        # Genel olumsuz terimler
                        "dÃ¼ÅŸÃ¼ÅŸ", "geriledi", "azaldÄ±", "zarar", "kayÄ±p", "olumsuz", "zayÄ±f", 
                        "risk", "endiÅŸe", "kriz", "tehlike", "yavaÅŸlama", "dezavantaj",
                        # Hisse senedi ve finans ile ilgili olumsuz terimler
                        "satÄ±ÅŸ baskÄ±sÄ±", "deÄŸer kaybÄ±", "daraldÄ±", "daralma", "borÃ§", "iflas", "konkordato",
                        "aÅŸaÄŸÄ± yÃ¶nlÃ¼", "indirildi", "dÃ¼ÅŸÃ¼rÃ¼ldÃ¼", "aÅŸÄ±rÄ± satÄ±m", "volatilite", "zayÄ±f performans",
                        "beklentilerin altÄ±nda", "ertelendi", "iptal", "durgunluk", "negatif", "dibe", "dip",
                        "indirim", "faiz artÄ±ÅŸÄ±", "vergi", "ceza", "yaptÄ±rÄ±m", "manipÃ¼lasyon", "soruÅŸturma",
                        "dava", "para cezasÄ±", "ÅŸikayet", "protesto", "grev", "maliyet artÄ±ÅŸÄ±", "fire"
                    ]
                    
                    # Metin Ã¶zel durumlarÄ± ele al - finans haberlerinde bazÄ± ifadeler Ã¶zel anlam taÅŸÄ±r
                    special_cases = [
                        {"phrase": "pay geri alÄ±m", "score": 1.0},
                        {"phrase": "hisse geri alÄ±m", "score": 1.0},
                        {"phrase": "hedef fiyat", "score": 0.8},
                        {"phrase": "tavan fiyat", "score": 0.7},
                        {"phrase": "ek sefer", "score": 0.7},
                        {"phrase": "yatÄ±rÄ±m tavsiyesi", "score": 0.6},
                        {"phrase": "al tavsiyesi", "score": 0.9},
                        {"phrase": "tut tavsiyesi", "score": 0.6},
                        {"phrase": "sat tavsiyesi", "score": 0.2}
                    ]
                    
                    # Ã–zel durumlarÄ± kontrol et
                    special_score = None
                    for case in special_cases:
                        if case["phrase"].lower() in text.lower():
                            special_score = case["score"]
                            log_message(f"Ã–zel durum tespit edildi: '{case['phrase']}', skor: {special_score}", "INFO")
                            break
                    
                    # EÄŸer Ã¶zel durum varsa, doÄŸrudan skoru ata
                    if special_score is not None:
                        score = special_score
                        label = "Olumlu" if score > 0.5 else ("NÃ¶tr" if score == 0.5 else "Olumsuz")
                    else:
                        # Kelime sayaÃ§larÄ±
                        positive_count = sum(1 for word in positive_words if word.lower() in text.lower())
                        negative_count = sum(1 for word in negative_words if word.lower() in text.lower())
                        
                        # Duygu skoru hesapla (0 ile 1 arasÄ±nda)
                        total = positive_count + negative_count
                        if total > 0:
                            # Pozitif sayÄ±sÄ± aÄŸÄ±rlÄ±klÄ±ysa skoru yÃ¼kselt
                            score = positive_count / (positive_count + negative_count)
                        else:
                            score = 0.5  # NÃ¶tr deÄŸer
                        
                        # Etiket belirle
                        if score > 0.6:
                            label = "Olumlu"
                        elif score < 0.4:
                            label = "Olumsuz"
                        else:
                            label = "NÃ¶tr"
                    
                    news_item["sentiment_score"] = score
                    news_item["sentiment_label"] = label
                
                # Haber verisini listeye ekle
                news_data.append(news_item)
            
            except Exception as e:
                log_message(f"Haber Ã¶ÄŸesi iÅŸleme hatasÄ±: {str(e)}", "ERROR")
                continue
        
        # Haberleri duygu skoruna gÃ¶re sÄ±rala (olumlu haberler Ã¶nce)
        news_data.sort(key=lambda x: x["sentiment_score"], reverse=True)
        
        # Belirtilen sayÄ±da haberi al
        if len(news_data) > num_news:
            news_data = news_data[:num_news]
        
        # SonuÃ§ oluÅŸtur
        result = {
            "success": True,
            "message": f"{ticker} iÃ§in {len(news_data)} haber bulundu.",
            "data": news_data,
            "logs": logs
        }
        
    except Exception as e:
        log_message(f"Genel hata: {str(e)}", "ERROR")
        result = {
            "success": False,
            "message": f"Haber getirme hatasÄ±: {str(e)}",
            "data": [],
            "logs": logs
        }
    
    return result

# Streamlit arayÃ¼zÃ¼
def render_stock_news_tab():
    st.title("Hisse Senedi Haberleri ğŸ“°")
    
    # Session state yÃ¶netimi
    if 'show_news_analysis' not in st.session_state:
        st.session_state.show_news_analysis = False
        st.session_state.news_url = ""
        st.session_state.news_analysis_results = None
    
    if 'analyzed_news_ids' not in st.session_state:
        st.session_state.analyzed_news_ids = []
    
    # Ä°ÅŸlem gÃ¼nlÃ¼ÄŸÃ¼
    log_expander = st.expander("Ä°ÅŸlem GÃ¼nlÃ¼ÄŸÃ¼ (Detaylar iÃ§in tÄ±klayÄ±n)", expanded=False)
    
    # EÄŸer analiz gÃ¶sterilmesi gerekiyorsa
    if st.session_state.show_news_analysis and st.session_state.news_url:
        with st.spinner("Haber analiz ediliyor..."):
            if st.session_state.news_analysis_results is None:
                display_log_message("Haber analizi baÅŸlatÄ±lÄ±yor...", log_expander)
                analysis_results = analyze_news(st.session_state.news_url, log_expander)
                st.session_state.news_analysis_results = analysis_results
            else:
                analysis_results = st.session_state.news_analysis_results
            
            # Analiz sonuÃ§larÄ±nÄ± gÃ¶ster
            if analysis_results.get("success", False):
                # Haber iÃ§eriÄŸi iÃ§in container
                with st.expander("Haber Ä°Ã§eriÄŸi", expanded=True):
                    st.markdown(f"## {analysis_results['title']}")
                    st.markdown(f"**Yazar:** {analysis_results['authors']} | **Tarih:** {analysis_results['publish_date']}")
                    st.markdown("---")
                    st.markdown(analysis_results['content'])
                
                # Analiz sonuÃ§larÄ±
                st.subheader("Yapay Zeka Analizi")
                
                # DuyarlÄ±lÄ±k analizi
                sentiment = analysis_results['sentiment']['label']
                sentiment_score = analysis_results['sentiment']['score']
                sentiment_color = "green" if sentiment == "POSITIVE" else ("red" if sentiment == "NEGATIVE" else "gray")
                
                col1, col2 = st.columns([1, 3])
                with col1:
                    st.metric("DuyarlÄ±lÄ±k", sentiment, f"{sentiment_score:.2f}")
                
                with col2:
                    st.markdown(f"""
                    <div style="border-left:5px solid {sentiment_color}; padding-left:15px; margin-top:10px;">
                    <h4>Haber Ã–zeti</h4>
                    <p>{analysis_results['summary']}</p>
                    </div>
                    """, unsafe_allow_html=True)
                    
                    # DuyarlÄ±lÄ±k aÃ§Ä±klamasÄ±
                    st.markdown(f"""
                    <div style="margin-top:10px; padding:10px; background-color:#f8f9fa; border-radius:5px;">
                    <p><strong>Yorum:</strong> {analysis_results['sentiment']['explanation']}</p>
                    </div>
                    """, unsafe_allow_html=True)
                
                # Kapat butonu
                if st.button("Analizi Kapat", key="close_analysis"):
                    st.session_state.show_news_analysis = False
                    st.session_state.news_url = ""
                    st.session_state.news_analysis_results = None
                    st.experimental_rerun()
            else:
                st.error(f"Haber analizi yapÄ±lamadÄ±: {analysis_results.get('error', 'Bilinmeyen hata')}")
                if st.button("Geri DÃ¶n"):
                    st.session_state.show_news_analysis = False
                    st.session_state.news_url = ""
                    st.session_state.news_analysis_results = None
                    st.experimental_rerun()
        
        # Analiz modu aktifse, diÄŸer iÃ§erikleri gÃ¶sterme
        return
    
    # Normal haber arama arayÃ¼zÃ¼
    col1, col2, col3 = st.columns([3, 1.5, 1])
    
    with col1:
        stock_symbol = st.text_input("Hisse Senedi Kodu (Ã¶rn: THYAO)", "THYAO", key="news_stock_symbol")
    
    with col2:
        # Haber kaynaklarÄ± seÃ§imi
        available_providers = ["Google News", "Yahoo Finance"]
        selected_providers = st.multiselect(
            "Haber KaynaklarÄ±", 
            available_providers,
            default=available_providers,
            key="news_providers"
        )
    
    with col3:
        max_results = st.selectbox("Maksimum Haber", [5, 10, 15, 20], index=1)
        search_btn = st.button("Haberleri Getir")
    
    # SonuÃ§lar iÃ§in container
    results_container = st.container()
    
    if search_btn or ('news_last_symbol' in st.session_state and st.session_state.news_last_symbol == stock_symbol):
        stock_symbol = stock_symbol.upper().strip()
        st.session_state.news_last_symbol = stock_symbol
        
        display_log_message(f"{stock_symbol} ile ilgili haberler aranÄ±yor...", log_expander)
        
        with results_container:
            try:
                # En az bir kaynak seÃ§ilmemiÅŸse uyarÄ± ver
                if not selected_providers:
                    st.warning("LÃ¼tfen en az bir haber kaynaÄŸÄ± seÃ§in.")
                    return
                
                # Haberleri getir
                display_log_message("Haberler getiriliyor...", log_expander)
                result = get_stock_news(stock_symbol, num_news=max_results)
                
                # Haber sonuÃ§larÄ±nÄ± gÃ¶ster
                if isinstance(result, dict) and "data" in result:
                    news_list = result["data"]
                    display_log_message(f"get_stock_news fonksiyonu tarafÄ±ndan dÃ¶ndÃ¼rÃ¼len haber sayÄ±sÄ±: {len(news_list)}", log_expander)
                    
                    if news_list and len(news_list) > 0:
                        # Gerekli alanlarÄ± standardize et
                        standardized_news_list = []
                        for news_item in news_list:
                            # Eksik alanlarÄ± varsayÄ±lan deÄŸerlerle doldur
                            standardized_item = {
                                "title": news_item.get("title", "BaÅŸlÄ±k BulunamadÄ±"),
                                "url": news_item.get("link", "#"),  # "link" anahtarÄ± kullanÄ±lÄ±yor
                                "source": news_item.get("source", "Bilinmeyen Kaynak"),
                                "pub_date": news_item.get("date", ""),
                                "summary": news_item.get("description", "Bu haber iÃ§in Ã¶zet bulunmuyor."),  # "description" anahtarÄ± kullanÄ±lÄ±yor
                                "sentiment": news_item.get("sentiment_score", 0.5),  # "sentiment_score" anahtarÄ± kullanÄ±lÄ±yor
                                "image_url": news_item.get("image_url", "")
                            }
                            
                            standardized_news_list.append(standardized_item)
                            
                            # Log iÃ§in haber bilgilerini gÃ¶ster
                            display_log_message(f"Haber: {standardized_item['title']}, Kaynak: {standardized_item['source']}", log_expander)
                        
                        # Liste olarak dÃ¶nen haberleri DataFrame'e dÃ¶nÃ¼ÅŸtÃ¼r
                        news_df = pd.DataFrame(standardized_news_list)
                        
                        # TekrarlÄ± haberleri kaldÄ±r
                        news_df = news_df.drop_duplicates(subset=['title'], keep='first')
                        
                        display_log_message(f"{len(news_df)} haber bulundu", log_expander)
                        
                        # DataFrame'in sÃ¼tunlarÄ±nÄ± kontrol et ve gÃ¶rÃ¼ntÃ¼le
                        display_log_message(f"DataFrame sÃ¼tunlarÄ±: {list(news_df.columns)}", log_expander)
                        
                        # Haberleri gÃ¶ster
                        st.subheader(f"{stock_symbol} ile Ä°lgili Haberler")
                        
                        # Her haberi kart olarak gÃ¶ster
                        for idx, news in news_df.iterrows():
                            # DuyarlÄ±lÄ±k rengi ve etiketi
                            sentiment_value = float(news["sentiment"])
                            if sentiment_value > 0.65:
                                sentiment_color = "#4CAF50"  # green
                                sentiment_label = "Olumlu"
                            elif sentiment_value < 0.35:
                                sentiment_color = "#F44336"  # red
                                sentiment_label = "Olumsuz"
                            else:
                                sentiment_color = "#FF9800"  # amber
                                sentiment_label = "NÃ¶tr"
                            
                            # Tarih formatÄ±
                            try:
                                pub_date = pd.to_datetime(news["pub_date"]).strftime("%d.%m.%Y %H:%M") 
                            except:
                                pub_date = "Tarih bilinmiyor"
                            
                            # Ã–zet
                            summary = news["summary"] if not pd.isna(news["summary"]) and news["summary"] != "Ã–zet alÄ±namadÄ±." else "Bu haber iÃ§in Ã¶zet bulunmuyor."
                            
                            # Haber kartÄ±
                            cols = st.columns([3, 1])
                            with cols[0]:
                                st.markdown(f"### {news['title']}")
                                st.markdown(f"""
                                <div style="font-size:0.85rem; color:#666; margin-bottom:8px;">
                                    <span style="background-color:#f0f0f0; padding:3px 6px; border-radius:3px; margin-right:8px;">
                                        <strong>{news['source']}</strong>
                                    </span>
                                    <span style="color:#888;">
                                        {pub_date}
                                    </span>
                                </div>
                                """, unsafe_allow_html=True)
                                st.markdown(f"""
                                <div style="padding: 10px; border-left: 3px solid #2196F3; background-color: #f8f9fa; margin-bottom: 10px;">
                                    {summary}
                                </div>
                                """, unsafe_allow_html=True)
                                
                                # Haberi oku butonu
                                st.markdown(f"""
                                <a href="{news['url']}" target="_blank" style="text-decoration:none;">
                                    <div style="display:inline-block; padding:5px 15px; background-color:#2196F3; color:white; 
                                                border-radius:4px; font-weight:bold; text-align:center; margin-top:5px;">
                                        Haberi Oku
                                    </div>
                                </a>
                                """, unsafe_allow_html=True)
                                
                                # Analiz et butonu
                                if st.button(f"Haberi Analiz Et", key=f"analyze_{idx}"):
                                    st.session_state.show_news_analysis = True
                                    st.session_state.news_url = news['url']
                                    st.session_state.news_analysis_results = None
                                    st.experimental_rerun()
                            
                            with cols[1]:
                                # DuyarlÄ±lÄ±k skoru
                                st.markdown(f"""
                                <div style="background-color:{sentiment_color}; color:white; padding:10px; border-radius:8px; 
                                          text-align:center; box-shadow:0 2px 5px rgba(0,0,0,0.1);">
                                    <h4 style="margin:0; font-size:1.2rem;">{sentiment_label}</h4>
                                    <p style="margin:0; font-size:1.5rem; font-weight:bold;">{sentiment_value:.2f}</p>
                                </div>
                                """, unsafe_allow_html=True)
                                
                                # Resim varsa gÃ¶ster
                                if not pd.isna(news.get("image_url")) and news["image_url"] != "":
                                    st.image(news["image_url"], use_column_width=True)
                            
                            st.markdown("---")
                    else:
                        display_log_message("news_list boÅŸ veya None dÃ¶nÃ¼yor", log_expander, "warning")
                        st.warning("Haber bulunamadÄ±. FarklÄ± bir hisse kodu deneyin veya daha sonra tekrar deneyin.")
            
            except Exception as e:
                st.error(f"Haber arama sÄ±rasÄ±nda bir hata oluÅŸtu: {str(e)}")
                display_log_message(f"Hata: {str(e)}", log_expander, "error")

# Basit GoogleNews sÄ±nÄ±fÄ±
class GoogleNews:
    """
    Google Haberler'den RSS beslemesi aracÄ±lÄ±ÄŸÄ±yla haber toplama sÄ±nÄ±fÄ±.
    
    TÃ¼rkÃ§e Google Haberler iÃ§in optimize edilmiÅŸtir ve hisse senedi haberleri
    aramak iÃ§in kullanÄ±lÄ±r.
    """
    
    def __init__(self, language='tr', region='TR'):
        """
        GoogleNews nesnesini baÅŸlatÄ±r.
        
        Args:
            language (str): Haber dili (varsayÄ±lan: 'tr' - TÃ¼rkÃ§e)
            region (str): BÃ¶lge kodu (varsayÄ±lan: 'TR' - TÃ¼rkiye)
        """
        import warnings
        # RSS parse ederken Ã§Ä±kan bazÄ± uyarÄ±larÄ± bastÄ±r
        warnings.filterwarnings("ignore", category=UserWarning, module='bs4')
        
        self.language = language.lower()
        self.region = region.upper()
        self.base_url = f"https://news.google.com/rss/search"
        
    def search(self, query, max_results=15):
        """
        Google Haberler'de arama yapar ve sonuÃ§larÄ± listeler.
        
        Args:
            query (str): Arama sorgusu
            max_results (int): Maksimum sonuÃ§ sayÄ±sÄ± (varsayÄ±lan: 15)
            
        Returns:
            list: AÅŸaÄŸÄ±daki anahtarlarÄ± iÃ§eren sÃ¶zlÃ¼k listesi:
                - title (str): Haber baÅŸlÄ±ÄŸÄ±
                - link (str): Haber baÄŸlantÄ±sÄ±
                - desc (str): AÃ§Ä±klama veya Ã¶zet
                - site (str): Haber kaynaÄŸÄ±
                - datetime (str): YayÄ±n tarihi
        """
        import requests
        from bs4 import BeautifulSoup
        from datetime import datetime
        import re
        import time
        import xml.etree.ElementTree as ET
        
        # SonuÃ§larÄ± saklamak iÃ§in liste
        results = []
        
        try:
            # Arama sorgusunu URL'ye ekle
            encoded_query = requests.utils.quote(query)
            url = f"{self.base_url}?q={encoded_query}&hl={self.language}&gl={self.region}&ceid={self.region}:{self.language}"
            
            # RSS beslemesini al
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
                'Accept-Language': f'{self.language},{self.language}-{self.region};q=0.9'
            }
            
            response = requests.get(url, headers=headers, timeout=15)
            
            # YanÄ±t baÅŸarÄ±lÄ± deÄŸilse hata fÄ±rlat
            if response.status_code != 200:
                raise Exception(f"HTTP HatasÄ±: {response.status_code}")
            
            items = []
            content = response.content
            
            # Parsing denemelerini sÄ±rayla gerÃ§ekleÅŸtir
            # 1. XML parser ile dene (lxml)
            try:
                soup = BeautifulSoup(content, 'lxml-xml')
                items = soup.find_all('item')
            except Exception:
                pass
                
            # 2. HTML parser ile dene
            if not items:
                try:
                    soup = BeautifulSoup(content, 'lxml')
                    items = soup.find_all('item')
                except Exception:
                    pass
                    
            # 3. Fallback: ElementTree ile dene
            if not items:
                try:
                    root = ET.fromstring(content)
                    # ElementTree ile item elementlerini bul
                    items_et = root.findall('.//item')
                    
                    # ElementTree elementlerini BeautifulSoup nesnelerine dÃ¶nÃ¼ÅŸtÃ¼r
                    if items_et:
                        items = []
                        for item_et in items_et:
                            item_str = ET.tostring(item_et, encoding='unicode')
                            items.append(BeautifulSoup(item_str, 'lxml-xml').find('item'))
                except Exception:
                    pass
                    
            # 4. Son Ã§are: regex ile dene
            if not items:
                try:
                    pattern = r'<item>(.*?)<\/item>'
                    items_raw = re.findall(pattern, response.text, re.DOTALL)
                    items = []
                    for item_raw in items_raw:
                        try:
                            bs_item = BeautifulSoup(f"<item>{item_raw}</item>", 'lxml-xml')
                            if bs_item and bs_item.find('item'):
                                items.append(bs_item.find('item'))
                        except Exception:
                            continue
                except Exception:
                    pass
            
            # Ä°ÅŸlenmiÅŸ URL'leri takip et (Ã§ift kayÄ±tlarÄ± Ã¶nlemek iÃ§in)
            processed_urls = set()
            
            # Her Ã¶ÄŸeyi iÅŸle
            for item in items[:max_results]:
                try:
                    # Temel bilgileri Ã§Ä±kar
                    title = ""
                    site = ""
                    
                    title_elem = item.find('title')
                    if title_elem and title_elem.text:
                        title_text = title_elem.text.strip()
                        
                        # Google News baÅŸlÄ±k formatÄ±: "BaÅŸlÄ±k - Kaynak"
                        if " - " in title_text:
                            title_parts = title_text.rsplit(" - ", 1)
                            if len(title_parts) == 2:
                                title = title_parts[0].strip()
                                site = title_parts[1].strip()
                        else:
                            title = title_text
                            # Kaynak bilgisini <source> etiketinden almayÄ± dene
                            source_elem = item.find('source')
                            if source_elem and source_elem.text:
                                site = source_elem.text.strip()
                    
                    # BaÄŸlantÄ±yÄ± al
                    link = ""
                    
                    # Ã–nce <link> etiketi iÃ§eriÄŸine bak
                    link_elem = item.find('link')
                    if link_elem:
                        if link_elem.text and link_elem.text.strip():
                            link = link_elem.text.strip()
                        elif link_elem.get('href'):
                            link = link_elem.get('href').strip()
                    
                    # <link> bulunamadÄ±ysa <guid> etiketine bak
                    if not link:
                        guid_elem = item.find('guid')
                        if guid_elem and guid_elem.text:
                            link = guid_elem.text.strip()
                    
                    # <guid> bulunamadÄ±ysa, <enclosure> etiketine bak
                    if not link:
                        enclosure_elem = item.find('enclosure')
                        if enclosure_elem and enclosure_elem.get('url'):
                            link = enclosure_elem.get('url').strip()
                    
                    # URL'yi temizle
                    if link and link.startswith("https://news.google.com/articles/"):
                        # Google News yÃ¶nlendirme URL'sini temizle
                        link = re.sub(r'\?.*$', '', link)
                    
                    # URL tekrarÄ±nÄ± kontrol et veya geÃ§erli bir URL yoksa atla
                    if not link or link in processed_urls:
                        continue
                    processed_urls.add(link)
                    
                    # AÃ§Ä±klamayÄ± al (description veya summary)
                    desc = ""
                    desc_elem = item.find('description') or item.find('summary') or item.find('content')
                    if desc_elem and desc_elem.text:
                        desc = desc_elem.text.strip()
                        # HTML etiketlerini temizle
                        desc = re.sub(r'<[^>]*>', '', desc)
                    
                    # YayÄ±n tarihini al
                    pub_date_str = ""
                    pub_date_elem = item.find('pubDate') or item.find('published') or item.find('updated')
                    if pub_date_elem and pub_date_elem.text:
                        pub_date_str = pub_date_elem.text.strip()
                    
                    # Tarih formatÄ±nÄ± dÃ¼zenle
                    datetime_str = ""
                    if pub_date_str:
                        try:
                            # Tarihi standartlaÅŸtÄ±r
                            pub_date_str = pub_date_str.replace('GMT', '+0000')
                            dt = None
                            
                            # FarklÄ± tarih formatlarÄ±nÄ± dene
                            date_formats = [
                                "%a, %d %b %Y %H:%M:%S %z",  # RFC 2822
                                "%Y-%m-%dT%H:%M:%S%z",       # ISO 8601
                                "%Y-%m-%dT%H:%M:%SZ",        # ISO 8601 (Z)
                                "%Y-%m-%d %H:%M:%S",         # Basic format
                                "%a, %d %b %Y %H:%M:%S"      # RFC 2822 without timezone
                            ]
                            
                            for fmt in date_formats:
                                try:
                                    dt = datetime.strptime(pub_date_str, fmt)
                                    break
                                except ValueError:
                                    continue
                            
                            if dt:
                                # KullanÄ±cÄ± dostu biÃ§ime Ã§evir
                                datetime_str = dt.strftime("%d.%m.%Y %H:%M")
                            else:
                                datetime_str = pub_date_str
                        except Exception:
                            datetime_str = pub_date_str
                    
                    # SonuÃ§lara ekle
                    if title and link:  # Hem baÅŸlÄ±k hem baÄŸlantÄ± varsa ekle
                        results.append({
                            'title': title,
                            'link': link,
                            'desc': desc,
                            'site': site,
                            'datetime': datetime_str
                        })
                    
                except Exception as e:
                    print(f"Haber Ã¶ÄŸesi iÅŸlenirken hata: {str(e)}")
                    continue
            
            # SonuÃ§ yoksa alternatif URL dene
            if not results:
                try:
                    # Alternatif URL formatÄ±nÄ± dene
                    alt_url = f"https://news.google.com/rss?q={encoded_query}&hl={self.language}&gl={self.region}&ceid={self.region}:{self.language}"
                    alt_response = requests.get(alt_url, headers=headers, timeout=15)
                    
                    if alt_response.status_code == 200:
                        # AynÄ± ayrÄ±ÅŸtÄ±rma adÄ±mlarÄ±nÄ± alternatif URL iÃ§in tekrarla
                        items = []
                        content = alt_response.content
                        
                        # 1. XML parser
                        try:
                            soup = BeautifulSoup(content, 'lxml-xml')
                            items = soup.find_all('item')
                        except Exception:
                            pass
                        
                        # 2. HTML parser
                        if not items:
                            try:
                                soup = BeautifulSoup(content, 'lxml')
                                items = soup.find_all('item')
                            except Exception:
                                pass
                        
                        # Alternatif URL'den gelen sonuÃ§larÄ± da aynÄ± ÅŸekilde iÅŸle
                        for item in items[:max_results]:
                            try:
                                # YukarÄ±daki iÅŸlemleri tekrarla
                                title = ""
                                site = ""
                                
                                title_elem = item.find('title')
                                if title_elem and title_elem.text:
                                    title_text = title_elem.text.strip()
                                    
                                    if " - " in title_text:
                                        title_parts = title_text.rsplit(" - ", 1)
                                        if len(title_parts) == 2:
                                            title = title_parts[0].strip()
                                            site = title_parts[1].strip()
                                    else:
                                        title = title_text
                                        source_elem = item.find('source')
                                        if source_elem and source_elem.text:
                                            site = source_elem.text.strip()
                                
                                # BaÄŸlantÄ±
                                link = ""
                                link_elem = item.find('link')
                                if link_elem:
                                    if link_elem.text and link_elem.text.strip():
                                        link = link_elem.text.strip()
                                    elif link_elem.get('href'):
                                        link = link_elem.get('href').strip()
                                
                                if not link:
                                    guid_elem = item.find('guid')
                                    if guid_elem and guid_elem.text:
                                        link = guid_elem.text.strip()
                                
                                # URL tekrarÄ±nÄ± kontrol et
                                if not link or link in processed_urls:
                                    continue
                                processed_urls.add(link)
                                
                                # AÃ§Ä±klama
                                desc = ""
                                desc_elem = item.find('description') or item.find('summary') or item.find('content')
                                if desc_elem and desc_elem.text:
                                    desc = desc_elem.text.strip()
                                    # HTML etiketlerini temizle
                                    desc = re.sub(r'<[^>]*>', '', desc)
                                
                                # YayÄ±n tarihi
                                pub_date_str = ""
                                pub_date_elem = item.find('pubDate') or item.find('published') or item.find('updated')
                                if pub_date_elem and pub_date_elem.text:
                                    pub_date_str = pub_date_elem.text.strip()
                                
                                # Tarih formatÄ±
                                datetime_str = ""
                                if pub_date_str:
                                    try:
                                        pub_date_str = pub_date_str.replace('GMT', '+0000')
                                        dt = None
                                        
                                        date_formats = [
                                            "%a, %d %b %Y %H:%M:%S %z",
                                            "%Y-%m-%dT%H:%M:%S%z",
                                            "%Y-%m-%dT%H:%M:%SZ",
                                            "%Y-%m-%d %H:%M:%S",
                                            "%a, %d %b %Y %H:%M:%S"
                                        ]
                                        
                                        for fmt in date_formats:
                                            try:
                                                dt = datetime.strptime(pub_date_str, fmt)
                                                break
                                            except ValueError:
                                                continue
                                        
                                        if dt:
                                            datetime_str = dt.strftime("%d.%m.%Y %H:%M")
                                        else:
                                            datetime_str = pub_date_str
                                    except Exception:
                                        datetime_str = pub_date_str
                                
                                # SonuÃ§larÄ± ekle
                                if title and link:
                                    results.append({
                                        'title': title,
                                        'link': link,
                                        'desc': desc,
                                        'site': site,
                                        'datetime': datetime_str
                                    })
                                
                            except Exception as e:
                                print(f"Alternatif haber Ã¶ÄŸesi iÅŸlenirken hata: {str(e)}")
                                continue
                except Exception as alt_e:
                    print(f"Alternatif URL ile arama hatasÄ±: {str(alt_e)}")
                    pass
            
        except Exception as e:
            print(f"GoogleNews arama hatasÄ±: {str(e)}")
            
        return results

# Haber kaynaklarÄ± (provider'lar)
NEWS_PROVIDERS = {
    'Google News': {
        'name': 'Google News',
        'icon': 'ğŸ“°',
        'enabled': True
    }
}

# Render the news tab
if __name__ == "__main__":
    render_stock_news_tab() 